{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjwalroyal14/CautiousSpeak/blob/main/Hate_speech%C2%A0detection_using_ML_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Detection using ML classifiers**"
      ],
      "metadata": {
        "id": "FmrsC_C8FqQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML classifiers vs Neural Network**"
      ],
      "metadata": {
        "id": "RkdTDsLSQipW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insatlling necesaary libraries"
      ],
      "metadata": {
        "id": "rDvnum5xRDjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBLZGYS_B8Wf",
        "outputId": "8398dddb-7180-4dbd-b34d-e8ee93fa61e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install catboost\n",
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiiFQZAHCM_y",
        "outputId": "a23b3d4e-a120-49e6-e5b3-1cb94522b731"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.1.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.11.4)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy seaborn matplotlib pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O28n_zaChJf",
        "outputId": "be9921bd-44d2-4d08-d60c-6badb95aae02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.11/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (4.67.1)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.6)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.0.5)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.13.0)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.7.0)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (4.5.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (8.7.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.5.0)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.24.1)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.2.1)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.10.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.14.4)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.1)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.11/dist-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders>=2.4.0->pycaret) (1.0.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (0.1.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.15)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.14.0->pycaret) (9.1.2)\n",
            "Requirement already satisfied: dash>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.0.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.18)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.4.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (2025.4.26)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.13.2)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.24.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.3.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.7)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning the source git"
      ],
      "metadata": {
        "id": "rZpoFn27RI1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danushkhanna/iNeuron.ai-Phishing-Domain-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5TFNiABCvvo",
        "outputId": "01f8e0ea-4a75-4a68-fec5-6e481eb933e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'iNeuron.ai-Phishing-Domain-Detection' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "woSWFeW3RNkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tNPX6c6sC02b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgbm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "XFA5-fbeC4Pq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.plots import plot_convergence\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "WCu74VfLC7n3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from pycaret.classification import *"
      ],
      "metadata": {
        "id": "uqOdhxvWC8k0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Detection dataset**"
      ],
      "metadata": {
        "id": "6h5pcw1BRW1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPBjhZX1C_lk",
        "outputId": "d2e56d51-e28d-447c-ee1a-043823dc160c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/CONAN_English_RewardTest.csv')\n",
        "df2=pd.read_csv('/content/drive/MyDrive/CONAN_Dataset - CONAN_English_RewardTrain.csv')\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "L-ROGajtDR1O",
        "outputId": "f686320a-bc09-482c-dd48-48a258afc8ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 speech  class\n",
              "0     The Arabs want to impose their religion and to...      0\n",
              "1     The Arabs are all terrorists and they want to ...      0\n",
              "2     It's a shame that there is no longer the cruci...      0\n",
              "3     Then we must castrate even Italians who rape, ...      1\n",
              "4     The Arabs do not want to impose their religion...      1\n",
              "...                                                 ...    ...\n",
              "1495  What is your problem with Muslims? They are pe...      1\n",
              "1496  Did you know that the only terrorist attacks i...      1\n",
              "1497  The Arabs want to impose their religion and to...      0\n",
              "1498           A real Islamic invasion is taking place.      0\n",
              "1499  Hi, I also condemn these acts that are so atro...      1\n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d741d821-d505-4555-91f9-19d8afc728fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Arabs are all terrorists and they want to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's a shame that there is no longer the cruci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then we must castrate even Italians who rape, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Arabs do not want to impose their religion...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>What is your problem with Muslims? They are pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>Did you know that the only terrorist attacks i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>A real Islamic invasion is taking place.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>Hi, I also condemn these acts that are so atro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d741d821-d505-4555-91f9-19d8afc728fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d741d821-d505-4555-91f9-19d8afc728fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d741d821-d505-4555-91f9-19d8afc728fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0aa44126-bd4b-46d4-a093-002958fcb760\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0aa44126-bd4b-46d4-a093-002958fcb760')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0aa44126-bd4b-46d4-a093-002958fcb760 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_71d0a842-480a-4a2f-b78b-c24aaca669c2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_71d0a842-480a-4a2f-b78b-c24aaca669c2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 786,\n        \"samples\": [\n          \"Tolerance of others' religions must be mutual. You cannot convict a person based on his faith.\",\n          \"There are also many Italian Muslims why we stop them from practising their beliefs? Why we give this opportunity only to Catholics? Why mosques bother you? And then I assure you that the number of mosques is negligible compared to the number of Catholic churches.\",\n          \"The problem lies in having a more open, secular and human mentality without blinders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "axfZRrUyDfZK",
        "outputId": "f72efa58-3eef-4768-dd58-e49a8c3a5ce2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              speech  class\n",
              "0  The Arabs want to impose their religion and to...      0\n",
              "1  The Arabs are all terrorists and they want to ...      0\n",
              "2  It's a shame that there is no longer the cruci...      0\n",
              "3  Then we must castrate even Italians who rape, ...      1\n",
              "4  The Arabs do not want to impose their religion...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4875b31-ad85-4935-b987-5f800a20c6c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Arabs are all terrorists and they want to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's a shame that there is no longer the cruci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then we must castrate even Italians who rape, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Arabs do not want to impose their religion...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4875b31-ad85-4935-b987-5f800a20c6c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4875b31-ad85-4935-b987-5f800a20c6c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4875b31-ad85-4935-b987-5f800a20c6c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-87597724-4731-4dc3-875a-1744691bb6e8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87597724-4731-4dc3-875a-1744691bb6e8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-87597724-4731-4dc3-875a-1744691bb6e8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 786,\n        \"samples\": [\n          \"Tolerance of others' religions must be mutual. You cannot convict a person based on his faith.\",\n          \"There are also many Italian Muslims why we stop them from practising their beliefs? Why we give this opportunity only to Catholics? Why mosques bother you? And then I assure you that the number of mosques is negligible compared to the number of Catholic churches.\",\n          \"The problem lies in having a more open, secular and human mentality without blinders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8lcc6JCDiZd",
        "outputId": "aca28137-faec-4cbf-c7dd-c64722aa1e04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             class\n",
            "count  1500.000000\n",
            "mean      0.600667\n",
            "std       0.489925\n",
            "min       0.000000\n",
            "25%       0.000000\n",
            "50%       1.000000\n",
            "75%       1.000000\n",
            "max       1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SETTING UP THE DATA FOR MODELLING\n",
        "\n",
        "setup(data=df2, target='class')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "6feDppxhEN7B",
        "outputId": "7eef6956-4f7d-4d28-deed-311213d2b56c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ea713c43610>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_79572_row8_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_79572\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_79572_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_79572_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_79572_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
              "      <td id=\"T_79572_row0_col1\" class=\"data row0 col1\" >1376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_79572_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_79572_row1_col1\" class=\"data row1 col1\" >class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_79572_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
              "      <td id=\"T_79572_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_79572_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
              "      <td id=\"T_79572_row3_col1\" class=\"data row3 col1\" >(1500, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_79572_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_79572_row4_col1\" class=\"data row4 col1\" >(1500, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_79572_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_79572_row5_col1\" class=\"data row5 col1\" >(1050, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_79572_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_79572_row6_col1\" class=\"data row6 col1\" >(450, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_79572_row7_col0\" class=\"data row7 col0\" >Categorical features</td>\n",
              "      <td id=\"T_79572_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_79572_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
              "      <td id=\"T_79572_row8_col1\" class=\"data row8 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_79572_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
              "      <td id=\"T_79572_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_79572_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
              "      <td id=\"T_79572_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_79572_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
              "      <td id=\"T_79572_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_79572_row12_col0\" class=\"data row12 col0\" >Maximum one-hot encoding</td>\n",
              "      <td id=\"T_79572_row12_col1\" class=\"data row12 col1\" >25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_79572_row13_col0\" class=\"data row13 col0\" >Encoding method</td>\n",
              "      <td id=\"T_79572_row13_col1\" class=\"data row13 col1\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_79572_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_79572_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_79572_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
              "      <td id=\"T_79572_row15_col1\" class=\"data row15 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_79572_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_79572_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_79572_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
              "      <td id=\"T_79572_row17_col1\" class=\"data row17 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_79572_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_79572_row18_col1\" class=\"data row18 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_79572_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_79572_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_79572_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_79572_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
              "      <td id=\"T_79572_row20_col1\" class=\"data row20 col1\" >9320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pycaret.classification.oop.ClassificationExperiment at 0x7ea713b3c350>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Data for Modeling-**"
      ],
      "metadata": {
        "id": "J958RiNumTXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= df2['speech']\n",
        "y_train= df2['class']"
      ],
      "metadata": {
        "id": "8Pi5UWoKEd3W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test= df1['speech']\n",
        "y_test= df1['class']"
      ],
      "metadata": {
        "id": "oVW1Yl2zEoyb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming X_train is a pandas Series containing text data\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "WomAXi9441Td"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbNYkTUEuP0",
        "outputId": "84630547-8de2-4d48-ff9e-2b6e653a5837"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 2246)\n",
            "(1500,)\n",
            "(1500, 2246)\n",
            "(1500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to store the results\n",
        "results = {}"
      ],
      "metadata": {
        "id": "y032q_2tE3PX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating Various ML Models-**"
      ],
      "metadata": {
        "id": "_rxn1TFtmcEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Logistic regression-**"
      ],
      "metadata": {
        "id": "q7EqC_TPE_CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(X_train, y_train)\n",
        "y_pred = logistic.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Logistic Regression'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Logistic Regression'][0])\n",
        "print(\"Precision:\", results['Logistic Regression'][1])\n",
        "print(\"Recall:\", results['Logistic Regression'][2])\n",
        "print(\"F1-score:\", results['Logistic Regression'][3])\n",
        "print(\"Training Time:\", results['Logistic Regression'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxAVURAE6Cf",
        "outputId": "16ecd25f-7bc2-4f36-cd8c-dc6a2899cc73"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9926666666666667\n",
            "Precision: 0.9927224312410754\n",
            "Recall: 0.9926666666666667\n",
            "F1-score: 0.992657134228\n",
            "Training Time: 0.09058690071105957\n",
            "CPU times: user 44 ms, sys: 1.15 ms, total: 45.1 ms\n",
            "Wall time: 144 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. K-Nearest Neighbors (KNN)**"
      ],
      "metadata": {
        "id": "thJBSMzpFBZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['K-Nearest Neighbors (KNN)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['K-Nearest Neighbors (KNN)'][0])\n",
        "print(\"Precision:\", results['K-Nearest Neighbors (KNN)'][1])\n",
        "print(\"Recall:\", results['K-Nearest Neighbors (KNN)'][2])\n",
        "print(\"F1-score:\", results['K-Nearest Neighbors (KNN)'][3])\n",
        "print(\"Training Time:\", results['K-Nearest Neighbors (KNN)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePCWQSiWE-MU",
        "outputId": "331a2927-fc49-4d31-9d5a-183a100cef41"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9613333333333334\n",
            "Precision: 0.9637670892742709\n",
            "Recall: 0.9613333333333334\n",
            "F1-score: 0.9615490402431071\n",
            "Training Time: 0.5908911228179932\n",
            "CPU times: user 131 ms, sys: 66.8 ms, total: 198 ms\n",
            "Wall time: 608 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Gaussian Naive Bayes (GaussianNB)**"
      ],
      "metadata": {
        "id": "cy3G5N9gFKM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "gnb.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = gnb.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEDxCYAFO56",
        "outputId": "b7bdb6ae-e4cd-40ed-f93b-0d054c8bd910"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.998\n",
            "Precision: 0.9980099667774087\n",
            "Recall: 0.998\n",
            "F1-score: 0.9980008303252941\n",
            "Training Time: 0.237623929977417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Decision Trees**"
      ],
      "metadata": {
        "id": "ynFNkD3zFRxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Decision Trees'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Decision Trees'][0])\n",
        "print(\"Precision:\", results['Decision Trees'][1])\n",
        "print(\"Recall:\", results['Decision Trees'][2])\n",
        "print(\"F1-score:\", results['Decision Trees'][3])\n",
        "print(\"Training Time:\", results['Decision Trees'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpyN_LK-FQej",
        "outputId": "b6d7d972-3785-4c7c-d324-17b586ce9c22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.12970185279846191\n",
            "CPU times: user 77.6 ms, sys: 0 ns, total: 77.6 ms\n",
            "Wall time: 145 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Random Forest**"
      ],
      "metadata": {
        "id": "jH0Z2EmuFZ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Random Forest'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Random Forest'][0])\n",
        "print(\"Precision:\", results['Random Forest'][1])\n",
        "print(\"Recall:\", results['Random Forest'][2])\n",
        "print(\"F1-score:\", results['Random Forest'][3])\n",
        "print(\"Training Time:\", results['Random Forest'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3vMlSWGFVuL",
        "outputId": "51df95d7-c228-4219-b407-74c0b1cea996"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.9094998836517334\n",
            "CPU times: user 580 ms, sys: 6.37 ms, total: 587 ms\n",
            "Wall time: 923 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Extra Trees**"
      ],
      "metadata": {
        "id": "INdeC4kgFcvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "y_pred = et.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Extra Trees'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Extra Trees'][0])\n",
        "print(\"Precision:\", results['Extra Trees'][1])\n",
        "print(\"Recall:\", results['Extra Trees'][2])\n",
        "print(\"F1-score:\", results['Extra Trees'][3])\n",
        "print(\"Training Time:\", results['Extra Trees'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV-BN4k6FeN1",
        "outputId": "b6be186d-8711-4520-f368-d59afd47cda0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.7418222427368164\n",
            "CPU times: user 528 ms, sys: 6.41 ms, total: 535 ms\n",
            "Wall time: 771 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "hfOEyHCaFh6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Support Vector Machines'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Support Vector Machines'][0])\n",
        "print(\"Precision:\", results['Support Vector Machines'][1])\n",
        "print(\"Recall:\", results['Support Vector Machines'][2])\n",
        "print(\"F1-score:\", results['Support Vector Machines'][3])\n",
        "print(\"Training Time:\", results['Support Vector Machines'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHqu1QAqFl2a",
        "outputId": "5f69d4d5-b606-4746-fc52-6db002231b8d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.6861007213592529\n",
            "CPU times: user 402 ms, sys: 4.16 ms, total: 406 ms\n",
            "Wall time: 713 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Neural Network MLP (Multi-layer Perceptron)**"
      ],
      "metadata": {
        "id": "DCnM0mTuFqA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Neural Networks (Multi-layer Perceptron)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Neural Networks (Multi-layer Perceptron)'][0])\n",
        "print(\"Precision:\", results['Neural Networks (Multi-layer Perceptron)'][1])\n",
        "print(\"Recall:\", results['Neural Networks (Multi-layer Perceptron)'][2])\n",
        "print(\"F1-score:\", results['Neural Networks (Multi-layer Perceptron)'][3])\n",
        "print(\"Training Time:\", results['Neural Networks (Multi-layer Perceptron)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCySSmY2FpXg",
        "outputId": "6e7e2dec-7baf-4860-e819-cc139c86e179"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 10.511328220367432\n",
            "CPU times: user 5.39 s, sys: 3.86 s, total: 9.25 s\n",
            "Wall time: 10.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. AdaBoost**"
      ],
      "metadata": {
        "id": "FURePsNQHBoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['AdaBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['AdaBoost'][0])\n",
        "print(\"Precision:\", results['AdaBoost'][1])\n",
        "print(\"Recall:\", results['AdaBoost'][2])\n",
        "print(\"F1-score:\", results['AdaBoost'][3])\n",
        "print(\"Training Time:\", results['AdaBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E19VajPaHDoO",
        "outputId": "4bc85f8c-7179-4df4-d43f-a59feecd0a9d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 1.2466678619384766\n",
            "CPU times: user 543 ms, sys: 7.48 ms, total: 551 ms\n",
            "Wall time: 1.28 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. XGBoost**"
      ],
      "metadata": {
        "id": "Gel0ZJOQHTQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "xgboost = xgb.XGBClassifier()\n",
        "xgboost.fit(X_train, y_train)\n",
        "y_pred = xgboost.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['XGBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['XGBoost'][0])\n",
        "print(\"Precision:\", results['XGBoost'][1])\n",
        "print(\"Recall:\", results['XGBoost'][2])\n",
        "print(\"F1-score:\", results['XGBoost'][3])\n",
        "print(\"Training Time:\", results['XGBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67t0JFLnHSkf",
        "outputId": "5871752b-6f35-417e-e152-b5f0e349ce3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 3.944979429244995\n",
            "CPU times: user 3.31 s, sys: 0 ns, total: 3.31 s\n",
            "Wall time: 3.97 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Light Gradient Boosting Machine (LGBM)**"
      ],
      "metadata": {
        "id": "KfG8dOHrJqSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm\n",
        "\n",
        "# Initialize LightGBM classifier\n",
        "lgbm_classifier = lgbm.LGBMClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lgbm_classifier.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lgbm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KsKHaGYJpWF",
        "outputId": "51b1a82b-d54b-4345-f1ad-116424fb5313"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 901, number of negative: 599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004775 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4542\n",
            "[LightGBM] [Info] Number of data points in the train set: 1500, number of used features: 202\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.600667 -> initscore=0.408244\n",
            "[LightGBM] [Info] Start training from score 0.408244\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.40665197372436523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. CatBoost**"
      ],
      "metadata": {
        "id": "EUWWiKAeJ25H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "cat = CatBoostClassifier()\n",
        "cat.fit(X_train, y_train)\n",
        "y_pred = cat.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['CatBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['CatBoost'][0])\n",
        "print(\"Precision:\", results['CatBoost'][1])\n",
        "print(\"Recall:\", results['CatBoost'][2])\n",
        "print(\"F1-score:\", results['CatBoost'][3])\n",
        "print(\"Training Time:\", results['CatBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ymFpkSEJ5dv",
        "outputId": "201c3237-7022-469a-9c1b-2b9d3d30fa62"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.01225\n",
            "0:\tlearn: 0.6810806\ttotal: 114ms\tremaining: 1m 53s\n",
            "1:\tlearn: 0.6701537\ttotal: 209ms\tremaining: 1m 44s\n",
            "2:\tlearn: 0.6571809\ttotal: 275ms\tremaining: 1m 31s\n",
            "3:\tlearn: 0.6463226\ttotal: 364ms\tremaining: 1m 30s\n",
            "4:\tlearn: 0.6324722\ttotal: 426ms\tremaining: 1m 24s\n",
            "5:\tlearn: 0.6234640\ttotal: 481ms\tremaining: 1m 19s\n",
            "6:\tlearn: 0.6152077\ttotal: 563ms\tremaining: 1m 19s\n",
            "7:\tlearn: 0.6047809\ttotal: 643ms\tremaining: 1m 19s\n",
            "8:\tlearn: 0.5921031\ttotal: 760ms\tremaining: 1m 23s\n",
            "9:\tlearn: 0.5843081\ttotal: 833ms\tremaining: 1m 22s\n",
            "10:\tlearn: 0.5726262\ttotal: 910ms\tremaining: 1m 21s\n",
            "11:\tlearn: 0.5643372\ttotal: 957ms\tremaining: 1m 18s\n",
            "12:\tlearn: 0.5577445\ttotal: 1.01s\tremaining: 1m 17s\n",
            "13:\tlearn: 0.5492630\ttotal: 1.09s\tremaining: 1m 16s\n",
            "14:\tlearn: 0.5406030\ttotal: 1.18s\tremaining: 1m 17s\n",
            "15:\tlearn: 0.5334646\ttotal: 1.25s\tremaining: 1m 16s\n",
            "16:\tlearn: 0.5260592\ttotal: 1.32s\tremaining: 1m 16s\n",
            "17:\tlearn: 0.5160168\ttotal: 1.39s\tremaining: 1m 15s\n",
            "18:\tlearn: 0.5055446\ttotal: 1.45s\tremaining: 1m 14s\n",
            "19:\tlearn: 0.4994996\ttotal: 1.51s\tremaining: 1m 14s\n",
            "20:\tlearn: 0.4927043\ttotal: 1.57s\tremaining: 1m 13s\n",
            "21:\tlearn: 0.4851101\ttotal: 1.63s\tremaining: 1m 12s\n",
            "22:\tlearn: 0.4788551\ttotal: 1.69s\tremaining: 1m 11s\n",
            "23:\tlearn: 0.4727389\ttotal: 1.75s\tremaining: 1m 11s\n",
            "24:\tlearn: 0.4645408\ttotal: 1.81s\tremaining: 1m 10s\n",
            "25:\tlearn: 0.4575083\ttotal: 1.86s\tremaining: 1m 9s\n",
            "26:\tlearn: 0.4468580\ttotal: 1.94s\tremaining: 1m 9s\n",
            "27:\tlearn: 0.4397846\ttotal: 2s\tremaining: 1m 9s\n",
            "28:\tlearn: 0.4346788\ttotal: 2.08s\tremaining: 1m 9s\n",
            "29:\tlearn: 0.4274945\ttotal: 2.14s\tremaining: 1m 9s\n",
            "30:\tlearn: 0.4216115\ttotal: 2.18s\tremaining: 1m 8s\n",
            "31:\tlearn: 0.4140000\ttotal: 2.28s\tremaining: 1m 9s\n",
            "32:\tlearn: 0.4071219\ttotal: 2.36s\tremaining: 1m 9s\n",
            "33:\tlearn: 0.4034946\ttotal: 2.41s\tremaining: 1m 8s\n",
            "34:\tlearn: 0.3987041\ttotal: 2.46s\tremaining: 1m 7s\n",
            "35:\tlearn: 0.3952557\ttotal: 2.55s\tremaining: 1m 8s\n",
            "36:\tlearn: 0.3907685\ttotal: 2.6s\tremaining: 1m 7s\n",
            "37:\tlearn: 0.3858030\ttotal: 2.67s\tremaining: 1m 7s\n",
            "38:\tlearn: 0.3801329\ttotal: 2.75s\tremaining: 1m 7s\n",
            "39:\tlearn: 0.3754808\ttotal: 2.86s\tremaining: 1m 8s\n",
            "40:\tlearn: 0.3704369\ttotal: 2.94s\tremaining: 1m 8s\n",
            "41:\tlearn: 0.3663734\ttotal: 3.02s\tremaining: 1m 8s\n",
            "42:\tlearn: 0.3624142\ttotal: 3.1s\tremaining: 1m 8s\n",
            "43:\tlearn: 0.3572405\ttotal: 3.16s\tremaining: 1m 8s\n",
            "44:\tlearn: 0.3523054\ttotal: 3.21s\tremaining: 1m 8s\n",
            "45:\tlearn: 0.3484798\ttotal: 3.26s\tremaining: 1m 7s\n",
            "46:\tlearn: 0.3450678\ttotal: 3.34s\tremaining: 1m 7s\n",
            "47:\tlearn: 0.3416664\ttotal: 3.44s\tremaining: 1m 8s\n",
            "48:\tlearn: 0.3381269\ttotal: 3.5s\tremaining: 1m 7s\n",
            "49:\tlearn: 0.3337103\ttotal: 3.56s\tremaining: 1m 7s\n",
            "50:\tlearn: 0.3300990\ttotal: 3.61s\tremaining: 1m 7s\n",
            "51:\tlearn: 0.3251562\ttotal: 3.66s\tremaining: 1m 6s\n",
            "52:\tlearn: 0.3210438\ttotal: 3.71s\tremaining: 1m 6s\n",
            "53:\tlearn: 0.3177520\ttotal: 3.78s\tremaining: 1m 6s\n",
            "54:\tlearn: 0.3150415\ttotal: 3.83s\tremaining: 1m 5s\n",
            "55:\tlearn: 0.3117218\ttotal: 3.87s\tremaining: 1m 5s\n",
            "56:\tlearn: 0.3076716\ttotal: 3.92s\tremaining: 1m 4s\n",
            "57:\tlearn: 0.3033684\ttotal: 3.96s\tremaining: 1m 4s\n",
            "58:\tlearn: 0.3001569\ttotal: 4.04s\tremaining: 1m 4s\n",
            "59:\tlearn: 0.2962988\ttotal: 4.09s\tremaining: 1m 4s\n",
            "60:\tlearn: 0.2938340\ttotal: 4.15s\tremaining: 1m 3s\n",
            "61:\tlearn: 0.2896705\ttotal: 4.21s\tremaining: 1m 3s\n",
            "62:\tlearn: 0.2876744\ttotal: 4.27s\tremaining: 1m 3s\n",
            "63:\tlearn: 0.2850324\ttotal: 4.35s\tremaining: 1m 3s\n",
            "64:\tlearn: 0.2827937\ttotal: 4.43s\tremaining: 1m 3s\n",
            "65:\tlearn: 0.2802532\ttotal: 4.49s\tremaining: 1m 3s\n",
            "66:\tlearn: 0.2771693\ttotal: 4.54s\tremaining: 1m 3s\n",
            "67:\tlearn: 0.2747960\ttotal: 4.59s\tremaining: 1m 2s\n",
            "68:\tlearn: 0.2722805\ttotal: 4.65s\tremaining: 1m 2s\n",
            "69:\tlearn: 0.2705450\ttotal: 4.72s\tremaining: 1m 2s\n",
            "70:\tlearn: 0.2683979\ttotal: 4.79s\tremaining: 1m 2s\n",
            "71:\tlearn: 0.2663373\ttotal: 4.86s\tremaining: 1m 2s\n",
            "72:\tlearn: 0.2641963\ttotal: 4.93s\tremaining: 1m 2s\n",
            "73:\tlearn: 0.2622357\ttotal: 4.98s\tremaining: 1m 2s\n",
            "74:\tlearn: 0.2597294\ttotal: 5.02s\tremaining: 1m 1s\n",
            "75:\tlearn: 0.2578898\ttotal: 5.11s\tremaining: 1m 2s\n",
            "76:\tlearn: 0.2557316\ttotal: 5.15s\tremaining: 1m 1s\n",
            "77:\tlearn: 0.2535732\ttotal: 5.19s\tremaining: 1m 1s\n",
            "78:\tlearn: 0.2511649\ttotal: 5.24s\tremaining: 1m 1s\n",
            "79:\tlearn: 0.2490372\ttotal: 5.27s\tremaining: 1m\n",
            "80:\tlearn: 0.2475874\ttotal: 5.32s\tremaining: 1m\n",
            "81:\tlearn: 0.2453250\ttotal: 5.37s\tremaining: 1m\n",
            "82:\tlearn: 0.2431713\ttotal: 5.41s\tremaining: 59.8s\n",
            "83:\tlearn: 0.2414642\ttotal: 5.45s\tremaining: 59.4s\n",
            "84:\tlearn: 0.2397018\ttotal: 5.49s\tremaining: 59.1s\n",
            "85:\tlearn: 0.2380128\ttotal: 5.54s\tremaining: 58.9s\n",
            "86:\tlearn: 0.2355461\ttotal: 5.6s\tremaining: 58.8s\n",
            "87:\tlearn: 0.2339445\ttotal: 5.65s\tremaining: 58.5s\n",
            "88:\tlearn: 0.2320667\ttotal: 5.69s\tremaining: 58.2s\n",
            "89:\tlearn: 0.2306960\ttotal: 5.73s\tremaining: 58s\n",
            "90:\tlearn: 0.2287348\ttotal: 5.78s\tremaining: 57.7s\n",
            "91:\tlearn: 0.2271670\ttotal: 5.82s\tremaining: 57.5s\n",
            "92:\tlearn: 0.2255833\ttotal: 5.9s\tremaining: 57.5s\n",
            "93:\tlearn: 0.2228967\ttotal: 5.95s\tremaining: 57.4s\n",
            "94:\tlearn: 0.2204817\ttotal: 6s\tremaining: 57.1s\n",
            "95:\tlearn: 0.2188565\ttotal: 6.05s\tremaining: 56.9s\n",
            "96:\tlearn: 0.2168701\ttotal: 6.09s\tremaining: 56.7s\n",
            "97:\tlearn: 0.2149205\ttotal: 6.14s\tremaining: 56.5s\n",
            "98:\tlearn: 0.2128968\ttotal: 6.18s\tremaining: 56.3s\n",
            "99:\tlearn: 0.2115958\ttotal: 6.22s\tremaining: 56s\n",
            "100:\tlearn: 0.2096899\ttotal: 6.28s\tremaining: 55.9s\n",
            "101:\tlearn: 0.2081648\ttotal: 6.34s\tremaining: 55.8s\n",
            "102:\tlearn: 0.2057496\ttotal: 6.39s\tremaining: 55.6s\n",
            "103:\tlearn: 0.2046510\ttotal: 6.43s\tremaining: 55.4s\n",
            "104:\tlearn: 0.2032974\ttotal: 6.47s\tremaining: 55.2s\n",
            "105:\tlearn: 0.2018709\ttotal: 6.52s\tremaining: 55s\n",
            "106:\tlearn: 0.2006802\ttotal: 6.58s\tremaining: 55s\n",
            "107:\tlearn: 0.1996458\ttotal: 6.65s\tremaining: 54.9s\n",
            "108:\tlearn: 0.1984366\ttotal: 6.72s\tremaining: 54.9s\n",
            "109:\tlearn: 0.1972428\ttotal: 6.79s\tremaining: 54.9s\n",
            "110:\tlearn: 0.1956846\ttotal: 6.87s\tremaining: 55s\n",
            "111:\tlearn: 0.1944334\ttotal: 6.93s\tremaining: 55s\n",
            "112:\tlearn: 0.1931047\ttotal: 7s\tremaining: 54.9s\n",
            "113:\tlearn: 0.1920598\ttotal: 7.04s\tremaining: 54.7s\n",
            "114:\tlearn: 0.1909816\ttotal: 7.09s\tremaining: 54.6s\n",
            "115:\tlearn: 0.1899069\ttotal: 7.16s\tremaining: 54.5s\n",
            "116:\tlearn: 0.1887903\ttotal: 7.23s\tremaining: 54.6s\n",
            "117:\tlearn: 0.1868891\ttotal: 7.29s\tremaining: 54.5s\n",
            "118:\tlearn: 0.1860333\ttotal: 7.38s\tremaining: 54.6s\n",
            "119:\tlearn: 0.1847621\ttotal: 7.43s\tremaining: 54.5s\n",
            "120:\tlearn: 0.1836539\ttotal: 7.5s\tremaining: 54.5s\n",
            "121:\tlearn: 0.1819683\ttotal: 7.56s\tremaining: 54.4s\n",
            "122:\tlearn: 0.1806544\ttotal: 7.6s\tremaining: 54.2s\n",
            "123:\tlearn: 0.1799492\ttotal: 7.7s\tremaining: 54.4s\n",
            "124:\tlearn: 0.1788621\ttotal: 7.8s\tremaining: 54.6s\n",
            "125:\tlearn: 0.1780138\ttotal: 7.84s\tremaining: 54.4s\n",
            "126:\tlearn: 0.1769034\ttotal: 7.89s\tremaining: 54.2s\n",
            "127:\tlearn: 0.1755409\ttotal: 7.93s\tremaining: 54s\n",
            "128:\tlearn: 0.1747135\ttotal: 7.99s\tremaining: 53.9s\n",
            "129:\tlearn: 0.1735129\ttotal: 8.04s\tremaining: 53.8s\n",
            "130:\tlearn: 0.1717475\ttotal: 8.12s\tremaining: 53.9s\n",
            "131:\tlearn: 0.1708554\ttotal: 8.19s\tremaining: 53.8s\n",
            "132:\tlearn: 0.1699565\ttotal: 8.24s\tremaining: 53.7s\n",
            "133:\tlearn: 0.1690206\ttotal: 8.31s\tremaining: 53.7s\n",
            "134:\tlearn: 0.1685235\ttotal: 8.38s\tremaining: 53.7s\n",
            "135:\tlearn: 0.1678544\ttotal: 8.46s\tremaining: 53.8s\n",
            "136:\tlearn: 0.1671513\ttotal: 8.5s\tremaining: 53.6s\n",
            "137:\tlearn: 0.1659896\ttotal: 8.59s\tremaining: 53.6s\n",
            "138:\tlearn: 0.1651701\ttotal: 8.69s\tremaining: 53.9s\n",
            "139:\tlearn: 0.1644083\ttotal: 8.79s\tremaining: 54s\n",
            "140:\tlearn: 0.1633626\ttotal: 8.89s\tremaining: 54.1s\n",
            "141:\tlearn: 0.1628158\ttotal: 8.97s\tremaining: 54.2s\n",
            "142:\tlearn: 0.1618338\ttotal: 9.07s\tremaining: 54.3s\n",
            "143:\tlearn: 0.1611457\ttotal: 9.17s\tremaining: 54.5s\n",
            "144:\tlearn: 0.1605723\ttotal: 9.25s\tremaining: 54.5s\n",
            "145:\tlearn: 0.1591413\ttotal: 9.35s\tremaining: 54.7s\n",
            "146:\tlearn: 0.1580314\ttotal: 9.46s\tremaining: 54.9s\n",
            "147:\tlearn: 0.1571600\ttotal: 9.52s\tremaining: 54.8s\n",
            "148:\tlearn: 0.1562363\ttotal: 9.63s\tremaining: 55s\n",
            "149:\tlearn: 0.1556541\ttotal: 9.72s\tremaining: 55.1s\n",
            "150:\tlearn: 0.1549037\ttotal: 9.81s\tremaining: 55.2s\n",
            "151:\tlearn: 0.1542719\ttotal: 9.88s\tremaining: 55.1s\n",
            "152:\tlearn: 0.1536540\ttotal: 9.93s\tremaining: 54.9s\n",
            "153:\tlearn: 0.1527407\ttotal: 10s\tremaining: 55s\n",
            "154:\tlearn: 0.1519826\ttotal: 10.1s\tremaining: 55s\n",
            "155:\tlearn: 0.1513093\ttotal: 10.2s\tremaining: 55s\n",
            "156:\tlearn: 0.1505349\ttotal: 10.3s\tremaining: 55.2s\n",
            "157:\tlearn: 0.1498628\ttotal: 10.4s\tremaining: 55.3s\n",
            "158:\tlearn: 0.1489728\ttotal: 10.5s\tremaining: 55.5s\n",
            "159:\tlearn: 0.1481000\ttotal: 10.6s\tremaining: 55.6s\n",
            "160:\tlearn: 0.1473430\ttotal: 10.7s\tremaining: 55.5s\n",
            "161:\tlearn: 0.1466378\ttotal: 10.7s\tremaining: 55.4s\n",
            "162:\tlearn: 0.1460479\ttotal: 10.8s\tremaining: 55.3s\n",
            "163:\tlearn: 0.1455275\ttotal: 10.8s\tremaining: 55.2s\n",
            "164:\tlearn: 0.1449365\ttotal: 10.9s\tremaining: 55s\n",
            "165:\tlearn: 0.1439712\ttotal: 10.9s\tremaining: 54.9s\n",
            "166:\tlearn: 0.1432015\ttotal: 11s\tremaining: 54.8s\n",
            "167:\tlearn: 0.1425996\ttotal: 11s\tremaining: 54.6s\n",
            "168:\tlearn: 0.1419977\ttotal: 11.1s\tremaining: 54.6s\n",
            "169:\tlearn: 0.1412961\ttotal: 11.1s\tremaining: 54.4s\n",
            "170:\tlearn: 0.1406599\ttotal: 11.2s\tremaining: 54.3s\n",
            "171:\tlearn: 0.1401003\ttotal: 11.3s\tremaining: 54.2s\n",
            "172:\tlearn: 0.1395329\ttotal: 11.3s\tremaining: 54.1s\n",
            "173:\tlearn: 0.1387863\ttotal: 11.4s\tremaining: 54s\n",
            "174:\tlearn: 0.1380932\ttotal: 11.4s\tremaining: 53.8s\n",
            "175:\tlearn: 0.1371749\ttotal: 11.5s\tremaining: 53.7s\n",
            "176:\tlearn: 0.1364871\ttotal: 11.5s\tremaining: 53.5s\n",
            "177:\tlearn: 0.1360343\ttotal: 11.6s\tremaining: 53.4s\n",
            "178:\tlearn: 0.1352974\ttotal: 11.6s\tremaining: 53.1s\n",
            "179:\tlearn: 0.1345932\ttotal: 11.6s\tremaining: 52.9s\n",
            "180:\tlearn: 0.1340329\ttotal: 11.6s\tremaining: 52.7s\n",
            "181:\tlearn: 0.1335569\ttotal: 11.7s\tremaining: 52.6s\n",
            "182:\tlearn: 0.1324631\ttotal: 11.7s\tremaining: 52.4s\n",
            "183:\tlearn: 0.1317575\ttotal: 11.8s\tremaining: 52.3s\n",
            "184:\tlearn: 0.1311888\ttotal: 11.8s\tremaining: 52.2s\n",
            "185:\tlearn: 0.1308135\ttotal: 11.9s\tremaining: 52s\n",
            "186:\tlearn: 0.1302432\ttotal: 11.9s\tremaining: 51.9s\n",
            "187:\tlearn: 0.1297638\ttotal: 12s\tremaining: 51.8s\n",
            "188:\tlearn: 0.1292138\ttotal: 12.1s\tremaining: 51.8s\n",
            "189:\tlearn: 0.1287481\ttotal: 12.1s\tremaining: 51.6s\n",
            "190:\tlearn: 0.1283651\ttotal: 12.2s\tremaining: 51.5s\n",
            "191:\tlearn: 0.1276737\ttotal: 12.2s\tremaining: 51.4s\n",
            "192:\tlearn: 0.1268485\ttotal: 12.3s\tremaining: 51.3s\n",
            "193:\tlearn: 0.1262810\ttotal: 12.3s\tremaining: 51.1s\n",
            "194:\tlearn: 0.1251794\ttotal: 12.4s\tremaining: 51.1s\n",
            "195:\tlearn: 0.1247976\ttotal: 12.4s\tremaining: 51.1s\n",
            "196:\tlearn: 0.1242280\ttotal: 12.5s\tremaining: 51s\n",
            "197:\tlearn: 0.1238642\ttotal: 12.6s\tremaining: 51s\n",
            "198:\tlearn: 0.1233500\ttotal: 12.6s\tremaining: 50.9s\n",
            "199:\tlearn: 0.1228191\ttotal: 12.7s\tremaining: 50.7s\n",
            "200:\tlearn: 0.1222307\ttotal: 12.7s\tremaining: 50.6s\n",
            "201:\tlearn: 0.1216517\ttotal: 12.8s\tremaining: 50.4s\n",
            "202:\tlearn: 0.1210001\ttotal: 12.8s\tremaining: 50.3s\n",
            "203:\tlearn: 0.1206626\ttotal: 12.9s\tremaining: 50.2s\n",
            "204:\tlearn: 0.1203225\ttotal: 12.9s\tremaining: 50s\n",
            "205:\tlearn: 0.1198608\ttotal: 12.9s\tremaining: 49.8s\n",
            "206:\tlearn: 0.1191292\ttotal: 13s\tremaining: 49.7s\n",
            "207:\tlearn: 0.1186016\ttotal: 13s\tremaining: 49.5s\n",
            "208:\tlearn: 0.1182060\ttotal: 13.1s\tremaining: 49.4s\n",
            "209:\tlearn: 0.1179915\ttotal: 13.1s\tremaining: 49.3s\n",
            "210:\tlearn: 0.1174849\ttotal: 13.2s\tremaining: 49.2s\n",
            "211:\tlearn: 0.1170825\ttotal: 13.2s\tremaining: 49.2s\n",
            "212:\tlearn: 0.1167616\ttotal: 13.3s\tremaining: 49.1s\n",
            "213:\tlearn: 0.1162446\ttotal: 13.3s\tremaining: 49s\n",
            "214:\tlearn: 0.1157821\ttotal: 13.4s\tremaining: 48.9s\n",
            "215:\tlearn: 0.1151754\ttotal: 13.4s\tremaining: 48.8s\n",
            "216:\tlearn: 0.1146644\ttotal: 13.5s\tremaining: 48.7s\n",
            "217:\tlearn: 0.1142588\ttotal: 13.6s\tremaining: 48.6s\n",
            "218:\tlearn: 0.1135680\ttotal: 13.6s\tremaining: 48.5s\n",
            "219:\tlearn: 0.1131555\ttotal: 13.7s\tremaining: 48.5s\n",
            "220:\tlearn: 0.1126546\ttotal: 13.7s\tremaining: 48.4s\n",
            "221:\tlearn: 0.1120365\ttotal: 13.8s\tremaining: 48.2s\n",
            "222:\tlearn: 0.1114132\ttotal: 13.8s\tremaining: 48.1s\n",
            "223:\tlearn: 0.1108453\ttotal: 13.9s\tremaining: 48s\n",
            "224:\tlearn: 0.1104149\ttotal: 13.9s\tremaining: 47.9s\n",
            "225:\tlearn: 0.1099535\ttotal: 13.9s\tremaining: 47.8s\n",
            "226:\tlearn: 0.1096361\ttotal: 14s\tremaining: 47.6s\n",
            "227:\tlearn: 0.1091704\ttotal: 14s\tremaining: 47.5s\n",
            "228:\tlearn: 0.1086169\ttotal: 14.1s\tremaining: 47.4s\n",
            "229:\tlearn: 0.1081346\ttotal: 14.1s\tremaining: 47.4s\n",
            "230:\tlearn: 0.1077653\ttotal: 14.2s\tremaining: 47.2s\n",
            "231:\tlearn: 0.1073155\ttotal: 14.2s\tremaining: 47.1s\n",
            "232:\tlearn: 0.1067054\ttotal: 14.3s\tremaining: 47s\n",
            "233:\tlearn: 0.1063659\ttotal: 14.4s\tremaining: 47.1s\n",
            "234:\tlearn: 0.1058857\ttotal: 14.4s\tremaining: 47s\n",
            "235:\tlearn: 0.1055838\ttotal: 14.5s\tremaining: 46.9s\n",
            "236:\tlearn: 0.1053180\ttotal: 14.5s\tremaining: 46.8s\n",
            "237:\tlearn: 0.1048589\ttotal: 14.6s\tremaining: 46.7s\n",
            "238:\tlearn: 0.1045272\ttotal: 14.7s\tremaining: 46.7s\n",
            "239:\tlearn: 0.1040704\ttotal: 14.7s\tremaining: 46.7s\n",
            "240:\tlearn: 0.1037995\ttotal: 14.8s\tremaining: 46.6s\n",
            "241:\tlearn: 0.1033539\ttotal: 14.8s\tremaining: 46.5s\n",
            "242:\tlearn: 0.1028797\ttotal: 14.9s\tremaining: 46.4s\n",
            "243:\tlearn: 0.1026042\ttotal: 14.9s\tremaining: 46.3s\n",
            "244:\tlearn: 0.1021716\ttotal: 15s\tremaining: 46.1s\n",
            "245:\tlearn: 0.1017706\ttotal: 15s\tremaining: 46.1s\n",
            "246:\tlearn: 0.1013759\ttotal: 15.1s\tremaining: 46s\n",
            "247:\tlearn: 0.1011114\ttotal: 15.2s\tremaining: 46s\n",
            "248:\tlearn: 0.1008008\ttotal: 15.2s\tremaining: 46s\n",
            "249:\tlearn: 0.1004180\ttotal: 15.3s\tremaining: 45.9s\n",
            "250:\tlearn: 0.1000110\ttotal: 15.4s\tremaining: 45.8s\n",
            "251:\tlearn: 0.0994798\ttotal: 15.4s\tremaining: 45.7s\n",
            "252:\tlearn: 0.0991876\ttotal: 15.5s\tremaining: 45.7s\n",
            "253:\tlearn: 0.0988481\ttotal: 15.6s\tremaining: 45.8s\n",
            "254:\tlearn: 0.0985397\ttotal: 15.7s\tremaining: 45.8s\n",
            "255:\tlearn: 0.0982679\ttotal: 15.8s\tremaining: 45.8s\n",
            "256:\tlearn: 0.0979872\ttotal: 15.8s\tremaining: 45.7s\n",
            "257:\tlearn: 0.0973932\ttotal: 15.8s\tremaining: 45.5s\n",
            "258:\tlearn: 0.0970994\ttotal: 15.9s\tremaining: 45.4s\n",
            "259:\tlearn: 0.0965984\ttotal: 15.9s\tremaining: 45.2s\n",
            "260:\tlearn: 0.0962781\ttotal: 15.9s\tremaining: 45s\n",
            "261:\tlearn: 0.0960764\ttotal: 15.9s\tremaining: 44.9s\n",
            "262:\tlearn: 0.0958651\ttotal: 16s\tremaining: 44.7s\n",
            "263:\tlearn: 0.0954406\ttotal: 16s\tremaining: 44.5s\n",
            "264:\tlearn: 0.0950108\ttotal: 16s\tremaining: 44.4s\n",
            "265:\tlearn: 0.0946630\ttotal: 16s\tremaining: 44.2s\n",
            "266:\tlearn: 0.0941982\ttotal: 16s\tremaining: 44s\n",
            "267:\tlearn: 0.0936982\ttotal: 16.1s\tremaining: 43.9s\n",
            "268:\tlearn: 0.0934173\ttotal: 16.1s\tremaining: 43.7s\n",
            "269:\tlearn: 0.0932191\ttotal: 16.1s\tremaining: 43.6s\n",
            "270:\tlearn: 0.0928822\ttotal: 16.1s\tremaining: 43.4s\n",
            "271:\tlearn: 0.0925370\ttotal: 16.2s\tremaining: 43.2s\n",
            "272:\tlearn: 0.0918414\ttotal: 16.2s\tremaining: 43.1s\n",
            "273:\tlearn: 0.0915646\ttotal: 16.2s\tremaining: 42.9s\n",
            "274:\tlearn: 0.0911812\ttotal: 16.2s\tremaining: 42.8s\n",
            "275:\tlearn: 0.0909205\ttotal: 16.2s\tremaining: 42.6s\n",
            "276:\tlearn: 0.0905200\ttotal: 16.3s\tremaining: 42.5s\n",
            "277:\tlearn: 0.0901549\ttotal: 16.3s\tremaining: 42.3s\n",
            "278:\tlearn: 0.0898747\ttotal: 16.3s\tremaining: 42.1s\n",
            "279:\tlearn: 0.0894327\ttotal: 16.3s\tremaining: 42s\n",
            "280:\tlearn: 0.0892184\ttotal: 16.4s\tremaining: 41.8s\n",
            "281:\tlearn: 0.0889086\ttotal: 16.4s\tremaining: 41.7s\n",
            "282:\tlearn: 0.0885739\ttotal: 16.4s\tremaining: 41.5s\n",
            "283:\tlearn: 0.0879689\ttotal: 16.4s\tremaining: 41.4s\n",
            "284:\tlearn: 0.0877502\ttotal: 16.4s\tremaining: 41.2s\n",
            "285:\tlearn: 0.0873342\ttotal: 16.5s\tremaining: 41.1s\n",
            "286:\tlearn: 0.0870125\ttotal: 16.5s\tremaining: 41s\n",
            "287:\tlearn: 0.0866301\ttotal: 16.5s\tremaining: 40.8s\n",
            "288:\tlearn: 0.0859020\ttotal: 16.5s\tremaining: 40.7s\n",
            "289:\tlearn: 0.0856397\ttotal: 16.6s\tremaining: 40.6s\n",
            "290:\tlearn: 0.0850570\ttotal: 16.6s\tremaining: 40.4s\n",
            "291:\tlearn: 0.0847555\ttotal: 16.6s\tremaining: 40.3s\n",
            "292:\tlearn: 0.0844902\ttotal: 16.6s\tremaining: 40.2s\n",
            "293:\tlearn: 0.0843482\ttotal: 16.7s\tremaining: 40s\n",
            "294:\tlearn: 0.0842471\ttotal: 16.7s\tremaining: 39.9s\n",
            "295:\tlearn: 0.0840965\ttotal: 16.7s\tremaining: 39.8s\n",
            "296:\tlearn: 0.0838353\ttotal: 16.7s\tremaining: 39.6s\n",
            "297:\tlearn: 0.0836711\ttotal: 16.8s\tremaining: 39.5s\n",
            "298:\tlearn: 0.0835282\ttotal: 16.8s\tremaining: 39.3s\n",
            "299:\tlearn: 0.0832892\ttotal: 16.8s\tremaining: 39.2s\n",
            "300:\tlearn: 0.0829893\ttotal: 16.8s\tremaining: 39.1s\n",
            "301:\tlearn: 0.0826781\ttotal: 16.8s\tremaining: 38.9s\n",
            "302:\tlearn: 0.0824332\ttotal: 16.9s\tremaining: 38.8s\n",
            "303:\tlearn: 0.0821298\ttotal: 16.9s\tremaining: 38.7s\n",
            "304:\tlearn: 0.0817964\ttotal: 16.9s\tremaining: 38.5s\n",
            "305:\tlearn: 0.0815205\ttotal: 16.9s\tremaining: 38.4s\n",
            "306:\tlearn: 0.0814082\ttotal: 16.9s\tremaining: 38.3s\n",
            "307:\tlearn: 0.0810802\ttotal: 17s\tremaining: 38.1s\n",
            "308:\tlearn: 0.0808374\ttotal: 17s\tremaining: 38s\n",
            "309:\tlearn: 0.0806685\ttotal: 17s\tremaining: 37.9s\n",
            "310:\tlearn: 0.0806032\ttotal: 17s\tremaining: 37.8s\n",
            "311:\tlearn: 0.0805005\ttotal: 17.1s\tremaining: 37.6s\n",
            "312:\tlearn: 0.0801213\ttotal: 17.1s\tremaining: 37.5s\n",
            "313:\tlearn: 0.0797696\ttotal: 17.1s\tremaining: 37.4s\n",
            "314:\tlearn: 0.0795991\ttotal: 17.1s\tremaining: 37.3s\n",
            "315:\tlearn: 0.0792366\ttotal: 17.2s\tremaining: 37.1s\n",
            "316:\tlearn: 0.0789259\ttotal: 17.2s\tremaining: 37s\n",
            "317:\tlearn: 0.0786566\ttotal: 17.2s\tremaining: 36.9s\n",
            "318:\tlearn: 0.0783571\ttotal: 17.2s\tremaining: 36.8s\n",
            "319:\tlearn: 0.0781988\ttotal: 17.2s\tremaining: 36.6s\n",
            "320:\tlearn: 0.0780016\ttotal: 17.3s\tremaining: 36.5s\n",
            "321:\tlearn: 0.0778645\ttotal: 17.3s\tremaining: 36.4s\n",
            "322:\tlearn: 0.0773153\ttotal: 17.3s\tremaining: 36.3s\n",
            "323:\tlearn: 0.0772324\ttotal: 17.3s\tremaining: 36.1s\n",
            "324:\tlearn: 0.0771522\ttotal: 17.3s\tremaining: 36s\n",
            "325:\tlearn: 0.0769093\ttotal: 17.4s\tremaining: 35.9s\n",
            "326:\tlearn: 0.0765624\ttotal: 17.4s\tremaining: 35.8s\n",
            "327:\tlearn: 0.0764775\ttotal: 17.4s\tremaining: 35.7s\n",
            "328:\tlearn: 0.0762988\ttotal: 17.4s\tremaining: 35.6s\n",
            "329:\tlearn: 0.0758448\ttotal: 17.5s\tremaining: 35.4s\n",
            "330:\tlearn: 0.0755213\ttotal: 17.5s\tremaining: 35.3s\n",
            "331:\tlearn: 0.0752144\ttotal: 17.5s\tremaining: 35.2s\n",
            "332:\tlearn: 0.0750917\ttotal: 17.5s\tremaining: 35.1s\n",
            "333:\tlearn: 0.0748373\ttotal: 17.5s\tremaining: 35s\n",
            "334:\tlearn: 0.0747834\ttotal: 17.6s\tremaining: 34.9s\n",
            "335:\tlearn: 0.0746179\ttotal: 17.6s\tremaining: 34.7s\n",
            "336:\tlearn: 0.0745540\ttotal: 17.6s\tremaining: 34.7s\n",
            "337:\tlearn: 0.0745088\ttotal: 17.7s\tremaining: 34.6s\n",
            "338:\tlearn: 0.0742493\ttotal: 17.7s\tremaining: 34.5s\n",
            "339:\tlearn: 0.0740167\ttotal: 17.7s\tremaining: 34.4s\n",
            "340:\tlearn: 0.0738826\ttotal: 17.7s\tremaining: 34.2s\n",
            "341:\tlearn: 0.0736402\ttotal: 17.7s\tremaining: 34.1s\n",
            "342:\tlearn: 0.0733863\ttotal: 17.8s\tremaining: 34s\n",
            "343:\tlearn: 0.0732982\ttotal: 17.8s\tremaining: 34s\n",
            "344:\tlearn: 0.0731592\ttotal: 17.8s\tremaining: 33.9s\n",
            "345:\tlearn: 0.0729377\ttotal: 17.9s\tremaining: 33.7s\n",
            "346:\tlearn: 0.0729000\ttotal: 17.9s\tremaining: 33.6s\n",
            "347:\tlearn: 0.0725604\ttotal: 17.9s\tremaining: 33.5s\n",
            "348:\tlearn: 0.0722969\ttotal: 17.9s\tremaining: 33.4s\n",
            "349:\tlearn: 0.0719395\ttotal: 17.9s\tremaining: 33.3s\n",
            "350:\tlearn: 0.0716748\ttotal: 18s\tremaining: 33.2s\n",
            "351:\tlearn: 0.0716270\ttotal: 18s\tremaining: 33.1s\n",
            "352:\tlearn: 0.0715730\ttotal: 18s\tremaining: 33s\n",
            "353:\tlearn: 0.0713408\ttotal: 18s\tremaining: 32.9s\n",
            "354:\tlearn: 0.0710840\ttotal: 18s\tremaining: 32.8s\n",
            "355:\tlearn: 0.0710251\ttotal: 18.1s\tremaining: 32.7s\n",
            "356:\tlearn: 0.0707964\ttotal: 18.1s\tremaining: 32.6s\n",
            "357:\tlearn: 0.0706609\ttotal: 18.1s\tremaining: 32.5s\n",
            "358:\tlearn: 0.0704559\ttotal: 18.1s\tremaining: 32.4s\n",
            "359:\tlearn: 0.0702014\ttotal: 18.2s\tremaining: 32.3s\n",
            "360:\tlearn: 0.0700810\ttotal: 18.2s\tremaining: 32.2s\n",
            "361:\tlearn: 0.0697853\ttotal: 18.2s\tremaining: 32.1s\n",
            "362:\tlearn: 0.0696338\ttotal: 18.2s\tremaining: 32s\n",
            "363:\tlearn: 0.0695837\ttotal: 18.2s\tremaining: 31.9s\n",
            "364:\tlearn: 0.0694563\ttotal: 18.3s\tremaining: 31.8s\n",
            "365:\tlearn: 0.0693176\ttotal: 18.3s\tremaining: 31.7s\n",
            "366:\tlearn: 0.0691982\ttotal: 18.3s\tremaining: 31.6s\n",
            "367:\tlearn: 0.0689901\ttotal: 18.3s\tremaining: 31.5s\n",
            "368:\tlearn: 0.0689404\ttotal: 18.4s\tremaining: 31.4s\n",
            "369:\tlearn: 0.0686718\ttotal: 18.4s\tremaining: 31.3s\n",
            "370:\tlearn: 0.0686398\ttotal: 18.4s\tremaining: 31.2s\n",
            "371:\tlearn: 0.0685352\ttotal: 18.4s\tremaining: 31.1s\n",
            "372:\tlearn: 0.0682609\ttotal: 18.4s\tremaining: 31s\n",
            "373:\tlearn: 0.0681360\ttotal: 18.5s\tremaining: 30.9s\n",
            "374:\tlearn: 0.0680856\ttotal: 18.5s\tremaining: 30.8s\n",
            "375:\tlearn: 0.0677930\ttotal: 18.5s\tremaining: 30.7s\n",
            "376:\tlearn: 0.0673247\ttotal: 18.5s\tremaining: 30.6s\n",
            "377:\tlearn: 0.0670497\ttotal: 18.6s\tremaining: 30.5s\n",
            "378:\tlearn: 0.0668979\ttotal: 18.6s\tremaining: 30.5s\n",
            "379:\tlearn: 0.0666961\ttotal: 18.6s\tremaining: 30.4s\n",
            "380:\tlearn: 0.0664830\ttotal: 18.6s\tremaining: 30.3s\n",
            "381:\tlearn: 0.0663183\ttotal: 18.7s\tremaining: 30.2s\n",
            "382:\tlearn: 0.0660033\ttotal: 18.7s\tremaining: 30.1s\n",
            "383:\tlearn: 0.0658402\ttotal: 18.7s\tremaining: 30s\n",
            "384:\tlearn: 0.0656218\ttotal: 18.7s\tremaining: 29.9s\n",
            "385:\tlearn: 0.0655033\ttotal: 18.8s\tremaining: 29.8s\n",
            "386:\tlearn: 0.0652460\ttotal: 18.8s\tremaining: 29.8s\n",
            "387:\tlearn: 0.0650238\ttotal: 18.8s\tremaining: 29.7s\n",
            "388:\tlearn: 0.0649802\ttotal: 18.8s\tremaining: 29.6s\n",
            "389:\tlearn: 0.0647781\ttotal: 18.8s\tremaining: 29.5s\n",
            "390:\tlearn: 0.0645957\ttotal: 18.9s\tremaining: 29.4s\n",
            "391:\tlearn: 0.0644528\ttotal: 18.9s\tremaining: 29.3s\n",
            "392:\tlearn: 0.0643687\ttotal: 18.9s\tremaining: 29.2s\n",
            "393:\tlearn: 0.0641889\ttotal: 18.9s\tremaining: 29.1s\n",
            "394:\tlearn: 0.0639800\ttotal: 19s\tremaining: 29s\n",
            "395:\tlearn: 0.0636870\ttotal: 19s\tremaining: 28.9s\n",
            "396:\tlearn: 0.0635881\ttotal: 19s\tremaining: 28.9s\n",
            "397:\tlearn: 0.0634859\ttotal: 19s\tremaining: 28.8s\n",
            "398:\tlearn: 0.0634432\ttotal: 19s\tremaining: 28.7s\n",
            "399:\tlearn: 0.0633020\ttotal: 19.1s\tremaining: 28.6s\n",
            "400:\tlearn: 0.0632535\ttotal: 19.1s\tremaining: 28.5s\n",
            "401:\tlearn: 0.0631136\ttotal: 19.1s\tremaining: 28.4s\n",
            "402:\tlearn: 0.0629101\ttotal: 19.1s\tremaining: 28.3s\n",
            "403:\tlearn: 0.0627823\ttotal: 19.2s\tremaining: 28.3s\n",
            "404:\tlearn: 0.0624723\ttotal: 19.2s\tremaining: 28.2s\n",
            "405:\tlearn: 0.0622398\ttotal: 19.2s\tremaining: 28.1s\n",
            "406:\tlearn: 0.0621810\ttotal: 19.2s\tremaining: 28s\n",
            "407:\tlearn: 0.0621457\ttotal: 19.2s\tremaining: 27.9s\n",
            "408:\tlearn: 0.0618201\ttotal: 19.3s\tremaining: 27.8s\n",
            "409:\tlearn: 0.0616207\ttotal: 19.3s\tremaining: 27.8s\n",
            "410:\tlearn: 0.0614404\ttotal: 19.3s\tremaining: 27.7s\n",
            "411:\tlearn: 0.0613336\ttotal: 19.3s\tremaining: 27.6s\n",
            "412:\tlearn: 0.0611772\ttotal: 19.4s\tremaining: 27.5s\n",
            "413:\tlearn: 0.0609310\ttotal: 19.4s\tremaining: 27.4s\n",
            "414:\tlearn: 0.0606623\ttotal: 19.4s\tremaining: 27.4s\n",
            "415:\tlearn: 0.0606263\ttotal: 19.4s\tremaining: 27.3s\n",
            "416:\tlearn: 0.0605699\ttotal: 19.5s\tremaining: 27.2s\n",
            "417:\tlearn: 0.0602689\ttotal: 19.5s\tremaining: 27.1s\n",
            "418:\tlearn: 0.0602210\ttotal: 19.5s\tremaining: 27s\n",
            "419:\tlearn: 0.0598994\ttotal: 19.5s\tremaining: 27s\n",
            "420:\tlearn: 0.0598475\ttotal: 19.6s\tremaining: 26.9s\n",
            "421:\tlearn: 0.0597408\ttotal: 19.6s\tremaining: 26.8s\n",
            "422:\tlearn: 0.0596095\ttotal: 19.6s\tremaining: 26.7s\n",
            "423:\tlearn: 0.0593908\ttotal: 19.6s\tremaining: 26.6s\n",
            "424:\tlearn: 0.0592344\ttotal: 19.6s\tremaining: 26.6s\n",
            "425:\tlearn: 0.0590494\ttotal: 19.7s\tremaining: 26.5s\n",
            "426:\tlearn: 0.0588447\ttotal: 19.7s\tremaining: 26.4s\n",
            "427:\tlearn: 0.0587191\ttotal: 19.7s\tremaining: 26.4s\n",
            "428:\tlearn: 0.0585765\ttotal: 19.7s\tremaining: 26.3s\n",
            "429:\tlearn: 0.0583136\ttotal: 19.8s\tremaining: 26.2s\n",
            "430:\tlearn: 0.0581177\ttotal: 19.8s\tremaining: 26.1s\n",
            "431:\tlearn: 0.0580753\ttotal: 19.8s\tremaining: 26.1s\n",
            "432:\tlearn: 0.0578447\ttotal: 19.8s\tremaining: 26s\n",
            "433:\tlearn: 0.0577897\ttotal: 19.9s\tremaining: 25.9s\n",
            "434:\tlearn: 0.0575517\ttotal: 19.9s\tremaining: 25.8s\n",
            "435:\tlearn: 0.0573465\ttotal: 19.9s\tremaining: 25.7s\n",
            "436:\tlearn: 0.0571637\ttotal: 19.9s\tremaining: 25.7s\n",
            "437:\tlearn: 0.0570478\ttotal: 19.9s\tremaining: 25.6s\n",
            "438:\tlearn: 0.0569042\ttotal: 20s\tremaining: 25.5s\n",
            "439:\tlearn: 0.0567605\ttotal: 20s\tremaining: 25.4s\n",
            "440:\tlearn: 0.0564753\ttotal: 20s\tremaining: 25.4s\n",
            "441:\tlearn: 0.0562574\ttotal: 20s\tremaining: 25.3s\n",
            "442:\tlearn: 0.0562251\ttotal: 20.1s\tremaining: 25.2s\n",
            "443:\tlearn: 0.0562021\ttotal: 20.1s\tremaining: 25.1s\n",
            "444:\tlearn: 0.0561052\ttotal: 20.1s\tremaining: 25.1s\n",
            "445:\tlearn: 0.0559168\ttotal: 20.1s\tremaining: 25s\n",
            "446:\tlearn: 0.0556570\ttotal: 20.1s\tremaining: 24.9s\n",
            "447:\tlearn: 0.0555133\ttotal: 20.2s\tremaining: 24.8s\n",
            "448:\tlearn: 0.0554629\ttotal: 20.2s\tremaining: 24.8s\n",
            "449:\tlearn: 0.0553093\ttotal: 20.2s\tremaining: 24.7s\n",
            "450:\tlearn: 0.0552113\ttotal: 20.2s\tremaining: 24.6s\n",
            "451:\tlearn: 0.0551904\ttotal: 20.2s\tremaining: 24.5s\n",
            "452:\tlearn: 0.0550678\ttotal: 20.3s\tremaining: 24.5s\n",
            "453:\tlearn: 0.0550415\ttotal: 20.3s\tremaining: 24.4s\n",
            "454:\tlearn: 0.0550014\ttotal: 20.3s\tremaining: 24.3s\n",
            "455:\tlearn: 0.0549702\ttotal: 20.3s\tremaining: 24.3s\n",
            "456:\tlearn: 0.0549370\ttotal: 20.4s\tremaining: 24.2s\n",
            "457:\tlearn: 0.0549156\ttotal: 20.4s\tremaining: 24.1s\n",
            "458:\tlearn: 0.0547706\ttotal: 20.4s\tremaining: 24s\n",
            "459:\tlearn: 0.0546001\ttotal: 20.4s\tremaining: 24s\n",
            "460:\tlearn: 0.0544666\ttotal: 20.4s\tremaining: 23.9s\n",
            "461:\tlearn: 0.0544356\ttotal: 20.5s\tremaining: 23.8s\n",
            "462:\tlearn: 0.0544148\ttotal: 20.5s\tremaining: 23.8s\n",
            "463:\tlearn: 0.0542364\ttotal: 20.5s\tremaining: 23.7s\n",
            "464:\tlearn: 0.0541264\ttotal: 20.5s\tremaining: 23.6s\n",
            "465:\tlearn: 0.0539919\ttotal: 20.6s\tremaining: 23.5s\n",
            "466:\tlearn: 0.0537867\ttotal: 20.6s\tremaining: 23.5s\n",
            "467:\tlearn: 0.0536824\ttotal: 20.6s\tremaining: 23.4s\n",
            "468:\tlearn: 0.0535464\ttotal: 20.6s\tremaining: 23.3s\n",
            "469:\tlearn: 0.0535277\ttotal: 20.6s\tremaining: 23.3s\n",
            "470:\tlearn: 0.0535087\ttotal: 20.7s\tremaining: 23.2s\n",
            "471:\tlearn: 0.0533210\ttotal: 20.7s\tremaining: 23.1s\n",
            "472:\tlearn: 0.0531095\ttotal: 20.7s\tremaining: 23.1s\n",
            "473:\tlearn: 0.0529323\ttotal: 20.7s\tremaining: 23s\n",
            "474:\tlearn: 0.0528878\ttotal: 20.8s\tremaining: 23s\n",
            "475:\tlearn: 0.0528443\ttotal: 20.8s\tremaining: 22.9s\n",
            "476:\tlearn: 0.0528086\ttotal: 20.8s\tremaining: 22.8s\n",
            "477:\tlearn: 0.0526074\ttotal: 20.8s\tremaining: 22.8s\n",
            "478:\tlearn: 0.0525815\ttotal: 20.9s\tremaining: 22.7s\n",
            "479:\tlearn: 0.0523802\ttotal: 20.9s\tremaining: 22.6s\n",
            "480:\tlearn: 0.0521694\ttotal: 20.9s\tremaining: 22.6s\n",
            "481:\tlearn: 0.0520419\ttotal: 20.9s\tremaining: 22.5s\n",
            "482:\tlearn: 0.0520130\ttotal: 20.9s\tremaining: 22.4s\n",
            "483:\tlearn: 0.0518537\ttotal: 21s\tremaining: 22.4s\n",
            "484:\tlearn: 0.0518241\ttotal: 21s\tremaining: 22.3s\n",
            "485:\tlearn: 0.0517944\ttotal: 21s\tremaining: 22.2s\n",
            "486:\tlearn: 0.0517617\ttotal: 21s\tremaining: 22.2s\n",
            "487:\tlearn: 0.0516833\ttotal: 21.1s\tremaining: 22.1s\n",
            "488:\tlearn: 0.0515537\ttotal: 21.1s\tremaining: 22s\n",
            "489:\tlearn: 0.0515350\ttotal: 21.1s\tremaining: 22s\n",
            "490:\tlearn: 0.0514256\ttotal: 21.2s\tremaining: 21.9s\n",
            "491:\tlearn: 0.0512256\ttotal: 21.2s\tremaining: 21.9s\n",
            "492:\tlearn: 0.0511906\ttotal: 21.2s\tremaining: 21.8s\n",
            "493:\tlearn: 0.0509816\ttotal: 21.3s\tremaining: 21.8s\n",
            "494:\tlearn: 0.0508388\ttotal: 21.3s\tremaining: 21.7s\n",
            "495:\tlearn: 0.0506428\ttotal: 21.3s\tremaining: 21.7s\n",
            "496:\tlearn: 0.0506197\ttotal: 21.4s\tremaining: 21.6s\n",
            "497:\tlearn: 0.0504064\ttotal: 21.4s\tremaining: 21.6s\n",
            "498:\tlearn: 0.0502447\ttotal: 21.5s\tremaining: 21.6s\n",
            "499:\tlearn: 0.0502200\ttotal: 21.5s\tremaining: 21.5s\n",
            "500:\tlearn: 0.0500923\ttotal: 21.5s\tremaining: 21.5s\n",
            "501:\tlearn: 0.0500579\ttotal: 21.6s\tremaining: 21.4s\n",
            "502:\tlearn: 0.0499186\ttotal: 21.6s\tremaining: 21.4s\n",
            "503:\tlearn: 0.0497769\ttotal: 21.7s\tremaining: 21.3s\n",
            "504:\tlearn: 0.0497346\ttotal: 21.7s\tremaining: 21.3s\n",
            "505:\tlearn: 0.0497051\ttotal: 21.8s\tremaining: 21.2s\n",
            "506:\tlearn: 0.0495150\ttotal: 21.8s\tremaining: 21.2s\n",
            "507:\tlearn: 0.0494899\ttotal: 21.9s\tremaining: 21.2s\n",
            "508:\tlearn: 0.0492851\ttotal: 21.9s\tremaining: 21.1s\n",
            "509:\tlearn: 0.0492327\ttotal: 21.9s\tremaining: 21.1s\n",
            "510:\tlearn: 0.0491616\ttotal: 22s\tremaining: 21s\n",
            "511:\tlearn: 0.0490078\ttotal: 22s\tremaining: 21s\n",
            "512:\tlearn: 0.0489555\ttotal: 22.1s\tremaining: 20.9s\n",
            "513:\tlearn: 0.0487587\ttotal: 22.1s\tremaining: 20.9s\n",
            "514:\tlearn: 0.0485656\ttotal: 22.1s\tremaining: 20.8s\n",
            "515:\tlearn: 0.0484503\ttotal: 22.2s\tremaining: 20.8s\n",
            "516:\tlearn: 0.0483650\ttotal: 22.2s\tremaining: 20.8s\n",
            "517:\tlearn: 0.0483433\ttotal: 22.3s\tremaining: 20.7s\n",
            "518:\tlearn: 0.0481624\ttotal: 22.3s\tremaining: 20.7s\n",
            "519:\tlearn: 0.0481313\ttotal: 22.3s\tremaining: 20.6s\n",
            "520:\tlearn: 0.0481006\ttotal: 22.4s\tremaining: 20.6s\n",
            "521:\tlearn: 0.0478907\ttotal: 22.4s\tremaining: 20.5s\n",
            "522:\tlearn: 0.0477701\ttotal: 22.5s\tremaining: 20.5s\n",
            "523:\tlearn: 0.0477515\ttotal: 22.5s\tremaining: 20.5s\n",
            "524:\tlearn: 0.0475670\ttotal: 22.6s\tremaining: 20.4s\n",
            "525:\tlearn: 0.0475331\ttotal: 22.6s\tremaining: 20.4s\n",
            "526:\tlearn: 0.0474577\ttotal: 22.6s\tremaining: 20.3s\n",
            "527:\tlearn: 0.0473552\ttotal: 22.7s\tremaining: 20.3s\n",
            "528:\tlearn: 0.0473338\ttotal: 22.7s\tremaining: 20.2s\n",
            "529:\tlearn: 0.0471567\ttotal: 22.7s\tremaining: 20.2s\n",
            "530:\tlearn: 0.0469989\ttotal: 22.8s\tremaining: 20.1s\n",
            "531:\tlearn: 0.0469834\ttotal: 22.8s\tremaining: 20.1s\n",
            "532:\tlearn: 0.0468618\ttotal: 22.9s\tremaining: 20s\n",
            "533:\tlearn: 0.0468440\ttotal: 22.9s\tremaining: 20s\n",
            "534:\tlearn: 0.0466798\ttotal: 22.9s\tremaining: 19.9s\n",
            "535:\tlearn: 0.0466541\ttotal: 23s\tremaining: 19.9s\n",
            "536:\tlearn: 0.0465174\ttotal: 23s\tremaining: 19.9s\n",
            "537:\tlearn: 0.0463450\ttotal: 23.1s\tremaining: 19.8s\n",
            "538:\tlearn: 0.0461735\ttotal: 23.1s\tremaining: 19.8s\n",
            "539:\tlearn: 0.0461569\ttotal: 23.1s\tremaining: 19.7s\n",
            "540:\tlearn: 0.0460068\ttotal: 23.2s\tremaining: 19.7s\n",
            "541:\tlearn: 0.0459623\ttotal: 23.2s\tremaining: 19.6s\n",
            "542:\tlearn: 0.0459384\ttotal: 23.3s\tremaining: 19.6s\n",
            "543:\tlearn: 0.0457166\ttotal: 23.3s\tremaining: 19.5s\n",
            "544:\tlearn: 0.0455906\ttotal: 23.3s\tremaining: 19.5s\n",
            "545:\tlearn: 0.0455477\ttotal: 23.4s\tremaining: 19.4s\n",
            "546:\tlearn: 0.0455229\ttotal: 23.4s\tremaining: 19.4s\n",
            "547:\tlearn: 0.0455020\ttotal: 23.4s\tremaining: 19.3s\n",
            "548:\tlearn: 0.0453651\ttotal: 23.5s\tremaining: 19.3s\n",
            "549:\tlearn: 0.0453373\ttotal: 23.5s\tremaining: 19.3s\n",
            "550:\tlearn: 0.0451862\ttotal: 23.6s\tremaining: 19.2s\n",
            "551:\tlearn: 0.0451555\ttotal: 23.6s\tremaining: 19.2s\n",
            "552:\tlearn: 0.0451306\ttotal: 23.7s\tremaining: 19.1s\n",
            "553:\tlearn: 0.0450431\ttotal: 23.7s\tremaining: 19.1s\n",
            "554:\tlearn: 0.0450259\ttotal: 23.8s\tremaining: 19.1s\n",
            "555:\tlearn: 0.0448718\ttotal: 23.8s\tremaining: 19s\n",
            "556:\tlearn: 0.0446626\ttotal: 23.8s\tremaining: 19s\n",
            "557:\tlearn: 0.0446136\ttotal: 23.9s\tremaining: 18.9s\n",
            "558:\tlearn: 0.0445736\ttotal: 23.9s\tremaining: 18.9s\n",
            "559:\tlearn: 0.0445387\ttotal: 24s\tremaining: 18.8s\n",
            "560:\tlearn: 0.0443290\ttotal: 24s\tremaining: 18.8s\n",
            "561:\tlearn: 0.0442566\ttotal: 24.1s\tremaining: 18.7s\n",
            "562:\tlearn: 0.0441419\ttotal: 24.1s\tremaining: 18.7s\n",
            "563:\tlearn: 0.0440059\ttotal: 24.1s\tremaining: 18.6s\n",
            "564:\tlearn: 0.0438731\ttotal: 24.2s\tremaining: 18.6s\n",
            "565:\tlearn: 0.0438481\ttotal: 24.2s\tremaining: 18.6s\n",
            "566:\tlearn: 0.0437148\ttotal: 24.3s\tremaining: 18.5s\n",
            "567:\tlearn: 0.0435516\ttotal: 24.3s\tremaining: 18.5s\n",
            "568:\tlearn: 0.0435291\ttotal: 24.3s\tremaining: 18.4s\n",
            "569:\tlearn: 0.0434070\ttotal: 24.4s\tremaining: 18.4s\n",
            "570:\tlearn: 0.0433872\ttotal: 24.4s\tremaining: 18.3s\n",
            "571:\tlearn: 0.0433680\ttotal: 24.5s\tremaining: 18.3s\n",
            "572:\tlearn: 0.0432375\ttotal: 24.5s\tremaining: 18.3s\n",
            "573:\tlearn: 0.0432064\ttotal: 24.5s\tremaining: 18.2s\n",
            "574:\tlearn: 0.0431711\ttotal: 24.6s\tremaining: 18.2s\n",
            "575:\tlearn: 0.0429462\ttotal: 24.6s\tremaining: 18.1s\n",
            "576:\tlearn: 0.0427448\ttotal: 24.7s\tremaining: 18.1s\n",
            "577:\tlearn: 0.0426045\ttotal: 24.7s\tremaining: 18s\n",
            "578:\tlearn: 0.0424483\ttotal: 24.8s\tremaining: 18s\n",
            "579:\tlearn: 0.0424288\ttotal: 24.8s\tremaining: 18s\n",
            "580:\tlearn: 0.0424099\ttotal: 24.8s\tremaining: 17.9s\n",
            "581:\tlearn: 0.0423826\ttotal: 24.9s\tremaining: 17.9s\n",
            "582:\tlearn: 0.0422955\ttotal: 24.9s\tremaining: 17.8s\n",
            "583:\tlearn: 0.0421996\ttotal: 25s\tremaining: 17.8s\n",
            "584:\tlearn: 0.0420567\ttotal: 25s\tremaining: 17.8s\n",
            "585:\tlearn: 0.0419095\ttotal: 25.1s\tremaining: 17.7s\n",
            "586:\tlearn: 0.0418795\ttotal: 25.1s\tremaining: 17.7s\n",
            "587:\tlearn: 0.0416881\ttotal: 25.1s\tremaining: 17.6s\n",
            "588:\tlearn: 0.0415075\ttotal: 25.2s\tremaining: 17.6s\n",
            "589:\tlearn: 0.0413773\ttotal: 25.2s\tremaining: 17.5s\n",
            "590:\tlearn: 0.0412441\ttotal: 25.3s\tremaining: 17.5s\n",
            "591:\tlearn: 0.0412183\ttotal: 25.3s\tremaining: 17.4s\n",
            "592:\tlearn: 0.0410803\ttotal: 25.3s\tremaining: 17.4s\n",
            "593:\tlearn: 0.0409343\ttotal: 25.4s\tremaining: 17.3s\n",
            "594:\tlearn: 0.0409163\ttotal: 25.4s\tremaining: 17.3s\n",
            "595:\tlearn: 0.0408913\ttotal: 25.5s\tremaining: 17.3s\n",
            "596:\tlearn: 0.0406634\ttotal: 25.5s\tremaining: 17.2s\n",
            "597:\tlearn: 0.0405676\ttotal: 25.6s\tremaining: 17.2s\n",
            "598:\tlearn: 0.0403578\ttotal: 25.6s\tremaining: 17.1s\n",
            "599:\tlearn: 0.0402300\ttotal: 25.6s\tremaining: 17.1s\n",
            "600:\tlearn: 0.0401402\ttotal: 25.6s\tremaining: 17s\n",
            "601:\tlearn: 0.0399292\ttotal: 25.6s\tremaining: 17s\n",
            "602:\tlearn: 0.0397250\ttotal: 25.7s\tremaining: 16.9s\n",
            "603:\tlearn: 0.0395447\ttotal: 25.7s\tremaining: 16.8s\n",
            "604:\tlearn: 0.0395263\ttotal: 25.7s\tremaining: 16.8s\n",
            "605:\tlearn: 0.0395020\ttotal: 25.7s\tremaining: 16.7s\n",
            "606:\tlearn: 0.0394125\ttotal: 25.8s\tremaining: 16.7s\n",
            "607:\tlearn: 0.0393905\ttotal: 25.8s\tremaining: 16.6s\n",
            "608:\tlearn: 0.0392822\ttotal: 25.8s\tremaining: 16.6s\n",
            "609:\tlearn: 0.0392436\ttotal: 25.8s\tremaining: 16.5s\n",
            "610:\tlearn: 0.0392226\ttotal: 25.8s\tremaining: 16.4s\n",
            "611:\tlearn: 0.0390979\ttotal: 25.9s\tremaining: 16.4s\n",
            "612:\tlearn: 0.0390213\ttotal: 25.9s\tremaining: 16.3s\n",
            "613:\tlearn: 0.0388780\ttotal: 25.9s\tremaining: 16.3s\n",
            "614:\tlearn: 0.0388642\ttotal: 25.9s\tremaining: 16.2s\n",
            "615:\tlearn: 0.0386942\ttotal: 25.9s\tremaining: 16.2s\n",
            "616:\tlearn: 0.0386717\ttotal: 26s\tremaining: 16.1s\n",
            "617:\tlearn: 0.0386528\ttotal: 26s\tremaining: 16.1s\n",
            "618:\tlearn: 0.0385422\ttotal: 26s\tremaining: 16s\n",
            "619:\tlearn: 0.0383088\ttotal: 26s\tremaining: 16s\n",
            "620:\tlearn: 0.0382429\ttotal: 26.1s\tremaining: 15.9s\n",
            "621:\tlearn: 0.0379604\ttotal: 26.1s\tremaining: 15.9s\n",
            "622:\tlearn: 0.0377960\ttotal: 26.1s\tremaining: 15.8s\n",
            "623:\tlearn: 0.0375101\ttotal: 26.1s\tremaining: 15.8s\n",
            "624:\tlearn: 0.0374602\ttotal: 26.2s\tremaining: 15.7s\n",
            "625:\tlearn: 0.0373183\ttotal: 26.2s\tremaining: 15.6s\n",
            "626:\tlearn: 0.0372349\ttotal: 26.2s\tremaining: 15.6s\n",
            "627:\tlearn: 0.0372138\ttotal: 26.2s\tremaining: 15.5s\n",
            "628:\tlearn: 0.0372004\ttotal: 26.3s\tremaining: 15.5s\n",
            "629:\tlearn: 0.0371716\ttotal: 26.3s\tremaining: 15.4s\n",
            "630:\tlearn: 0.0370206\ttotal: 26.3s\tremaining: 15.4s\n",
            "631:\tlearn: 0.0368612\ttotal: 26.3s\tremaining: 15.3s\n",
            "632:\tlearn: 0.0368441\ttotal: 26.4s\tremaining: 15.3s\n",
            "633:\tlearn: 0.0368314\ttotal: 26.4s\tremaining: 15.2s\n",
            "634:\tlearn: 0.0368104\ttotal: 26.4s\tremaining: 15.2s\n",
            "635:\tlearn: 0.0367638\ttotal: 26.4s\tremaining: 15.1s\n",
            "636:\tlearn: 0.0366786\ttotal: 26.4s\tremaining: 15.1s\n",
            "637:\tlearn: 0.0366624\ttotal: 26.5s\tremaining: 15s\n",
            "638:\tlearn: 0.0365275\ttotal: 26.5s\tremaining: 15s\n",
            "639:\tlearn: 0.0364369\ttotal: 26.5s\tremaining: 14.9s\n",
            "640:\tlearn: 0.0363189\ttotal: 26.5s\tremaining: 14.9s\n",
            "641:\tlearn: 0.0361984\ttotal: 26.5s\tremaining: 14.8s\n",
            "642:\tlearn: 0.0361830\ttotal: 26.6s\tremaining: 14.8s\n",
            "643:\tlearn: 0.0361594\ttotal: 26.6s\tremaining: 14.7s\n",
            "644:\tlearn: 0.0361130\ttotal: 26.6s\tremaining: 14.6s\n",
            "645:\tlearn: 0.0359510\ttotal: 26.6s\tremaining: 14.6s\n",
            "646:\tlearn: 0.0359333\ttotal: 26.7s\tremaining: 14.5s\n",
            "647:\tlearn: 0.0359139\ttotal: 26.7s\tremaining: 14.5s\n",
            "648:\tlearn: 0.0359019\ttotal: 26.7s\tremaining: 14.4s\n",
            "649:\tlearn: 0.0358249\ttotal: 26.7s\tremaining: 14.4s\n",
            "650:\tlearn: 0.0357245\ttotal: 26.7s\tremaining: 14.3s\n",
            "651:\tlearn: 0.0356284\ttotal: 26.8s\tremaining: 14.3s\n",
            "652:\tlearn: 0.0353943\ttotal: 26.8s\tremaining: 14.2s\n",
            "653:\tlearn: 0.0353158\ttotal: 26.8s\tremaining: 14.2s\n",
            "654:\tlearn: 0.0351888\ttotal: 26.8s\tremaining: 14.1s\n",
            "655:\tlearn: 0.0350406\ttotal: 26.9s\tremaining: 14.1s\n",
            "656:\tlearn: 0.0349635\ttotal: 26.9s\tremaining: 14s\n",
            "657:\tlearn: 0.0349451\ttotal: 26.9s\tremaining: 14s\n",
            "658:\tlearn: 0.0349327\ttotal: 26.9s\tremaining: 13.9s\n",
            "659:\tlearn: 0.0349189\ttotal: 26.9s\tremaining: 13.9s\n",
            "660:\tlearn: 0.0348171\ttotal: 27s\tremaining: 13.8s\n",
            "661:\tlearn: 0.0347989\ttotal: 27s\tremaining: 13.8s\n",
            "662:\tlearn: 0.0347858\ttotal: 27s\tremaining: 13.7s\n",
            "663:\tlearn: 0.0346423\ttotal: 27s\tremaining: 13.7s\n",
            "664:\tlearn: 0.0346268\ttotal: 27s\tremaining: 13.6s\n",
            "665:\tlearn: 0.0345058\ttotal: 27.1s\tremaining: 13.6s\n",
            "666:\tlearn: 0.0344490\ttotal: 27.1s\tremaining: 13.5s\n",
            "667:\tlearn: 0.0344353\ttotal: 27.1s\tremaining: 13.5s\n",
            "668:\tlearn: 0.0344188\ttotal: 27.2s\tremaining: 13.4s\n",
            "669:\tlearn: 0.0342666\ttotal: 27.2s\tremaining: 13.4s\n",
            "670:\tlearn: 0.0341225\ttotal: 27.2s\tremaining: 13.3s\n",
            "671:\tlearn: 0.0341029\ttotal: 27.2s\tremaining: 13.3s\n",
            "672:\tlearn: 0.0340890\ttotal: 27.2s\tremaining: 13.2s\n",
            "673:\tlearn: 0.0338915\ttotal: 27.3s\tremaining: 13.2s\n",
            "674:\tlearn: 0.0338756\ttotal: 27.3s\tremaining: 13.1s\n",
            "675:\tlearn: 0.0338581\ttotal: 27.3s\tremaining: 13.1s\n",
            "676:\tlearn: 0.0337067\ttotal: 27.3s\tremaining: 13s\n",
            "677:\tlearn: 0.0335942\ttotal: 27.4s\tremaining: 13s\n",
            "678:\tlearn: 0.0335818\ttotal: 27.4s\tremaining: 12.9s\n",
            "679:\tlearn: 0.0335668\ttotal: 27.4s\tremaining: 12.9s\n",
            "680:\tlearn: 0.0334563\ttotal: 27.4s\tremaining: 12.8s\n",
            "681:\tlearn: 0.0334432\ttotal: 27.4s\tremaining: 12.8s\n",
            "682:\tlearn: 0.0334324\ttotal: 27.5s\tremaining: 12.7s\n",
            "683:\tlearn: 0.0332334\ttotal: 27.5s\tremaining: 12.7s\n",
            "684:\tlearn: 0.0330551\ttotal: 27.5s\tremaining: 12.7s\n",
            "685:\tlearn: 0.0329551\ttotal: 27.5s\tremaining: 12.6s\n",
            "686:\tlearn: 0.0329446\ttotal: 27.6s\tremaining: 12.6s\n",
            "687:\tlearn: 0.0328064\ttotal: 27.6s\tremaining: 12.5s\n",
            "688:\tlearn: 0.0327169\ttotal: 27.6s\tremaining: 12.5s\n",
            "689:\tlearn: 0.0326421\ttotal: 27.6s\tremaining: 12.4s\n",
            "690:\tlearn: 0.0326245\ttotal: 27.6s\tremaining: 12.4s\n",
            "691:\tlearn: 0.0324521\ttotal: 27.7s\tremaining: 12.3s\n",
            "692:\tlearn: 0.0324403\ttotal: 27.7s\tremaining: 12.3s\n",
            "693:\tlearn: 0.0324279\ttotal: 27.7s\tremaining: 12.2s\n",
            "694:\tlearn: 0.0324177\ttotal: 27.7s\tremaining: 12.2s\n",
            "695:\tlearn: 0.0323755\ttotal: 27.8s\tremaining: 12.1s\n",
            "696:\tlearn: 0.0323382\ttotal: 27.8s\tremaining: 12.1s\n",
            "697:\tlearn: 0.0322219\ttotal: 27.8s\tremaining: 12s\n",
            "698:\tlearn: 0.0322072\ttotal: 27.8s\tremaining: 12s\n",
            "699:\tlearn: 0.0320410\ttotal: 27.8s\tremaining: 11.9s\n",
            "700:\tlearn: 0.0319309\ttotal: 27.9s\tremaining: 11.9s\n",
            "701:\tlearn: 0.0319191\ttotal: 27.9s\tremaining: 11.8s\n",
            "702:\tlearn: 0.0318515\ttotal: 27.9s\tremaining: 11.8s\n",
            "703:\tlearn: 0.0318403\ttotal: 27.9s\tremaining: 11.7s\n",
            "704:\tlearn: 0.0316931\ttotal: 27.9s\tremaining: 11.7s\n",
            "705:\tlearn: 0.0315481\ttotal: 28s\tremaining: 11.6s\n",
            "706:\tlearn: 0.0315385\ttotal: 28s\tremaining: 11.6s\n",
            "707:\tlearn: 0.0314884\ttotal: 28s\tremaining: 11.6s\n",
            "708:\tlearn: 0.0314719\ttotal: 28s\tremaining: 11.5s\n",
            "709:\tlearn: 0.0313668\ttotal: 28.1s\tremaining: 11.5s\n",
            "710:\tlearn: 0.0312868\ttotal: 28.1s\tremaining: 11.4s\n",
            "711:\tlearn: 0.0312745\ttotal: 28.1s\tremaining: 11.4s\n",
            "712:\tlearn: 0.0312421\ttotal: 28.1s\tremaining: 11.3s\n",
            "713:\tlearn: 0.0311813\ttotal: 28.2s\tremaining: 11.3s\n",
            "714:\tlearn: 0.0311544\ttotal: 28.2s\tremaining: 11.2s\n",
            "715:\tlearn: 0.0310408\ttotal: 28.2s\tremaining: 11.2s\n",
            "716:\tlearn: 0.0309571\ttotal: 28.2s\tremaining: 11.1s\n",
            "717:\tlearn: 0.0308187\ttotal: 28.3s\tremaining: 11.1s\n",
            "718:\tlearn: 0.0307890\ttotal: 28.3s\tremaining: 11.1s\n",
            "719:\tlearn: 0.0306824\ttotal: 28.3s\tremaining: 11s\n",
            "720:\tlearn: 0.0305334\ttotal: 28.3s\tremaining: 11s\n",
            "721:\tlearn: 0.0305197\ttotal: 28.3s\tremaining: 10.9s\n",
            "722:\tlearn: 0.0303834\ttotal: 28.4s\tremaining: 10.9s\n",
            "723:\tlearn: 0.0302887\ttotal: 28.4s\tremaining: 10.8s\n",
            "724:\tlearn: 0.0301161\ttotal: 28.4s\tremaining: 10.8s\n",
            "725:\tlearn: 0.0300774\ttotal: 28.4s\tremaining: 10.7s\n",
            "726:\tlearn: 0.0300618\ttotal: 28.5s\tremaining: 10.7s\n",
            "727:\tlearn: 0.0299684\ttotal: 28.5s\tremaining: 10.6s\n",
            "728:\tlearn: 0.0298638\ttotal: 28.5s\tremaining: 10.6s\n",
            "729:\tlearn: 0.0297825\ttotal: 28.5s\tremaining: 10.6s\n",
            "730:\tlearn: 0.0296898\ttotal: 28.6s\tremaining: 10.5s\n",
            "731:\tlearn: 0.0296810\ttotal: 28.6s\tremaining: 10.5s\n",
            "732:\tlearn: 0.0295036\ttotal: 28.6s\tremaining: 10.4s\n",
            "733:\tlearn: 0.0292899\ttotal: 28.6s\tremaining: 10.4s\n",
            "734:\tlearn: 0.0292781\ttotal: 28.6s\tremaining: 10.3s\n",
            "735:\tlearn: 0.0292680\ttotal: 28.7s\tremaining: 10.3s\n",
            "736:\tlearn: 0.0292591\ttotal: 28.7s\tremaining: 10.2s\n",
            "737:\tlearn: 0.0292512\ttotal: 28.7s\tremaining: 10.2s\n",
            "738:\tlearn: 0.0290921\ttotal: 28.7s\tremaining: 10.1s\n",
            "739:\tlearn: 0.0290838\ttotal: 28.7s\tremaining: 10.1s\n",
            "740:\tlearn: 0.0289767\ttotal: 28.8s\tremaining: 10.1s\n",
            "741:\tlearn: 0.0289642\ttotal: 28.8s\tremaining: 10s\n",
            "742:\tlearn: 0.0289498\ttotal: 28.8s\tremaining: 9.97s\n",
            "743:\tlearn: 0.0289279\ttotal: 28.8s\tremaining: 9.92s\n",
            "744:\tlearn: 0.0288247\ttotal: 28.9s\tremaining: 9.88s\n",
            "745:\tlearn: 0.0287092\ttotal: 28.9s\tremaining: 9.83s\n",
            "746:\tlearn: 0.0286429\ttotal: 28.9s\tremaining: 9.79s\n",
            "747:\tlearn: 0.0286348\ttotal: 28.9s\tremaining: 9.74s\n",
            "748:\tlearn: 0.0285315\ttotal: 28.9s\tremaining: 9.7s\n",
            "749:\tlearn: 0.0283987\ttotal: 29s\tremaining: 9.66s\n",
            "750:\tlearn: 0.0283775\ttotal: 29s\tremaining: 9.61s\n",
            "751:\tlearn: 0.0283696\ttotal: 29s\tremaining: 9.57s\n",
            "752:\tlearn: 0.0282356\ttotal: 29s\tremaining: 9.52s\n",
            "753:\tlearn: 0.0282272\ttotal: 29.1s\tremaining: 9.48s\n",
            "754:\tlearn: 0.0282200\ttotal: 29.1s\tremaining: 9.44s\n",
            "755:\tlearn: 0.0282100\ttotal: 29.1s\tremaining: 9.39s\n",
            "756:\tlearn: 0.0281971\ttotal: 29.1s\tremaining: 9.35s\n",
            "757:\tlearn: 0.0280934\ttotal: 29.1s\tremaining: 9.3s\n",
            "758:\tlearn: 0.0280775\ttotal: 29.2s\tremaining: 9.26s\n",
            "759:\tlearn: 0.0280604\ttotal: 29.2s\tremaining: 9.22s\n",
            "760:\tlearn: 0.0278910\ttotal: 29.2s\tremaining: 9.18s\n",
            "761:\tlearn: 0.0276646\ttotal: 29.3s\tremaining: 9.14s\n",
            "762:\tlearn: 0.0275134\ttotal: 29.3s\tremaining: 9.09s\n",
            "763:\tlearn: 0.0274994\ttotal: 29.3s\tremaining: 9.05s\n",
            "764:\tlearn: 0.0274032\ttotal: 29.3s\tremaining: 9.01s\n",
            "765:\tlearn: 0.0272454\ttotal: 29.3s\tremaining: 8.96s\n",
            "766:\tlearn: 0.0272350\ttotal: 29.4s\tremaining: 8.92s\n",
            "767:\tlearn: 0.0271380\ttotal: 29.4s\tremaining: 8.88s\n",
            "768:\tlearn: 0.0271245\ttotal: 29.4s\tremaining: 8.83s\n",
            "769:\tlearn: 0.0270163\ttotal: 29.4s\tremaining: 8.79s\n",
            "770:\tlearn: 0.0269978\ttotal: 29.4s\tremaining: 8.75s\n",
            "771:\tlearn: 0.0269909\ttotal: 29.5s\tremaining: 8.71s\n",
            "772:\tlearn: 0.0269820\ttotal: 29.5s\tremaining: 8.66s\n",
            "773:\tlearn: 0.0268698\ttotal: 29.5s\tremaining: 8.62s\n",
            "774:\tlearn: 0.0267677\ttotal: 29.5s\tremaining: 8.58s\n",
            "775:\tlearn: 0.0267597\ttotal: 29.6s\tremaining: 8.53s\n",
            "776:\tlearn: 0.0267417\ttotal: 29.6s\tremaining: 8.49s\n",
            "777:\tlearn: 0.0267347\ttotal: 29.6s\tremaining: 8.45s\n",
            "778:\tlearn: 0.0266863\ttotal: 29.6s\tremaining: 8.4s\n",
            "779:\tlearn: 0.0266785\ttotal: 29.7s\tremaining: 8.36s\n",
            "780:\tlearn: 0.0265877\ttotal: 29.7s\tremaining: 8.32s\n",
            "781:\tlearn: 0.0265690\ttotal: 29.7s\tremaining: 8.28s\n",
            "782:\tlearn: 0.0265625\ttotal: 29.7s\tremaining: 8.23s\n",
            "783:\tlearn: 0.0264952\ttotal: 29.7s\tremaining: 8.19s\n",
            "784:\tlearn: 0.0264875\ttotal: 29.8s\tremaining: 8.15s\n",
            "785:\tlearn: 0.0264049\ttotal: 29.8s\tremaining: 8.11s\n",
            "786:\tlearn: 0.0263976\ttotal: 29.8s\tremaining: 8.07s\n",
            "787:\tlearn: 0.0263415\ttotal: 29.8s\tremaining: 8.03s\n",
            "788:\tlearn: 0.0263304\ttotal: 29.9s\tremaining: 7.98s\n",
            "789:\tlearn: 0.0263239\ttotal: 29.9s\tremaining: 7.94s\n",
            "790:\tlearn: 0.0263175\ttotal: 29.9s\tremaining: 7.9s\n",
            "791:\tlearn: 0.0263097\ttotal: 29.9s\tremaining: 7.86s\n",
            "792:\tlearn: 0.0263034\ttotal: 30s\tremaining: 7.82s\n",
            "793:\tlearn: 0.0261924\ttotal: 30s\tremaining: 7.78s\n",
            "794:\tlearn: 0.0261320\ttotal: 30s\tremaining: 7.73s\n",
            "795:\tlearn: 0.0261146\ttotal: 30s\tremaining: 7.69s\n",
            "796:\tlearn: 0.0260321\ttotal: 30s\tremaining: 7.65s\n",
            "797:\tlearn: 0.0260200\ttotal: 30.1s\tremaining: 7.61s\n",
            "798:\tlearn: 0.0260124\ttotal: 30.1s\tremaining: 7.57s\n",
            "799:\tlearn: 0.0259495\ttotal: 30.1s\tremaining: 7.53s\n",
            "800:\tlearn: 0.0259432\ttotal: 30.1s\tremaining: 7.49s\n",
            "801:\tlearn: 0.0258783\ttotal: 30.1s\tremaining: 7.44s\n",
            "802:\tlearn: 0.0257452\ttotal: 30.2s\tremaining: 7.4s\n",
            "803:\tlearn: 0.0257327\ttotal: 30.2s\tremaining: 7.36s\n",
            "804:\tlearn: 0.0256357\ttotal: 30.2s\tremaining: 7.32s\n",
            "805:\tlearn: 0.0255514\ttotal: 30.3s\tremaining: 7.28s\n",
            "806:\tlearn: 0.0254936\ttotal: 30.3s\tremaining: 7.24s\n",
            "807:\tlearn: 0.0254845\ttotal: 30.3s\tremaining: 7.2s\n",
            "808:\tlearn: 0.0254726\ttotal: 30.3s\tremaining: 7.16s\n",
            "809:\tlearn: 0.0254529\ttotal: 30.3s\tremaining: 7.12s\n",
            "810:\tlearn: 0.0253417\ttotal: 30.4s\tremaining: 7.08s\n",
            "811:\tlearn: 0.0252291\ttotal: 30.4s\tremaining: 7.04s\n",
            "812:\tlearn: 0.0252124\ttotal: 30.4s\tremaining: 6.99s\n",
            "813:\tlearn: 0.0252069\ttotal: 30.4s\tremaining: 6.95s\n",
            "814:\tlearn: 0.0251995\ttotal: 30.5s\tremaining: 6.91s\n",
            "815:\tlearn: 0.0251441\ttotal: 30.5s\tremaining: 6.87s\n",
            "816:\tlearn: 0.0251224\ttotal: 30.5s\tremaining: 6.83s\n",
            "817:\tlearn: 0.0251163\ttotal: 30.5s\tremaining: 6.79s\n",
            "818:\tlearn: 0.0250000\ttotal: 30.5s\tremaining: 6.75s\n",
            "819:\tlearn: 0.0249009\ttotal: 30.6s\tremaining: 6.71s\n",
            "820:\tlearn: 0.0248940\ttotal: 30.6s\tremaining: 6.67s\n",
            "821:\tlearn: 0.0248809\ttotal: 30.6s\tremaining: 6.63s\n",
            "822:\tlearn: 0.0248356\ttotal: 30.6s\tremaining: 6.59s\n",
            "823:\tlearn: 0.0248262\ttotal: 30.6s\tremaining: 6.55s\n",
            "824:\tlearn: 0.0248201\ttotal: 30.7s\tremaining: 6.5s\n",
            "825:\tlearn: 0.0247234\ttotal: 30.7s\tremaining: 6.47s\n",
            "826:\tlearn: 0.0246659\ttotal: 30.7s\tremaining: 6.43s\n",
            "827:\tlearn: 0.0246589\ttotal: 30.7s\tremaining: 6.39s\n",
            "828:\tlearn: 0.0246525\ttotal: 30.8s\tremaining: 6.34s\n",
            "829:\tlearn: 0.0246467\ttotal: 30.8s\tremaining: 6.3s\n",
            "830:\tlearn: 0.0246339\ttotal: 30.8s\tremaining: 6.26s\n",
            "831:\tlearn: 0.0245033\ttotal: 30.8s\tremaining: 6.22s\n",
            "832:\tlearn: 0.0244977\ttotal: 30.8s\tremaining: 6.18s\n",
            "833:\tlearn: 0.0244912\ttotal: 30.9s\tremaining: 6.14s\n",
            "834:\tlearn: 0.0243788\ttotal: 30.9s\tremaining: 6.1s\n",
            "835:\tlearn: 0.0243724\ttotal: 30.9s\tremaining: 6.06s\n",
            "836:\tlearn: 0.0243560\ttotal: 30.9s\tremaining: 6.02s\n",
            "837:\tlearn: 0.0242354\ttotal: 31s\tremaining: 5.98s\n",
            "838:\tlearn: 0.0241857\ttotal: 31s\tremaining: 5.94s\n",
            "839:\tlearn: 0.0241212\ttotal: 31s\tremaining: 5.9s\n",
            "840:\tlearn: 0.0241059\ttotal: 31s\tremaining: 5.86s\n",
            "841:\tlearn: 0.0240510\ttotal: 31s\tremaining: 5.82s\n",
            "842:\tlearn: 0.0240365\ttotal: 31.1s\tremaining: 5.78s\n",
            "843:\tlearn: 0.0240307\ttotal: 31.1s\tremaining: 5.75s\n",
            "844:\tlearn: 0.0239232\ttotal: 31.1s\tremaining: 5.71s\n",
            "845:\tlearn: 0.0239179\ttotal: 31.1s\tremaining: 5.67s\n",
            "846:\tlearn: 0.0239125\ttotal: 31.1s\tremaining: 5.63s\n",
            "847:\tlearn: 0.0238163\ttotal: 31.2s\tremaining: 5.59s\n",
            "848:\tlearn: 0.0237715\ttotal: 31.2s\tremaining: 5.55s\n",
            "849:\tlearn: 0.0237615\ttotal: 31.2s\tremaining: 5.51s\n",
            "850:\tlearn: 0.0237497\ttotal: 31.2s\tremaining: 5.47s\n",
            "851:\tlearn: 0.0237446\ttotal: 31.3s\tremaining: 5.43s\n",
            "852:\tlearn: 0.0237343\ttotal: 31.3s\tremaining: 5.39s\n",
            "853:\tlearn: 0.0237290\ttotal: 31.3s\tremaining: 5.35s\n",
            "854:\tlearn: 0.0237180\ttotal: 31.3s\tremaining: 5.31s\n",
            "855:\tlearn: 0.0237127\ttotal: 31.4s\tremaining: 5.27s\n",
            "856:\tlearn: 0.0236196\ttotal: 31.4s\tremaining: 5.24s\n",
            "857:\tlearn: 0.0235020\ttotal: 31.4s\tremaining: 5.2s\n",
            "858:\tlearn: 0.0233959\ttotal: 31.4s\tremaining: 5.16s\n",
            "859:\tlearn: 0.0233579\ttotal: 31.4s\tremaining: 5.12s\n",
            "860:\tlearn: 0.0232635\ttotal: 31.5s\tremaining: 5.08s\n",
            "861:\tlearn: 0.0232368\ttotal: 31.5s\tremaining: 5.04s\n",
            "862:\tlearn: 0.0231161\ttotal: 31.5s\tremaining: 5s\n",
            "863:\tlearn: 0.0230342\ttotal: 31.5s\tremaining: 4.96s\n",
            "864:\tlearn: 0.0230240\ttotal: 31.5s\tremaining: 4.92s\n",
            "865:\tlearn: 0.0230161\ttotal: 31.6s\tremaining: 4.88s\n",
            "866:\tlearn: 0.0229498\ttotal: 31.6s\tremaining: 4.85s\n",
            "867:\tlearn: 0.0229447\ttotal: 31.6s\tremaining: 4.81s\n",
            "868:\tlearn: 0.0228355\ttotal: 31.6s\tremaining: 4.77s\n",
            "869:\tlearn: 0.0227916\ttotal: 31.7s\tremaining: 4.73s\n",
            "870:\tlearn: 0.0227139\ttotal: 31.7s\tremaining: 4.69s\n",
            "871:\tlearn: 0.0227035\ttotal: 31.7s\tremaining: 4.65s\n",
            "872:\tlearn: 0.0226954\ttotal: 31.7s\tremaining: 4.61s\n",
            "873:\tlearn: 0.0225985\ttotal: 31.7s\tremaining: 4.58s\n",
            "874:\tlearn: 0.0225668\ttotal: 31.8s\tremaining: 4.54s\n",
            "875:\tlearn: 0.0224527\ttotal: 31.8s\tremaining: 4.5s\n",
            "876:\tlearn: 0.0224429\ttotal: 31.8s\tremaining: 4.46s\n",
            "877:\tlearn: 0.0223755\ttotal: 31.8s\tremaining: 4.42s\n",
            "878:\tlearn: 0.0222308\ttotal: 31.9s\tremaining: 4.38s\n",
            "879:\tlearn: 0.0221305\ttotal: 31.9s\tremaining: 4.34s\n",
            "880:\tlearn: 0.0221223\ttotal: 31.9s\tremaining: 4.31s\n",
            "881:\tlearn: 0.0220929\ttotal: 31.9s\tremaining: 4.27s\n",
            "882:\tlearn: 0.0220877\ttotal: 31.9s\tremaining: 4.23s\n",
            "883:\tlearn: 0.0220776\ttotal: 32s\tremaining: 4.19s\n",
            "884:\tlearn: 0.0220720\ttotal: 32s\tremaining: 4.16s\n",
            "885:\tlearn: 0.0220666\ttotal: 32s\tremaining: 4.12s\n",
            "886:\tlearn: 0.0219802\ttotal: 32s\tremaining: 4.08s\n",
            "887:\tlearn: 0.0218919\ttotal: 32.1s\tremaining: 4.04s\n",
            "888:\tlearn: 0.0218871\ttotal: 32.1s\tremaining: 4s\n",
            "889:\tlearn: 0.0218096\ttotal: 32.1s\tremaining: 3.97s\n",
            "890:\tlearn: 0.0217994\ttotal: 32.1s\tremaining: 3.93s\n",
            "891:\tlearn: 0.0217771\ttotal: 32.1s\tremaining: 3.89s\n",
            "892:\tlearn: 0.0217725\ttotal: 32.2s\tremaining: 3.85s\n",
            "893:\tlearn: 0.0217321\ttotal: 32.2s\tremaining: 3.82s\n",
            "894:\tlearn: 0.0217237\ttotal: 32.2s\tremaining: 3.78s\n",
            "895:\tlearn: 0.0217148\ttotal: 32.2s\tremaining: 3.74s\n",
            "896:\tlearn: 0.0217105\ttotal: 32.3s\tremaining: 3.7s\n",
            "897:\tlearn: 0.0217065\ttotal: 32.3s\tremaining: 3.67s\n",
            "898:\tlearn: 0.0216255\ttotal: 32.3s\tremaining: 3.63s\n",
            "899:\tlearn: 0.0216160\ttotal: 32.3s\tremaining: 3.59s\n",
            "900:\tlearn: 0.0215317\ttotal: 32.4s\tremaining: 3.56s\n",
            "901:\tlearn: 0.0214415\ttotal: 32.4s\tremaining: 3.52s\n",
            "902:\tlearn: 0.0213960\ttotal: 32.4s\tremaining: 3.48s\n",
            "903:\tlearn: 0.0213407\ttotal: 32.4s\tremaining: 3.44s\n",
            "904:\tlearn: 0.0213321\ttotal: 32.4s\tremaining: 3.41s\n",
            "905:\tlearn: 0.0213230\ttotal: 32.5s\tremaining: 3.37s\n",
            "906:\tlearn: 0.0213185\ttotal: 32.5s\tremaining: 3.33s\n",
            "907:\tlearn: 0.0212486\ttotal: 32.5s\tremaining: 3.29s\n",
            "908:\tlearn: 0.0212396\ttotal: 32.5s\tremaining: 3.26s\n",
            "909:\tlearn: 0.0212310\ttotal: 32.6s\tremaining: 3.22s\n",
            "910:\tlearn: 0.0211183\ttotal: 32.6s\tremaining: 3.18s\n",
            "911:\tlearn: 0.0210341\ttotal: 32.6s\tremaining: 3.15s\n",
            "912:\tlearn: 0.0209750\ttotal: 32.6s\tremaining: 3.11s\n",
            "913:\tlearn: 0.0209049\ttotal: 32.6s\tremaining: 3.07s\n",
            "914:\tlearn: 0.0208570\ttotal: 32.7s\tremaining: 3.04s\n",
            "915:\tlearn: 0.0208475\ttotal: 32.7s\tremaining: 3s\n",
            "916:\tlearn: 0.0208403\ttotal: 32.7s\tremaining: 2.96s\n",
            "917:\tlearn: 0.0207789\ttotal: 32.7s\tremaining: 2.92s\n",
            "918:\tlearn: 0.0206912\ttotal: 32.8s\tremaining: 2.89s\n",
            "919:\tlearn: 0.0206384\ttotal: 32.8s\tremaining: 2.85s\n",
            "920:\tlearn: 0.0205593\ttotal: 32.8s\tremaining: 2.81s\n",
            "921:\tlearn: 0.0205011\ttotal: 32.8s\tremaining: 2.78s\n",
            "922:\tlearn: 0.0204425\ttotal: 32.8s\tremaining: 2.74s\n",
            "923:\tlearn: 0.0203945\ttotal: 32.9s\tremaining: 2.7s\n",
            "924:\tlearn: 0.0203320\ttotal: 32.9s\tremaining: 2.67s\n",
            "925:\tlearn: 0.0203202\ttotal: 32.9s\tremaining: 2.63s\n",
            "926:\tlearn: 0.0203111\ttotal: 32.9s\tremaining: 2.59s\n",
            "927:\tlearn: 0.0202568\ttotal: 33s\tremaining: 2.56s\n",
            "928:\tlearn: 0.0202502\ttotal: 33s\tremaining: 2.52s\n",
            "929:\tlearn: 0.0201877\ttotal: 33s\tremaining: 2.48s\n",
            "930:\tlearn: 0.0201839\ttotal: 33s\tremaining: 2.45s\n",
            "931:\tlearn: 0.0201007\ttotal: 33s\tremaining: 2.41s\n",
            "932:\tlearn: 0.0200230\ttotal: 33.1s\tremaining: 2.37s\n",
            "933:\tlearn: 0.0200117\ttotal: 33.1s\tremaining: 2.34s\n",
            "934:\tlearn: 0.0200029\ttotal: 33.1s\tremaining: 2.3s\n",
            "935:\tlearn: 0.0199989\ttotal: 33.1s\tremaining: 2.27s\n",
            "936:\tlearn: 0.0199910\ttotal: 33.1s\tremaining: 2.23s\n",
            "937:\tlearn: 0.0199869\ttotal: 33.2s\tremaining: 2.19s\n",
            "938:\tlearn: 0.0198989\ttotal: 33.2s\tremaining: 2.16s\n",
            "939:\tlearn: 0.0198898\ttotal: 33.2s\tremaining: 2.12s\n",
            "940:\tlearn: 0.0198867\ttotal: 33.2s\tremaining: 2.08s\n",
            "941:\tlearn: 0.0198152\ttotal: 33.3s\tremaining: 2.05s\n",
            "942:\tlearn: 0.0197754\ttotal: 33.3s\tremaining: 2.01s\n",
            "943:\tlearn: 0.0197203\ttotal: 33.3s\tremaining: 1.98s\n",
            "944:\tlearn: 0.0196681\ttotal: 33.3s\tremaining: 1.94s\n",
            "945:\tlearn: 0.0195774\ttotal: 33.4s\tremaining: 1.91s\n",
            "946:\tlearn: 0.0195511\ttotal: 33.4s\tremaining: 1.87s\n",
            "947:\tlearn: 0.0194790\ttotal: 33.4s\tremaining: 1.83s\n",
            "948:\tlearn: 0.0194751\ttotal: 33.4s\tremaining: 1.8s\n",
            "949:\tlearn: 0.0194447\ttotal: 33.5s\tremaining: 1.76s\n",
            "950:\tlearn: 0.0194375\ttotal: 33.5s\tremaining: 1.73s\n",
            "951:\tlearn: 0.0193713\ttotal: 33.5s\tremaining: 1.69s\n",
            "952:\tlearn: 0.0192892\ttotal: 33.5s\tremaining: 1.65s\n",
            "953:\tlearn: 0.0192855\ttotal: 33.5s\tremaining: 1.62s\n",
            "954:\tlearn: 0.0192747\ttotal: 33.6s\tremaining: 1.58s\n",
            "955:\tlearn: 0.0192712\ttotal: 33.6s\tremaining: 1.55s\n",
            "956:\tlearn: 0.0192672\ttotal: 33.6s\tremaining: 1.51s\n",
            "957:\tlearn: 0.0191939\ttotal: 33.6s\tremaining: 1.47s\n",
            "958:\tlearn: 0.0191602\ttotal: 33.7s\tremaining: 1.44s\n",
            "959:\tlearn: 0.0190983\ttotal: 33.7s\tremaining: 1.4s\n",
            "960:\tlearn: 0.0190635\ttotal: 33.7s\tremaining: 1.37s\n",
            "961:\tlearn: 0.0189828\ttotal: 33.7s\tremaining: 1.33s\n",
            "962:\tlearn: 0.0189757\ttotal: 33.8s\tremaining: 1.3s\n",
            "963:\tlearn: 0.0189720\ttotal: 33.8s\tremaining: 1.26s\n",
            "964:\tlearn: 0.0189654\ttotal: 33.8s\tremaining: 1.23s\n",
            "965:\tlearn: 0.0189348\ttotal: 33.8s\tremaining: 1.19s\n",
            "966:\tlearn: 0.0189274\ttotal: 33.8s\tremaining: 1.15s\n",
            "967:\tlearn: 0.0188827\ttotal: 33.9s\tremaining: 1.12s\n",
            "968:\tlearn: 0.0188199\ttotal: 33.9s\tremaining: 1.08s\n",
            "969:\tlearn: 0.0187938\ttotal: 33.9s\tremaining: 1.05s\n",
            "970:\tlearn: 0.0187875\ttotal: 33.9s\tremaining: 1.01s\n",
            "971:\tlearn: 0.0187791\ttotal: 33.9s\tremaining: 978ms\n",
            "972:\tlearn: 0.0187758\ttotal: 34s\tremaining: 943ms\n",
            "973:\tlearn: 0.0187653\ttotal: 34s\tremaining: 907ms\n",
            "974:\tlearn: 0.0187614\ttotal: 34s\tremaining: 872ms\n",
            "975:\tlearn: 0.0186718\ttotal: 34s\tremaining: 837ms\n",
            "976:\tlearn: 0.0186209\ttotal: 34.1s\tremaining: 802ms\n",
            "977:\tlearn: 0.0186175\ttotal: 34.1s\tremaining: 766ms\n",
            "978:\tlearn: 0.0185028\ttotal: 34.1s\tremaining: 731ms\n",
            "979:\tlearn: 0.0184774\ttotal: 34.1s\tremaining: 696ms\n",
            "980:\tlearn: 0.0184690\ttotal: 34.1s\tremaining: 661ms\n",
            "981:\tlearn: 0.0183861\ttotal: 34.2s\tremaining: 626ms\n",
            "982:\tlearn: 0.0183761\ttotal: 34.2s\tremaining: 591ms\n",
            "983:\tlearn: 0.0183664\ttotal: 34.2s\tremaining: 556ms\n",
            "984:\tlearn: 0.0183626\ttotal: 34.2s\tremaining: 521ms\n",
            "985:\tlearn: 0.0183596\ttotal: 34.3s\tremaining: 486ms\n",
            "986:\tlearn: 0.0182800\ttotal: 34.3s\tremaining: 451ms\n",
            "987:\tlearn: 0.0182356\ttotal: 34.3s\tremaining: 416ms\n",
            "988:\tlearn: 0.0182113\ttotal: 34.3s\tremaining: 382ms\n",
            "989:\tlearn: 0.0182078\ttotal: 34.3s\tremaining: 347ms\n",
            "990:\tlearn: 0.0182043\ttotal: 34.4s\tremaining: 312ms\n",
            "991:\tlearn: 0.0182009\ttotal: 34.4s\tremaining: 277ms\n",
            "992:\tlearn: 0.0181976\ttotal: 34.4s\tremaining: 243ms\n",
            "993:\tlearn: 0.0181884\ttotal: 34.4s\tremaining: 208ms\n",
            "994:\tlearn: 0.0181444\ttotal: 34.5s\tremaining: 173ms\n",
            "995:\tlearn: 0.0180937\ttotal: 34.5s\tremaining: 139ms\n",
            "996:\tlearn: 0.0180533\ttotal: 34.5s\tremaining: 104ms\n",
            "997:\tlearn: 0.0180457\ttotal: 34.5s\tremaining: 69.2ms\n",
            "998:\tlearn: 0.0179745\ttotal: 34.6s\tremaining: 34.6ms\n",
            "999:\tlearn: 0.0179711\ttotal: 34.6s\tremaining: 0us\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 34.9872305393219\n",
            "CPU times: user 39.3 s, sys: 4.75 s, total: 44.1 s\n",
            "Wall time: 35 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Stochastic Gradient Descent (SGD)**"
      ],
      "metadata": {
        "id": "MfzCGwacnmM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Stochastic Gradient Descent (SGD)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Stochastic Gradient Descent (SGD)'][0])\n",
        "print(\"Precision:\", results['Stochastic Gradient Descent (SGD)'][1])\n",
        "print(\"Recall:\", results['Stochastic Gradient Descent (SGD)'][2])\n",
        "print(\"F1-score:\", results['Stochastic Gradient Descent (SGD)'][3])\n",
        "print(\"Training Time:\", results['Stochastic Gradient Descent (SGD)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGYIMrV1noie",
        "outputId": "f771bb92-2def-4dff-99b9-e907efde7391"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.0030994415283203125\n",
            "CPU times: user 13 ms, sys: 0 ns, total: 13 ms\n",
            "Wall time: 12.9 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Linear Discriminant Analysis (LDA)**"
      ],
      "metadata": {
        "id": "hFd3OieZKDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Initialize Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lda.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lda.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaoOVVwFKERs",
        "outputId": "1e0a879d-b9cb-4efb-9c77-9e0c6f494957"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9906666666666667\n",
            "Precision: 0.9907830650972412\n",
            "Recall: 0.9906666666666667\n",
            "F1-score: 0.9906792563465785\n",
            "Training Time: 6.3993659019470215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Quadratic Discriminant Analysis (QDA)**"
      ],
      "metadata": {
        "id": "r-Kr6q8VKIyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Initialize Quadratic Discriminant Analysis (QDA)\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "qda.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = qda.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPrQyz2rKMbZ",
        "outputId": "bec7bf00-88b5-4cfd-b9dd-875141a9d309"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 2.335886240005493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks 🧠"
      ],
      "metadata": {
        "id": "oTHFBxWJKRym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating NN layers and compiling with loss, metrics, optimizer configs"
      ],
      "metadata": {
        "id": "eeuS5khpopxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training NN"
      ],
      "metadata": {
        "id": "_Q-qs1TXoqfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Convert SparseTensor to dense numpy arrays\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_dense,\n",
        "                     y_train,\n",
        "                     epochs=500,\n",
        "                     verbose=1,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(X_test_dense, y_test))\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3YIzhuKXLz",
        "outputId": "aa015631-1572-4013-81ce-27d4d4d89288"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - binary_accuracy: 0.7609 - loss: 0.6456 - val_binary_accuracy: 0.9567 - val_loss: 0.2637\n",
            "Epoch 2/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9781 - loss: 0.1520 - val_binary_accuracy: 0.9980 - val_loss: 0.0202\n",
            "Epoch 3/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 0.9993 - loss: 0.0136 - val_binary_accuracy: 0.9993 - val_loss: 0.0067\n",
            "Epoch 4/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 0.9993 - loss: 0.0058 - val_binary_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 5/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 0.0026 - val_binary_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 6/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 0.0015 - val_binary_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 7/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.5541e-04 - val_binary_accuracy: 1.0000 - val_loss: 7.8067e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 6.8326e-04 - val_binary_accuracy: 1.0000 - val_loss: 5.7534e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.2887e-04 - val_binary_accuracy: 1.0000 - val_loss: 4.5086e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 4.8359e-04 - val_binary_accuracy: 1.0000 - val_loss: 3.6092e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.3373e-04 - val_binary_accuracy: 1.0000 - val_loss: 2.9583e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.9958e-04 - val_binary_accuracy: 1.0000 - val_loss: 2.4828e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.2502e-04 - val_binary_accuracy: 1.0000 - val_loss: 2.1017e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8927e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.8099e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.8337e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.5645e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4756e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.3723e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.3035e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.2079e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0965e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.0764e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.6503e-05 - val_binary_accuracy: 1.0000 - val_loss: 9.5961e-05\n",
            "Epoch 20/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.6596e-05 - val_binary_accuracy: 1.0000 - val_loss: 8.6387e-05\n",
            "Epoch 21/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 8.6522e-05 - val_binary_accuracy: 1.0000 - val_loss: 7.7634e-05\n",
            "Epoch 22/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.5276e-05 - val_binary_accuracy: 1.0000 - val_loss: 7.0791e-05\n",
            "Epoch 23/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.5286e-05 - val_binary_accuracy: 1.0000 - val_loss: 6.4287e-05\n",
            "Epoch 24/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.5084e-05 - val_binary_accuracy: 1.0000 - val_loss: 5.8703e-05\n",
            "Epoch 25/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 5.9709e-05 - val_binary_accuracy: 1.0000 - val_loss: 5.3835e-05\n",
            "Epoch 26/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.3687e-05 - val_binary_accuracy: 1.0000 - val_loss: 4.9469e-05\n",
            "Epoch 27/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 5.1461e-05 - val_binary_accuracy: 1.0000 - val_loss: 4.5535e-05\n",
            "Epoch 28/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 4.6791e-05 - val_binary_accuracy: 1.0000 - val_loss: 4.2155e-05\n",
            "Epoch 29/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.2647e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.9070e-05\n",
            "Epoch 30/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.4805e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.6286e-05\n",
            "Epoch 31/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.0141e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.3791e-05\n",
            "Epoch 32/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.1068e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.1570e-05\n",
            "Epoch 33/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.8673e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.9475e-05\n",
            "Epoch 34/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.7536e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.7623e-05\n",
            "Epoch 35/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5842e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.5882e-05\n",
            "Epoch 36/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.4851e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.4310e-05\n",
            "Epoch 37/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3265e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.2850e-05\n",
            "Epoch 38/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.2787e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.1479e-05\n",
            "Epoch 39/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0768e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.0284e-05\n",
            "Epoch 40/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9109e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.9159e-05\n",
            "Epoch 41/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.8474e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.8102e-05\n",
            "Epoch 42/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.6750e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.7112e-05\n",
            "Epoch 43/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6024e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.6210e-05\n",
            "Epoch 44/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5508e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.5361e-05\n",
            "Epoch 45/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.4978e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.4553e-05\n",
            "Epoch 46/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5140e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.3829e-05\n",
            "Epoch 47/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.2900e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.3155e-05\n",
            "Epoch 48/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.1932e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.2517e-05\n",
            "Epoch 49/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 1.0994e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.1924e-05\n",
            "Epoch 50/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 1.2194e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.1319e-05\n",
            "Epoch 51/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 1.3049e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.0787e-05\n",
            "Epoch 52/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 1.1311e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.0283e-05\n",
            "Epoch 53/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 9.8997e-06 - val_binary_accuracy: 1.0000 - val_loss: 9.8243e-06\n",
            "Epoch 54/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.6433e-06 - val_binary_accuracy: 1.0000 - val_loss: 9.3657e-06\n",
            "Epoch 55/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.0386e-06 - val_binary_accuracy: 1.0000 - val_loss: 8.9615e-06\n",
            "Epoch 56/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.7781e-06 - val_binary_accuracy: 1.0000 - val_loss: 8.5567e-06\n",
            "Epoch 57/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.3767e-06 - val_binary_accuracy: 1.0000 - val_loss: 8.1948e-06\n",
            "Epoch 58/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.1264e-06 - val_binary_accuracy: 1.0000 - val_loss: 7.8398e-06\n",
            "Epoch 59/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.2260e-06 - val_binary_accuracy: 1.0000 - val_loss: 7.5184e-06\n",
            "Epoch 60/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.6933e-06 - val_binary_accuracy: 1.0000 - val_loss: 7.2131e-06\n",
            "Epoch 61/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 8.4146e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.9010e-06\n",
            "Epoch 62/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.4759e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.6163e-06\n",
            "Epoch 63/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.6130e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.3444e-06\n",
            "Epoch 64/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 7.0649e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.0945e-06\n",
            "Epoch 65/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.2466e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.8532e-06\n",
            "Epoch 66/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.5396e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.6218e-06\n",
            "Epoch 67/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.8017e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.4083e-06\n",
            "Epoch 68/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7602e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.2082e-06\n",
            "Epoch 69/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.5482e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.9990e-06\n",
            "Epoch 70/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.7127e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.8135e-06\n",
            "Epoch 71/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.0084e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.6356e-06\n",
            "Epoch 72/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 4.9871e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.4621e-06\n",
            "Epoch 73/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 4.8850e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.2923e-06\n",
            "Epoch 74/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.3796e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.1381e-06\n",
            "Epoch 75/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 4.1480e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.9881e-06\n",
            "Epoch 76/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.4529e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.8469e-06\n",
            "Epoch 77/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.0857e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.7069e-06\n",
            "Epoch 78/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 3.7994e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.5762e-06\n",
            "Epoch 79/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.5500e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.4519e-06\n",
            "Epoch 80/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 3.6199e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.3259e-06\n",
            "Epoch 81/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.9373e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.2126e-06\n",
            "Epoch 82/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.4717e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.0949e-06\n",
            "Epoch 83/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.9192e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.9967e-06\n",
            "Epoch 84/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.8810e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.8902e-06\n",
            "Epoch 85/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5352e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.7952e-06\n",
            "Epoch 86/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6872e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.6945e-06\n",
            "Epoch 87/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5983e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.6041e-06\n",
            "Epoch 88/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3962e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.5176e-06\n",
            "Epoch 89/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.9268e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.4312e-06\n",
            "Epoch 90/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.4924e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.3491e-06\n",
            "Epoch 91/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.2891e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.2752e-06\n",
            "Epoch 92/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3021e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.1994e-06\n",
            "Epoch 93/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - binary_accuracy: 1.0000 - loss: 2.2248e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.1262e-06\n",
            "Epoch 94/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 1.9567e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.0588e-06\n",
            "Epoch 95/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.9129e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.9902e-06\n",
            "Epoch 96/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 2.0266e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.9269e-06\n",
            "Epoch 97/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8076e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.8678e-06\n",
            "Epoch 98/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.7191e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.8056e-06\n",
            "Epoch 99/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.5811e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.7498e-06\n",
            "Epoch 100/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8131e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.6925e-06\n",
            "Epoch 101/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.4442e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.6400e-06\n",
            "Epoch 102/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5324e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.5884e-06\n",
            "Epoch 103/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5459e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.5388e-06\n",
            "Epoch 104/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5497e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.4902e-06\n",
            "Epoch 105/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5627e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.4445e-06\n",
            "Epoch 106/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6222e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.3998e-06\n",
            "Epoch 107/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2477e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.3590e-06\n",
            "Epoch 108/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 1.0000 - loss: 1.2423e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.3168e-06\n",
            "Epoch 109/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 1.2225e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2773e-06\n",
            "Epoch 110/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2079e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2369e-06\n",
            "Epoch 111/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2051e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2007e-06\n",
            "Epoch 112/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2800e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.1636e-06\n",
            "Epoch 113/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.0926e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.1282e-06\n",
            "Epoch 114/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 1.1701e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.0943e-06\n",
            "Epoch 115/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.1006e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.0619e-06\n",
            "Epoch 116/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0377e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.0304e-06\n",
            "Epoch 117/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1679e-06 - val_binary_accuracy: 1.0000 - val_loss: 9.9975e-07\n",
            "Epoch 118/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.6222e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.7041e-07\n",
            "Epoch 119/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0452e-06 - val_binary_accuracy: 1.0000 - val_loss: 9.4155e-07\n",
            "Epoch 120/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 9.3076e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.1429e-07\n",
            "Epoch 121/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.6385e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.8778e-07\n",
            "Epoch 122/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.0605e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.6297e-07\n",
            "Epoch 123/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.0906e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.3598e-07\n",
            "Epoch 124/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.6695e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.1222e-07\n",
            "Epoch 125/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.4367e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.8836e-07\n",
            "Epoch 126/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.2106e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.6654e-07\n",
            "Epoch 127/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.1092e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.4383e-07\n",
            "Epoch 128/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.6778e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.2224e-07\n",
            "Epoch 129/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.9013e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.0114e-07\n",
            "Epoch 130/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.1556e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.8169e-07\n",
            "Epoch 131/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.6749e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.6222e-07\n",
            "Epoch 132/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.2724e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.4375e-07\n",
            "Epoch 133/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.9364e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.2510e-07\n",
            "Epoch 134/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.3355e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.0751e-07\n",
            "Epoch 135/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.3188e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.9026e-07\n",
            "Epoch 136/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2930e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.7362e-07\n",
            "Epoch 137/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 5.5248e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.5766e-07\n",
            "Epoch 138/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 5.4882e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.4273e-07\n",
            "Epoch 139/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 5.0416e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.2682e-07\n",
            "Epoch 140/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 4.9134e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.1215e-07\n",
            "Epoch 141/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.1257e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.9836e-07\n",
            "Epoch 142/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.0032e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.8407e-07\n",
            "Epoch 143/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.9504e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.7034e-07\n",
            "Epoch 144/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.4417e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.5740e-07\n",
            "Epoch 145/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.6435e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.4482e-07\n",
            "Epoch 146/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7136e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.3238e-07\n",
            "Epoch 147/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.2569e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.2079e-07\n",
            "Epoch 148/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.9177e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.0937e-07\n",
            "Epoch 149/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.7626e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.9797e-07\n",
            "Epoch 150/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.9530e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.8719e-07\n",
            "Epoch 151/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.4714e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.7714e-07\n",
            "Epoch 152/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.6269e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.6605e-07\n",
            "Epoch 153/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.6386e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.5614e-07\n",
            "Epoch 154/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.2492e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.4639e-07\n",
            "Epoch 155/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.6680e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.3695e-07\n",
            "Epoch 156/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.3574e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.2787e-07\n",
            "Epoch 157/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.9704e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.1941e-07\n",
            "Epoch 158/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.1131e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.1050e-07\n",
            "Epoch 159/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0301e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.0231e-07\n",
            "Epoch 160/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 3.2190e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.9394e-07\n",
            "Epoch 161/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 2.7134e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.8644e-07\n",
            "Epoch 162/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 3.0420e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.7840e-07\n",
            "Epoch 163/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 3.0172e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.7095e-07\n",
            "Epoch 164/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7986e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.6372e-07\n",
            "Epoch 165/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6459e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.5684e-07\n",
            "Epoch 166/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.1520e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.5024e-07\n",
            "Epoch 167/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6100e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.4319e-07\n",
            "Epoch 168/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3049e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.3716e-07\n",
            "Epoch 169/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.2267e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.3068e-07\n",
            "Epoch 170/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0648e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.2456e-07\n",
            "Epoch 171/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.2179e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.1858e-07\n",
            "Epoch 172/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0213e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.1278e-07\n",
            "Epoch 173/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0917e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.0726e-07\n",
            "Epoch 174/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0710e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.0176e-07\n",
            "Epoch 175/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0316e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.9642e-07\n",
            "Epoch 176/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8817e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.9153e-07\n",
            "Epoch 177/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9284e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.8633e-07\n",
            "Epoch 178/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8842e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.8144e-07\n",
            "Epoch 179/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.7749e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.7665e-07\n",
            "Epoch 180/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6214e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.7223e-07\n",
            "Epoch 181/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7008e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.6758e-07\n",
            "Epoch 182/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5635e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.6322e-07\n",
            "Epoch 183/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.7435e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.5903e-07\n",
            "Epoch 184/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.6039e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.5480e-07\n",
            "Epoch 185/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.3911e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.5096e-07\n",
            "Epoch 186/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.5747e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.4694e-07\n",
            "Epoch 187/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3204e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.4332e-07\n",
            "Epoch 188/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3433e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.3980e-07\n",
            "Epoch 189/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4574e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.3591e-07\n",
            "Epoch 190/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3561e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.3251e-07\n",
            "Epoch 191/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1826e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.2926e-07\n",
            "Epoch 192/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1787e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.2585e-07\n",
            "Epoch 193/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2210e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.2262e-07\n",
            "Epoch 194/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1081e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.1954e-07\n",
            "Epoch 195/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2471e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.1643e-07\n",
            "Epoch 196/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1206e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.1358e-07\n",
            "Epoch 197/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.9739e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1069e-07\n",
            "Epoch 198/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0028e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.0785e-07\n",
            "Epoch 199/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1000e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.0513e-07\n",
            "Epoch 200/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1860e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.0248e-07\n",
            "Epoch 201/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1238e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.9905e-08\n",
            "Epoch 202/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0800e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.7370e-08\n",
            "Epoch 203/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0730e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.4894e-08\n",
            "Epoch 204/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.5703e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.2613e-08\n",
            "Epoch 205/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 8.4552e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.0235e-08\n",
            "Epoch 206/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 8.2393e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.7974e-08\n",
            "Epoch 207/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 9.2325e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.5838e-08\n",
            "Epoch 208/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 9.3331e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.3632e-08\n",
            "Epoch 209/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0195e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.1548e-08\n",
            "Epoch 210/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.4921e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.9581e-08\n",
            "Epoch 211/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.5363e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.7572e-08\n",
            "Epoch 212/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.9981e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.5733e-08\n",
            "Epoch 213/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.9491e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.3824e-08\n",
            "Epoch 214/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.8195e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.2057e-08\n",
            "Epoch 215/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.5510e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.0265e-08\n",
            "Epoch 216/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.9387e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.8520e-08\n",
            "Epoch 217/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.2352e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.6868e-08\n",
            "Epoch 218/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.3165e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.5203e-08\n",
            "Epoch 219/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.9773e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.3585e-08\n",
            "Epoch 220/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.1196e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.2084e-08\n",
            "Epoch 221/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.2578e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.0558e-08\n",
            "Epoch 222/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.6570e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.9203e-08\n",
            "Epoch 223/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.9382e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.7650e-08\n",
            "Epoch 224/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.8141e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.6292e-08\n",
            "Epoch 225/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.8736e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.4913e-08\n",
            "Epoch 226/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.1840e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.3630e-08\n",
            "Epoch 227/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 5.4599e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.2333e-08\n",
            "Epoch 228/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.8544e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.1090e-08\n",
            "Epoch 229/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.6795e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.9882e-08\n",
            "Epoch 230/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.6278e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.8679e-08\n",
            "Epoch 231/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7304e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.7579e-08\n",
            "Epoch 232/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7840e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.6409e-08\n",
            "Epoch 233/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.8677e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.5310e-08\n",
            "Epoch 234/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.1271e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.4277e-08\n",
            "Epoch 235/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.1462e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.3199e-08\n",
            "Epoch 236/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.0772e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.2198e-08\n",
            "Epoch 237/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.8591e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.1218e-08\n",
            "Epoch 238/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.0179e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.0235e-08\n",
            "Epoch 239/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.4162e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.9325e-08\n",
            "Epoch 240/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.7507e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.8414e-08\n",
            "Epoch 241/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.2004e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.7502e-08\n",
            "Epoch 242/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.6901e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.6649e-08\n",
            "Epoch 243/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.2424e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.5833e-08\n",
            "Epoch 244/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.7446e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.4990e-08\n",
            "Epoch 245/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.1673e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.4185e-08\n",
            "Epoch 246/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.1035e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.3411e-08\n",
            "Epoch 247/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.7743e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.2657e-08\n",
            "Epoch 248/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 2.9260e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.1910e-08\n",
            "Epoch 249/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.9531e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.1166e-08\n",
            "Epoch 250/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 3.3777e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.0448e-08\n",
            "Epoch 251/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.7358e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.9794e-08\n",
            "Epoch 252/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 2.9289e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.9076e-08\n",
            "Epoch 253/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.9798e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.8411e-08\n",
            "Epoch 254/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6633e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.7815e-08\n",
            "Epoch 255/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.0064e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.7156e-08\n",
            "Epoch 256/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3856e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.6559e-08\n",
            "Epoch 257/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6440e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.5960e-08\n",
            "Epoch 258/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5837e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.5380e-08\n",
            "Epoch 259/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2477e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.4854e-08\n",
            "Epoch 260/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4236e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.4283e-08\n",
            "Epoch 261/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3845e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.3739e-08\n",
            "Epoch 262/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3045e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.3218e-08\n",
            "Epoch 263/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3734e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.2712e-08\n",
            "Epoch 264/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2872e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.2220e-08\n",
            "Epoch 265/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1543e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.1728e-08\n",
            "Epoch 266/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3610e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.1262e-08\n",
            "Epoch 267/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9273e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.0799e-08\n",
            "Epoch 268/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8898e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.0363e-08\n",
            "Epoch 269/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 1.9406e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.9926e-08\n",
            "Epoch 270/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.1441e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.9502e-08\n",
            "Epoch 271/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.0276e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.9094e-08\n",
            "Epoch 272/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.9148e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.8688e-08\n",
            "Epoch 273/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8620e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.8294e-08\n",
            "Epoch 274/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8423e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.7895e-08\n",
            "Epoch 275/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8248e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.7516e-08\n",
            "Epoch 276/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6478e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.7165e-08\n",
            "Epoch 277/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5399e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.6808e-08\n",
            "Epoch 278/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9978e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.6427e-08\n",
            "Epoch 279/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6106e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.6095e-08\n",
            "Epoch 280/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7192e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.5758e-08\n",
            "Epoch 281/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7302e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.5433e-08\n",
            "Epoch 282/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6611e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.5115e-08\n",
            "Epoch 283/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3146e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.4814e-08\n",
            "Epoch 284/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4018e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.4499e-08\n",
            "Epoch 285/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3559e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.4200e-08\n",
            "Epoch 286/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4293e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3904e-08\n",
            "Epoch 287/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4477e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3629e-08\n",
            "Epoch 288/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2696e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3351e-08\n",
            "Epoch 289/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2904e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3086e-08\n",
            "Epoch 290/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3529e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2832e-08\n",
            "Epoch 291/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.3384e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2571e-08\n",
            "Epoch 292/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.1282e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2335e-08\n",
            "Epoch 293/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 1.1434e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2081e-08\n",
            "Epoch 294/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2699e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1837e-08\n",
            "Epoch 295/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0323e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1625e-08\n",
            "Epoch 296/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1678e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1377e-08\n",
            "Epoch 297/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1183e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1156e-08\n",
            "Epoch 298/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.1119e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0930e-08\n",
            "Epoch 299/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1175e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0717e-08\n",
            "Epoch 300/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1025e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0515e-08\n",
            "Epoch 301/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1546e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0304e-08\n",
            "Epoch 302/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.7638e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.0118e-08\n",
            "Epoch 303/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0015e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.9155e-09\n",
            "Epoch 304/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1427e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.7199e-09\n",
            "Epoch 305/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1746e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.5530e-09\n",
            "Epoch 306/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.8121e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.3750e-09\n",
            "Epoch 307/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.9177e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.2122e-09\n",
            "Epoch 308/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.3985e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.0381e-09\n",
            "Epoch 309/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.5949e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.8690e-09\n",
            "Epoch 310/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.9688e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.7025e-09\n",
            "Epoch 311/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.0122e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.5502e-09\n",
            "Epoch 312/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.7880e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.4058e-09\n",
            "Epoch 313/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 7.4652e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.2548e-09\n",
            "Epoch 314/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 7.0863e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.1197e-09\n",
            "Epoch 315/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 7.3384e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.9702e-09\n",
            "Epoch 316/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 7.8363e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.8216e-09\n",
            "Epoch 317/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.7494e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.6849e-09\n",
            "Epoch 318/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.7538e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.5525e-09\n",
            "Epoch 319/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.8961e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.4226e-09\n",
            "Epoch 320/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.4223e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.2913e-09\n",
            "Epoch 321/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.8370e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.1626e-09\n",
            "Epoch 322/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.9383e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.0463e-09\n",
            "Epoch 323/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.8288e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.9227e-09\n",
            "Epoch 324/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.3017e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.8113e-09\n",
            "Epoch 325/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.1471e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.6979e-09\n",
            "Epoch 326/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.4249e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.5913e-09\n",
            "Epoch 327/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.1712e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.4851e-09\n",
            "Epoch 328/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.8243e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.3758e-09\n",
            "Epoch 329/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.7479e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.2716e-09\n",
            "Epoch 330/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.5985e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.1696e-09\n",
            "Epoch 331/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.1099e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.0668e-09\n",
            "Epoch 332/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.1040e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.9759e-09\n",
            "Epoch 333/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.7413e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.8812e-09\n",
            "Epoch 334/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 5.5048e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.7869e-09\n",
            "Epoch 335/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 5.4630e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.6940e-09\n",
            "Epoch 336/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 5.3531e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.6029e-09\n",
            "Epoch 337/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - binary_accuracy: 1.0000 - loss: 5.5140e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.5102e-09\n",
            "Epoch 338/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - binary_accuracy: 1.0000 - loss: 5.3408e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.4228e-09\n",
            "Epoch 339/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - binary_accuracy: 1.0000 - loss: 6.0859e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.3377e-09\n",
            "Epoch 340/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - binary_accuracy: 1.0000 - loss: 5.0093e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.2561e-09\n",
            "Epoch 341/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 5.0445e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.1823e-09\n",
            "Epoch 342/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.1352e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.1034e-09\n",
            "Epoch 343/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.7160e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.0280e-09\n",
            "Epoch 344/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7123e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.9565e-09\n",
            "Epoch 345/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.6645e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.8780e-09\n",
            "Epoch 346/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2869e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.8083e-09\n",
            "Epoch 347/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.4482e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.7425e-09\n",
            "Epoch 348/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.3391e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.6774e-09\n",
            "Epoch 349/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.1469e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.6077e-09\n",
            "Epoch 350/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.5250e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.5365e-09\n",
            "Epoch 351/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.3037e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.4789e-09\n",
            "Epoch 352/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.7968e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.4098e-09\n",
            "Epoch 353/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.6844e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.3472e-09\n",
            "Epoch 354/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.2816e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.2820e-09\n",
            "Epoch 355/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.2499e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.2281e-09\n",
            "Epoch 356/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.2924e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.1666e-09\n",
            "Epoch 357/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.1586e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.1067e-09\n",
            "Epoch 358/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.2600e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.0477e-09\n",
            "Epoch 359/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 3.9048e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.9896e-09\n",
            "Epoch 360/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 4.1042e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.9371e-09\n",
            "Epoch 361/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 3.7674e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.8828e-09\n",
            "Epoch 362/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.8256e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.8342e-09\n",
            "Epoch 363/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.9670e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.7918e-09\n",
            "Epoch 364/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.9248e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.7461e-09\n",
            "Epoch 365/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.5172e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.6994e-09\n",
            "Epoch 366/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.4941e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.6605e-09\n",
            "Epoch 367/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3373e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.6082e-09\n",
            "Epoch 368/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.4167e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.5683e-09\n",
            "Epoch 369/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.8799e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.5282e-09\n",
            "Epoch 370/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.4260e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.4854e-09\n",
            "Epoch 371/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.8879e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.4508e-09\n",
            "Epoch 372/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.9308e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.4138e-09\n",
            "Epoch 373/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.7469e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.3730e-09\n",
            "Epoch 374/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.3362e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.3367e-09\n",
            "Epoch 375/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0057e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.2952e-09\n",
            "Epoch 376/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.0030e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.2683e-09\n",
            "Epoch 377/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.6010e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.2281e-09\n",
            "Epoch 378/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0531e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.1956e-09\n",
            "Epoch 379/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3241e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.1570e-09\n",
            "Epoch 380/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 3.1141e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.1230e-09\n",
            "Epoch 381/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 3.2439e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.0946e-09\n",
            "Epoch 382/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 3.2577e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.0651e-09\n",
            "Epoch 383/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 3.0282e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.0255e-09\n",
            "Epoch 384/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 2.9692e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9939e-09\n",
            "Epoch 385/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7180e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9675e-09\n",
            "Epoch 386/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.9173e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9335e-09\n",
            "Epoch 387/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0102e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9000e-09\n",
            "Epoch 388/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 3.0770e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8716e-09\n",
            "Epoch 389/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.9732e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8376e-09\n",
            "Epoch 390/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6306e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8122e-09\n",
            "Epoch 391/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5912e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.7853e-09\n",
            "Epoch 392/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.8035e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.7568e-09\n",
            "Epoch 393/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7078e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.7322e-09\n",
            "Epoch 394/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6340e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6994e-09\n",
            "Epoch 395/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.8720e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6743e-09\n",
            "Epoch 396/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5787e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6505e-09\n",
            "Epoch 397/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.3359e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6234e-09\n",
            "Epoch 398/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4997e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6035e-09\n",
            "Epoch 399/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.9176e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5806e-09\n",
            "Epoch 400/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7005e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5565e-09\n",
            "Epoch 401/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5277e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5338e-09\n",
            "Epoch 402/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 2.4972e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5123e-09\n",
            "Epoch 403/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 2.3554e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4900e-09\n",
            "Epoch 404/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.7032e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4738e-09\n",
            "Epoch 405/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.5865e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4490e-09\n",
            "Epoch 406/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.2874e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4333e-09\n",
            "Epoch 407/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 2.5733e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4083e-09\n",
            "Epoch 408/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1888e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3940e-09\n",
            "Epoch 409/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4770e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3742e-09\n",
            "Epoch 410/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4362e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3521e-09\n",
            "Epoch 411/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4078e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3355e-09\n",
            "Epoch 412/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.2062e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3208e-09\n",
            "Epoch 413/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1150e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2970e-09\n",
            "Epoch 414/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.2680e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2692e-09\n",
            "Epoch 415/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2130e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2498e-09\n",
            "Epoch 416/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1965e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2287e-09\n",
            "Epoch 417/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9990e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2033e-09\n",
            "Epoch 418/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9537e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2031e-09\n",
            "Epoch 419/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1436e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1720e-09\n",
            "Epoch 420/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1050e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1553e-09\n",
            "Epoch 421/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0823e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1481e-09\n",
            "Epoch 422/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3387e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1293e-09\n",
            "Epoch 423/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.9705e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1262e-09\n",
            "Epoch 424/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 2.3282e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0984e-09\n",
            "Epoch 425/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.1462e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1013e-09\n",
            "Epoch 426/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 2.4176e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0835e-09\n",
            "Epoch 427/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.9738e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0725e-09\n",
            "Epoch 428/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9545e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0560e-09\n",
            "Epoch 429/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.9368e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0467e-09\n",
            "Epoch 430/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8648e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0343e-09\n",
            "Epoch 431/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8328e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0235e-09\n",
            "Epoch 432/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1382e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0138e-09\n",
            "Epoch 433/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.1162e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0027e-09\n",
            "Epoch 434/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2503e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9976e-09\n",
            "Epoch 435/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1469e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9919e-09\n",
            "Epoch 436/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1963e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9584e-09\n",
            "Epoch 437/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0025e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9593e-09\n",
            "Epoch 438/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.7030e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9637e-09\n",
            "Epoch 439/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8967e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9567e-09\n",
            "Epoch 440/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.9136e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9432e-09\n",
            "Epoch 441/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8259e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9324e-09\n",
            "Epoch 442/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7666e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9181e-09\n",
            "Epoch 443/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7141e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9070e-09\n",
            "Epoch 444/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9005e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9046e-09\n",
            "Epoch 445/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0497e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8990e-09\n",
            "Epoch 446/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7697e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8828e-09\n",
            "Epoch 447/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9801e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8829e-09\n",
            "Epoch 448/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 2.0507e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8714e-09\n",
            "Epoch 449/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.8293e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8669e-09\n",
            "Epoch 450/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.8515e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8490e-09\n",
            "Epoch 451/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6962e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8451e-09\n",
            "Epoch 452/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8947e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8423e-09\n",
            "Epoch 453/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6943e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8318e-09\n",
            "Epoch 454/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8995e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8204e-09\n",
            "Epoch 455/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7627e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8161e-09\n",
            "Epoch 456/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7632e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7980e-09\n",
            "Epoch 457/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7263e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8048e-09\n",
            "Epoch 458/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6928e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7957e-09\n",
            "Epoch 459/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7537e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7976e-09\n",
            "Epoch 460/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.8194e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7897e-09\n",
            "Epoch 461/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9166e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7801e-09\n",
            "Epoch 462/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7386e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7714e-09\n",
            "Epoch 463/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7623e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7732e-09\n",
            "Epoch 464/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9074e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7685e-09\n",
            "Epoch 465/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7696e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7540e-09\n",
            "Epoch 466/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9104e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7649e-09\n",
            "Epoch 467/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6045e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7588e-09\n",
            "Epoch 468/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.6533e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7375e-09\n",
            "Epoch 469/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.7208e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7405e-09\n",
            "Epoch 470/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.7767e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7429e-09\n",
            "Epoch 471/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.8119e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7430e-09\n",
            "Epoch 472/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7795e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7375e-09\n",
            "Epoch 473/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9391e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7246e-09\n",
            "Epoch 474/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7155e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7168e-09\n",
            "Epoch 475/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5403e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7157e-09\n",
            "Epoch 476/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.5594e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7141e-09\n",
            "Epoch 477/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.6496e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7232e-09\n",
            "Epoch 478/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7516e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7068e-09\n",
            "Epoch 479/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6296e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7019e-09\n",
            "Epoch 480/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7234e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6975e-09\n",
            "Epoch 481/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.6390e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7034e-09\n",
            "Epoch 482/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7272e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7073e-09\n",
            "Epoch 483/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6171e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6932e-09\n",
            "Epoch 484/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7542e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6902e-09\n",
            "Epoch 485/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7364e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6870e-09\n",
            "Epoch 486/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.6892e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6741e-09\n",
            "Epoch 487/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6464e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6930e-09\n",
            "Epoch 488/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8729e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6758e-09\n",
            "Epoch 489/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.6219e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6942e-09\n",
            "Epoch 490/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.5558e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6719e-09\n",
            "Epoch 491/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.8369e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6741e-09\n",
            "Epoch 492/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 1.4745e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6746e-09\n",
            "Epoch 493/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.7280e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6633e-09\n",
            "Epoch 494/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6479e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6555e-09\n",
            "Epoch 495/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6022e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6638e-09\n",
            "Epoch 496/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7414e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6513e-09\n",
            "Epoch 497/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8135e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6836e-09\n",
            "Epoch 498/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6443e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6668e-09\n",
            "Epoch 499/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6591e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6525e-09\n",
            "Epoch 500/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6555e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6576e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.plot(history.history['binary_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "y6dgf8EcpEE4",
        "outputId": "86809a31-9abb-4594-f503-c0cade4cd489"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ea6a53d4390>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.round(model.predict(X_test)).flatten()\n",
        "\n",
        "results['Neural Network'] = [accuracy_score(y_test, y_pred),\n",
        "                             precision_score(y_test, y_pred, average='weighted'),\n",
        "                             recall_score(y_test, y_pred, average='weighted'),\n",
        "                             f1_score(y_test, y_pred, average='weighted'),\n",
        "                             training_time]\n",
        "print(\"Accuracy:\", results['Neural Network'][0])\n",
        "print(\"Precision:\", results['Neural Network'][1])\n",
        "print(\"Recall:\", results['Neural Network'][2])\n",
        "print(\"F1-score:\", results['Neural Network'][3])\n",
        "print(\"Training Time:\", results['Neural Network'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-kWVBeaKbxE",
        "outputId": "ccc59df4-c283-4195-8466-76a5a34c3739"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 314.6143274307251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Result Comparison and Analysis 📈"
      ],
      "metadata": {
        "id": "5Svry9nRpSCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time'])\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "BxPpTKIaZO8k",
        "outputId": "1de7dec2-3f0b-4d19-df19-9cab57e50cb5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Accuracy  Precision    Recall  \\\n",
              "Logistic Regression                       0.992667   0.992722  0.992667   \n",
              "K-Nearest Neighbors (KNN)                 0.961333   0.963767  0.961333   \n",
              "Decision Trees                            1.000000   1.000000  1.000000   \n",
              "Random Forest                             1.000000   1.000000  1.000000   \n",
              "Extra Trees                               1.000000   1.000000  1.000000   \n",
              "Support Vector Machines                   1.000000   1.000000  1.000000   \n",
              "Neural Networks (Multi-layer Perceptron)  1.000000   1.000000  1.000000   \n",
              "AdaBoost                                  1.000000   1.000000  1.000000   \n",
              "XGBoost                                   1.000000   1.000000  1.000000   \n",
              "CatBoost                                  1.000000   1.000000  1.000000   \n",
              "Stochastic Gradient Descent (SGD)         1.000000   1.000000  1.000000   \n",
              "Neural Network                            1.000000   1.000000  1.000000   \n",
              "\n",
              "                                          F1-Score  Training Time  \n",
              "Logistic Regression                       0.992657       0.090587  \n",
              "K-Nearest Neighbors (KNN)                 0.961549       0.590891  \n",
              "Decision Trees                            1.000000       0.129702  \n",
              "Random Forest                             1.000000       0.909500  \n",
              "Extra Trees                               1.000000       0.741822  \n",
              "Support Vector Machines                   1.000000       0.686101  \n",
              "Neural Networks (Multi-layer Perceptron)  1.000000      10.511328  \n",
              "AdaBoost                                  1.000000       1.246668  \n",
              "XGBoost                                   1.000000       3.944979  \n",
              "CatBoost                                  1.000000      34.987231  \n",
              "Stochastic Gradient Descent (SGD)         1.000000       0.003099  \n",
              "Neural Network                            1.000000     314.614327  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00bac59c-303f-4237-80c0-eeb0de1f9a46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.992667</td>\n",
              "      <td>0.992722</td>\n",
              "      <td>0.992667</td>\n",
              "      <td>0.992657</td>\n",
              "      <td>0.090587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbors (KNN)</th>\n",
              "      <td>0.961333</td>\n",
              "      <td>0.963767</td>\n",
              "      <td>0.961333</td>\n",
              "      <td>0.961549</td>\n",
              "      <td>0.590891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Trees</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.909500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra Trees</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.741822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machines</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.686101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Networks (Multi-layer Perceptron)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.511328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.246668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.944979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>34.987231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stochastic Gradient Descent (SGD)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>314.614327</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00bac59c-303f-4237-80c0-eeb0de1f9a46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00bac59c-303f-4237-80c0-eeb0de1f9a46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00bac59c-303f-4237-80c0-eeb0de1f9a46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7bde77b4-e3c6-4490-8dcf-b21b36c570b4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bde77b4-e3c6-4490-8dcf-b21b36c570b4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7bde77b4-e3c6-4490-8dcf-b21b36c570b4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bb71b7f4-b30c-442e-8cec-a040c1587bee\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb71b7f4-b30c-442e-8cec-a040c1587bee button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011170397386744012,\n        \"min\": 0.9613333333333334,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9926666666666667,\n          0.9613333333333334,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010479518297760882,\n        \"min\": 0.9637670892742709,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9927224312410754,\n          0.9637670892742709,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011170397386744012,\n        \"min\": 0.9613333333333334,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9926666666666667,\n          0.9613333333333334,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011109528176126307,\n        \"min\": 0.9615490402431071,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.992657134228,\n          0.9615490402431071,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.96098935983102,\n        \"min\": 0.0030994415283203125,\n        \"max\": 314.6143274307251,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.0030994415283203125,\n          34.9872305393219,\n          0.09058690071105957\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Best Performing Model - Linear Discriminant Analysis (LDA)"
      ],
      "metadata": {
        "id": "5CwALZoTpgOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Convert SparseTensor to dense numpy arrays\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Initialize Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lda.fit(X_train_dense, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lda.predict(X_test_dense)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHigg7lQpqu4",
        "outputId": "51d900ca-f032-4333-d8c1-9b4b0bef9639"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9906666666666667\n",
            "Precision: 0.9907830650972412\n",
            "Recall: 0.9906666666666667\n",
            "F1-score: 0.9906792563465785\n",
            "Training Time: 3.9504804611206055\n",
            "CPU times: user 6.72 s, sys: 711 ms, total: 7.43 s\n",
            "Wall time: 4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bc_aBu5pxyU",
        "outputId": "1a51cd53-6665-4b5e-c41e-495799c1175b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       599\n",
            "           1       1.00      0.99      0.99       901\n",
            "\n",
            "    accuracy                           0.99      1500\n",
            "   macro avg       0.99      0.99      0.99      1500\n",
            "weighted avg       0.99      0.99      0.99      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix-"
      ],
      "metadata": {
        "id": "_qxMzBIYp6-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "classes = ['0', '1']\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "\n",
        "# Fill the cells of the confusion matrix with values\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "D97HTxxOp5tk",
        "outputId": "de232b84-56b7-4357-f6ae-47b758fa7acf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Iterate over each classifier\n",
        "classifiers = {\n",
        "    'Logistic Regression': logistic,\n",
        "    'K-Nearest Neighbors (KNN)': knn,\n",
        "    'Gaussian Naive Bayes': gnb,\n",
        "    'Decision Trees': dt,\n",
        "    'Random Forest': rf,\n",
        "    'Extra Trees': et,\n",
        "    'Support Vector Machines': svm,\n",
        "    'Neural Networks (Multi-layer Perceptron)': mlp,\n",
        "    'AdaBoost': ada,\n",
        "    'XGBoost': xgboost,\n",
        "    'LightGBM': lgbm,\n",
        "    'CatBoost': cat,\n",
        "    'Stochastic Gradient Descent (SGD)': sgd,\n",
        "    'Linear Discriminant Analysis': lda,\n",
        "    'Quadratic Discriminant Analysis': qda,\n",
        "    'Neural Network': model\n",
        "}\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "    try:\n",
        "        # Predict using the classifier\n",
        "        if name == 'Neural Network':  # For neural network model\n",
        "            # Convert SparseTensor to dense numpy arrays\n",
        "            X_test_dense = X_test.toarray()\n",
        "            y_pred = np.round(classifier.predict(X_test_dense)).flatten()\n",
        "        elif name == 'LightGBM':\n",
        "            # Predict using LightGBM model directly\n",
        "            y_pred = classifier.predict(X_test)\n",
        "        else:\n",
        "            # Convert TF-IDF transformed sparse matrices to dense numpy arrays\n",
        "            X_test_dense = X_test.toarray()\n",
        "            y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "        # Get indices of rows predicted as hate speech\n",
        "        hate_speech_indices = np.where(y_pred == 1)[0]\n",
        "\n",
        "        # Get the rows of speeches predicted as hate speech\n",
        "        hate_speech_rows = df1.iloc[hate_speech_indices]\n",
        "\n",
        "        # Display the hate speech rows\n",
        "        print(f\"Hate speech detected by {name} classifier:\")\n",
        "        print(hate_speech_rows)\n",
        "\n",
        "        # Save the hate speech rows to a CSV file\n",
        "        hate_speech_rows.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/{name}_hate_speech.csv\", index=False)\n",
        "    except AttributeError:\n",
        "        print(f\"AttributeError: Cannot predict using {name}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXZ-ElHbqkc7",
        "outputId": "60ceef67-b994-47ab-c715-be1aa373b987"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate speech detected by Logistic Regression classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[910 rows x 2 columns]\n",
            "Hate speech detected by K-Nearest Neighbors (KNN) classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "12    Saying 'Arabs' is a generalization and does no...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[853 rows x 2 columns]\n",
            "Hate speech detected by Gaussian Naive Bayes classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[898 rows x 2 columns]\n",
            "Hate speech detected by Decision Trees classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Random Forest classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Extra Trees classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Support Vector Machines classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Neural Networks (Multi-layer Perceptron) classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by AdaBoost classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by XGBoost classifier:\n",
            "                                                 speech  class\n",
            "2     It's a shame that there is no longer the cruci...      0\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "5     These Islamic will bring us back to the Middle...      0\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "...                                                 ...    ...\n",
            "1494                      I wish all of them would die.      0\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1498           A real Islamic invasion is taking place.      0\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[1274 rows x 2 columns]\n",
            "AttributeError: Cannot predict using LightGBM.\n",
            "Hate speech detected by CatBoost classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Stochastic Gradient Descent (SGD) classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Linear Discriminant Analysis classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[891 rows x 2 columns]\n",
            "Hate speech detected by Quadratic Discriminant Analysis classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Hate speech detected by Neural Network classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zVxsPfIUrvYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}