{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjwalroyal14/CautiousSpeak/blob/main/Hate_speech%C2%A0detection_using_ML_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Detection using ML classifiers**"
      ],
      "metadata": {
        "id": "FmrsC_C8FqQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML classifiers vs Neural Network**"
      ],
      "metadata": {
        "id": "RkdTDsLSQipW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insatlling necesaary libraries"
      ],
      "metadata": {
        "id": "rDvnum5xRDjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBLZGYS_B8Wf",
        "outputId": "aa7aaa62-c3f1-4bda-ccd4-39a50b9992f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install catboost\n",
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiiFQZAHCM_y",
        "outputId": "c0211dca-d3ba-49b7-e621-2a71bfb90208"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.1.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.11.4)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (25.1.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy seaborn matplotlib pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O28n_zaChJf",
        "outputId": "fc84e9f4-2c14-4807-a2ff-5f0138724931"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.11/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (4.67.1)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.6)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.0.5)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.13.0)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.7.0)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (4.5.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (8.7.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.5.0)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (5.24.1)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.2.1)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.10.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.14.4)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.11/dist-packages (from pycaret) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from pycaret) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.11/dist-packages (from pycaret) (3.1.1)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.11/dist-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders>=2.4.0->pycaret) (1.0.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (0.1.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.6.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.15)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.55.0->pycaret) (0.43.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.14.0->pycaret) (9.1.2)\n",
            "Requirement already satisfied: dash>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.0.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.18)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.4.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from pmdarima>=2.0.4->pycaret) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->pycaret) (2025.4.26)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.13.2)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.24.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.3.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.7)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "woSWFeW3RNkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tNPX6c6sC02b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgbm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "XFA5-fbeC4Pq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.plots import plot_convergence\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "WCu74VfLC7n3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from pycaret.classification import *"
      ],
      "metadata": {
        "id": "uqOdhxvWC8k0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Detection dataset**"
      ],
      "metadata": {
        "id": "6h5pcw1BRW1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPBjhZX1C_lk",
        "outputId": "e7d4ac8d-ea8d-4f26-86fb-770844af788f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/CONAN_English_RewardTest.csv')\n",
        "df2=pd.read_csv('/content/drive/MyDrive/CONAN_Dataset - CONAN_English_RewardTrain.csv')\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "L-ROGajtDR1O",
        "outputId": "a7a75b57-d6d7-4e0b-cad9-7cdc4ea7e2b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 speech  class\n",
              "0     The Arabs want to impose their religion and to...      0\n",
              "1     The Arabs are all terrorists and they want to ...      0\n",
              "2     It's a shame that there is no longer the cruci...      0\n",
              "3     Then we must castrate even Italians who rape, ...      1\n",
              "4     The Arabs do not want to impose their religion...      1\n",
              "...                                                 ...    ...\n",
              "1495  What is your problem with Muslims? They are pe...      1\n",
              "1496  Did you know that the only terrorist attacks i...      1\n",
              "1497  The Arabs want to impose their religion and to...      0\n",
              "1498           A real Islamic invasion is taking place.      0\n",
              "1499  Hi, I also condemn these acts that are so atro...      1\n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a136a6cd-88b9-432f-9fdd-ab4ae5dbc5eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Arabs are all terrorists and they want to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's a shame that there is no longer the cruci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then we must castrate even Italians who rape, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Arabs do not want to impose their religion...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>What is your problem with Muslims? They are pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>Did you know that the only terrorist attacks i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>A real Islamic invasion is taking place.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>Hi, I also condemn these acts that are so atro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a136a6cd-88b9-432f-9fdd-ab4ae5dbc5eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a136a6cd-88b9-432f-9fdd-ab4ae5dbc5eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a136a6cd-88b9-432f-9fdd-ab4ae5dbc5eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5dc6418e-8bf5-4f38-8d3e-342e6f8552dd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5dc6418e-8bf5-4f38-8d3e-342e6f8552dd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5dc6418e-8bf5-4f38-8d3e-342e6f8552dd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4d2c3cea-c3ed-4da4-b8aa-a88464fc0028\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4d2c3cea-c3ed-4da4-b8aa-a88464fc0028 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 786,\n        \"samples\": [\n          \"Tolerance of others' religions must be mutual. You cannot convict a person based on his faith.\",\n          \"There are also many Italian Muslims why we stop them from practising their beliefs? Why we give this opportunity only to Catholics? Why mosques bother you? And then I assure you that the number of mosques is negligible compared to the number of Catholic churches.\",\n          \"The problem lies in having a more open, secular and human mentality without blinders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "axfZRrUyDfZK",
        "outputId": "c79755e1-30c2-478d-bb9a-eb5da7260c16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              speech  class\n",
              "0  The Arabs want to impose their religion and to...      0\n",
              "1  The Arabs are all terrorists and they want to ...      0\n",
              "2  It's a shame that there is no longer the cruci...      0\n",
              "3  Then we must castrate even Italians who rape, ...      1\n",
              "4  The Arabs do not want to impose their religion...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c79aeecd-1e58-412e-8b8a-765b5750985a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Arabs are all terrorists and they want to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's a shame that there is no longer the cruci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then we must castrate even Italians who rape, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Arabs do not want to impose their religion...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c79aeecd-1e58-412e-8b8a-765b5750985a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c79aeecd-1e58-412e-8b8a-765b5750985a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c79aeecd-1e58-412e-8b8a-765b5750985a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dc8797de-723f-48ad-b9ed-03489cef089e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc8797de-723f-48ad-b9ed-03489cef089e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dc8797de-723f-48ad-b9ed-03489cef089e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 786,\n        \"samples\": [\n          \"Tolerance of others' religions must be mutual. You cannot convict a person based on his faith.\",\n          \"There are also many Italian Muslims why we stop them from practising their beliefs? Why we give this opportunity only to Catholics? Why mosques bother you? And then I assure you that the number of mosques is negligible compared to the number of Catholic churches.\",\n          \"The problem lies in having a more open, secular and human mentality without blinders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8lcc6JCDiZd",
        "outputId": "ce208ba9-09ea-49d8-f392-db106a009cb8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             class\n",
            "count  1500.000000\n",
            "mean      0.600667\n",
            "std       0.489925\n",
            "min       0.000000\n",
            "25%       0.000000\n",
            "50%       1.000000\n",
            "75%       1.000000\n",
            "max       1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SETTING UP THE DATA FOR MODELLING\n",
        "\n",
        "setup(data=df2, target='class')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "6feDppxhEN7B",
        "outputId": "9e0b44df-b118-4393-ab92-0419304b4764"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x78308bdee450>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_b2be4_row8_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_b2be4\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_b2be4_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_b2be4_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_b2be4_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
              "      <td id=\"T_b2be4_row0_col1\" class=\"data row0 col1\" >7408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_b2be4_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_b2be4_row1_col1\" class=\"data row1 col1\" >class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_b2be4_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
              "      <td id=\"T_b2be4_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_b2be4_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
              "      <td id=\"T_b2be4_row3_col1\" class=\"data row3 col1\" >(1500, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_b2be4_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_b2be4_row4_col1\" class=\"data row4 col1\" >(1500, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_b2be4_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_b2be4_row5_col1\" class=\"data row5 col1\" >(1050, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_b2be4_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_b2be4_row6_col1\" class=\"data row6 col1\" >(450, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_b2be4_row7_col0\" class=\"data row7 col0\" >Categorical features</td>\n",
              "      <td id=\"T_b2be4_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_b2be4_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
              "      <td id=\"T_b2be4_row8_col1\" class=\"data row8 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_b2be4_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
              "      <td id=\"T_b2be4_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_b2be4_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
              "      <td id=\"T_b2be4_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_b2be4_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
              "      <td id=\"T_b2be4_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_b2be4_row12_col0\" class=\"data row12 col0\" >Maximum one-hot encoding</td>\n",
              "      <td id=\"T_b2be4_row12_col1\" class=\"data row12 col1\" >25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_b2be4_row13_col0\" class=\"data row13 col0\" >Encoding method</td>\n",
              "      <td id=\"T_b2be4_row13_col1\" class=\"data row13 col1\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_b2be4_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_b2be4_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_b2be4_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
              "      <td id=\"T_b2be4_row15_col1\" class=\"data row15 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_b2be4_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_b2be4_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_b2be4_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
              "      <td id=\"T_b2be4_row17_col1\" class=\"data row17 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_b2be4_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_b2be4_row18_col1\" class=\"data row18 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_b2be4_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_b2be4_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b2be4_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_b2be4_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
              "      <td id=\"T_b2be4_row20_col1\" class=\"data row20 col1\" >d66e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pycaret.classification.oop.ClassificationExperiment at 0x782f7c865b10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Data for Modeling-**"
      ],
      "metadata": {
        "id": "J958RiNumTXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= df2['speech']\n",
        "y_train= df2['class']"
      ],
      "metadata": {
        "id": "8Pi5UWoKEd3W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test= df1['speech']\n",
        "y_test= df1['class']"
      ],
      "metadata": {
        "id": "oVW1Yl2zEoyb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming X_train is a pandas Series containing text data\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "WomAXi9441Td"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbNYkTUEuP0",
        "outputId": "f49e4a7d-e63d-42ac-8e4b-0727a446061f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 2246)\n",
            "(1500,)\n",
            "(1500, 2246)\n",
            "(1500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to store the results\n",
        "results = {}"
      ],
      "metadata": {
        "id": "y032q_2tE3PX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating Various ML Models-**"
      ],
      "metadata": {
        "id": "_rxn1TFtmcEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Logistic regression-**"
      ],
      "metadata": {
        "id": "q7EqC_TPE_CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(X_train, y_train)\n",
        "y_pred = logistic.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Logistic Regression'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Logistic Regression'][0])\n",
        "print(\"Precision:\", results['Logistic Regression'][1])\n",
        "print(\"Recall:\", results['Logistic Regression'][2])\n",
        "print(\"F1-score:\", results['Logistic Regression'][3])\n",
        "print(\"Training Time:\", results['Logistic Regression'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxAVURAE6Cf",
        "outputId": "647a0177-4d7e-4036-b066-0ef5c9616ef0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9926666666666667\n",
            "Precision: 0.9927224312410754\n",
            "Recall: 0.9926666666666667\n",
            "F1-score: 0.992657134228\n",
            "Training Time: 0.04000067710876465\n",
            "CPU times: user 37.4 ms, sys: 1.48 ms, total: 38.8 ms\n",
            "Wall time: 61.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. K-Nearest Neighbors (KNN)**"
      ],
      "metadata": {
        "id": "thJBSMzpFBZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['K-Nearest Neighbors (KNN)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['K-Nearest Neighbors (KNN)'][0])\n",
        "print(\"Precision:\", results['K-Nearest Neighbors (KNN)'][1])\n",
        "print(\"Recall:\", results['K-Nearest Neighbors (KNN)'][2])\n",
        "print(\"F1-score:\", results['K-Nearest Neighbors (KNN)'][3])\n",
        "print(\"Training Time:\", results['K-Nearest Neighbors (KNN)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePCWQSiWE-MU",
        "outputId": "d3d87459-6698-4b5f-a2dc-7f3f88370157"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9613333333333334\n",
            "Precision: 0.9637670892742709\n",
            "Recall: 0.9613333333333334\n",
            "F1-score: 0.9615490402431071\n",
            "Training Time: 0.3860800266265869\n",
            "CPU times: user 141 ms, sys: 92.7 ms, total: 233 ms\n",
            "Wall time: 402 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Gaussian Naive Bayes (GaussianNB)**"
      ],
      "metadata": {
        "id": "cy3G5N9gFKM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "gnb.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = gnb.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEDxCYAFO56",
        "outputId": "9d044081-95cd-4bcf-d411-93bbdc5b1ff8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.998\n",
            "Precision: 0.9980099667774087\n",
            "Recall: 0.998\n",
            "F1-score: 0.9980008303252941\n",
            "Training Time: 0.1571180820465088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Decision Trees**"
      ],
      "metadata": {
        "id": "ynFNkD3zFRxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Decision Trees'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Decision Trees'][0])\n",
        "print(\"Precision:\", results['Decision Trees'][1])\n",
        "print(\"Recall:\", results['Decision Trees'][2])\n",
        "print(\"F1-score:\", results['Decision Trees'][3])\n",
        "print(\"Training Time:\", results['Decision Trees'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpyN_LK-FQej",
        "outputId": "ef1f6429-bbac-43e8-ab5e-19d6745e5fff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.12174606323242188\n",
            "CPU times: user 81.1 ms, sys: 0 ns, total: 81.1 ms\n",
            "Wall time: 166 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Random Forest**"
      ],
      "metadata": {
        "id": "jH0Z2EmuFZ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Random Forest'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Random Forest'][0])\n",
        "print(\"Precision:\", results['Random Forest'][1])\n",
        "print(\"Recall:\", results['Random Forest'][2])\n",
        "print(\"F1-score:\", results['Random Forest'][3])\n",
        "print(\"Training Time:\", results['Random Forest'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3vMlSWGFVuL",
        "outputId": "b46264ef-dfb6-4cee-de47-c8a80ddecc09"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.8520467281341553\n",
            "CPU times: user 595 ms, sys: 9.25 ms, total: 605 ms\n",
            "Wall time: 864 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Extra Trees**"
      ],
      "metadata": {
        "id": "INdeC4kgFcvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "y_pred = et.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Extra Trees'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Extra Trees'][0])\n",
        "print(\"Precision:\", results['Extra Trees'][1])\n",
        "print(\"Recall:\", results['Extra Trees'][2])\n",
        "print(\"F1-score:\", results['Extra Trees'][3])\n",
        "print(\"Training Time:\", results['Extra Trees'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV-BN4k6FeN1",
        "outputId": "dfd77a20-5d76-4740-b7df-31a23e31a92d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.7830729484558105\n",
            "CPU times: user 545 ms, sys: 3.79 ms, total: 549 ms\n",
            "Wall time: 797 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "hfOEyHCaFh6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Support Vector Machines'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Support Vector Machines'][0])\n",
        "print(\"Precision:\", results['Support Vector Machines'][1])\n",
        "print(\"Recall:\", results['Support Vector Machines'][2])\n",
        "print(\"F1-score:\", results['Support Vector Machines'][3])\n",
        "print(\"Training Time:\", results['Support Vector Machines'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHqu1QAqFl2a",
        "outputId": "14ef8a57-348d-4899-e04b-33534859dfdb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.5474233627319336\n",
            "CPU times: user 406 ms, sys: 7.11 ms, total: 413 ms\n",
            "Wall time: 572 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Neural Network MLP (Multi-layer Perceptron)**"
      ],
      "metadata": {
        "id": "DCnM0mTuFqA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Neural Networks (Multi-layer Perceptron)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Neural Networks (Multi-layer Perceptron)'][0])\n",
        "print(\"Precision:\", results['Neural Networks (Multi-layer Perceptron)'][1])\n",
        "print(\"Recall:\", results['Neural Networks (Multi-layer Perceptron)'][2])\n",
        "print(\"F1-score:\", results['Neural Networks (Multi-layer Perceptron)'][3])\n",
        "print(\"Training Time:\", results['Neural Networks (Multi-layer Perceptron)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCySSmY2FpXg",
        "outputId": "7487fa9a-968d-4626-bad6-2e41056fca4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 11.617569923400879\n",
            "CPU times: user 5.66 s, sys: 3.98 s, total: 9.64 s\n",
            "Wall time: 11.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. AdaBoost**"
      ],
      "metadata": {
        "id": "FURePsNQHBoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['AdaBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['AdaBoost'][0])\n",
        "print(\"Precision:\", results['AdaBoost'][1])\n",
        "print(\"Recall:\", results['AdaBoost'][2])\n",
        "print(\"F1-score:\", results['AdaBoost'][3])\n",
        "print(\"Training Time:\", results['AdaBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E19VajPaHDoO",
        "outputId": "85ee7c82-2f27-49c4-f4fa-af31a8a972f9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.93149733543396\n",
            "CPU times: user 533 ms, sys: 29.1 ms, total: 562 ms\n",
            "Wall time: 948 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. XGBoost**"
      ],
      "metadata": {
        "id": "Gel0ZJOQHTQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "xgboost = xgb.XGBClassifier()\n",
        "xgboost.fit(X_train, y_train)\n",
        "y_pred = xgboost.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['XGBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['XGBoost'][0])\n",
        "print(\"Precision:\", results['XGBoost'][1])\n",
        "print(\"Recall:\", results['XGBoost'][2])\n",
        "print(\"F1-score:\", results['XGBoost'][3])\n",
        "print(\"Training Time:\", results['XGBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67t0JFLnHSkf",
        "outputId": "7ab67377-517e-4502-e2fb-d287521829e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 8.296206712722778\n",
            "CPU times: user 6.17 s, sys: 2.88 ms, total: 6.18 s\n",
            "Wall time: 8.38 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Light Gradient Boosting Machine (LGBM)**"
      ],
      "metadata": {
        "id": "KfG8dOHrJqSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm\n",
        "\n",
        "# Initialize LightGBM classifier\n",
        "lgbm_classifier = lgbm.LGBMClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lgbm_classifier.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lgbm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KsKHaGYJpWF",
        "outputId": "44bc7903-e119-4d7c-f916-56092e363a74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 901, number of negative: 599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011786 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4542\n",
            "[LightGBM] [Info] Number of data points in the train set: 1500, number of used features: 202\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.600667 -> initscore=0.408244\n",
            "[LightGBM] [Info] Start training from score 0.408244\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.5419774055480957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. CatBoost**"
      ],
      "metadata": {
        "id": "EUWWiKAeJ25H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "cat = CatBoostClassifier()\n",
        "cat.fit(X_train, y_train)\n",
        "y_pred = cat.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['CatBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['CatBoost'][0])\n",
        "print(\"Precision:\", results['CatBoost'][1])\n",
        "print(\"Recall:\", results['CatBoost'][2])\n",
        "print(\"F1-score:\", results['CatBoost'][3])\n",
        "print(\"Training Time:\", results['CatBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ymFpkSEJ5dv",
        "outputId": "e10c1b60-aa3b-4406-f412-62958b21323b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.01225\n",
            "0:\tlearn: 0.6810806\ttotal: 198ms\tremaining: 3m 18s\n",
            "1:\tlearn: 0.6701537\ttotal: 352ms\tremaining: 2m 55s\n",
            "2:\tlearn: 0.6571809\ttotal: 456ms\tremaining: 2m 31s\n",
            "3:\tlearn: 0.6463226\ttotal: 519ms\tremaining: 2m 9s\n",
            "4:\tlearn: 0.6324722\ttotal: 621ms\tremaining: 2m 3s\n",
            "5:\tlearn: 0.6234640\ttotal: 735ms\tremaining: 2m 1s\n",
            "6:\tlearn: 0.6152077\ttotal: 808ms\tremaining: 1m 54s\n",
            "7:\tlearn: 0.6047809\ttotal: 881ms\tremaining: 1m 49s\n",
            "8:\tlearn: 0.5921031\ttotal: 976ms\tremaining: 1m 47s\n",
            "9:\tlearn: 0.5843081\ttotal: 1.1s\tremaining: 1m 48s\n",
            "10:\tlearn: 0.5726262\ttotal: 1.21s\tremaining: 1m 48s\n",
            "11:\tlearn: 0.5643372\ttotal: 1.27s\tremaining: 1m 44s\n",
            "12:\tlearn: 0.5577445\ttotal: 1.33s\tremaining: 1m 41s\n",
            "13:\tlearn: 0.5492630\ttotal: 1.39s\tremaining: 1m 37s\n",
            "14:\tlearn: 0.5406030\ttotal: 1.45s\tremaining: 1m 34s\n",
            "15:\tlearn: 0.5334646\ttotal: 1.54s\tremaining: 1m 34s\n",
            "16:\tlearn: 0.5260592\ttotal: 1.61s\tremaining: 1m 32s\n",
            "17:\tlearn: 0.5160168\ttotal: 1.67s\tremaining: 1m 31s\n",
            "18:\tlearn: 0.5055446\ttotal: 1.72s\tremaining: 1m 28s\n",
            "19:\tlearn: 0.4994996\ttotal: 1.81s\tremaining: 1m 28s\n",
            "20:\tlearn: 0.4927043\ttotal: 1.88s\tremaining: 1m 27s\n",
            "21:\tlearn: 0.4851101\ttotal: 1.94s\tremaining: 1m 26s\n",
            "22:\tlearn: 0.4788551\ttotal: 2.01s\tremaining: 1m 25s\n",
            "23:\tlearn: 0.4727389\ttotal: 2.1s\tremaining: 1m 25s\n",
            "24:\tlearn: 0.4645408\ttotal: 2.16s\tremaining: 1m 24s\n",
            "25:\tlearn: 0.4575083\ttotal: 2.22s\tremaining: 1m 23s\n",
            "26:\tlearn: 0.4468580\ttotal: 2.28s\tremaining: 1m 22s\n",
            "27:\tlearn: 0.4397846\ttotal: 2.35s\tremaining: 1m 21s\n",
            "28:\tlearn: 0.4346788\ttotal: 2.4s\tremaining: 1m 20s\n",
            "29:\tlearn: 0.4274945\ttotal: 2.47s\tremaining: 1m 19s\n",
            "30:\tlearn: 0.4216115\ttotal: 2.52s\tremaining: 1m 18s\n",
            "31:\tlearn: 0.4140000\ttotal: 2.56s\tremaining: 1m 17s\n",
            "32:\tlearn: 0.4071219\ttotal: 2.64s\tremaining: 1m 17s\n",
            "33:\tlearn: 0.4034946\ttotal: 2.69s\tremaining: 1m 16s\n",
            "34:\tlearn: 0.3987041\ttotal: 2.74s\tremaining: 1m 15s\n",
            "35:\tlearn: 0.3952557\ttotal: 2.79s\tremaining: 1m 14s\n",
            "36:\tlearn: 0.3907685\ttotal: 2.83s\tremaining: 1m 13s\n",
            "37:\tlearn: 0.3858030\ttotal: 2.87s\tremaining: 1m 12s\n",
            "38:\tlearn: 0.3801329\ttotal: 2.93s\tremaining: 1m 12s\n",
            "39:\tlearn: 0.3754808\ttotal: 2.97s\tremaining: 1m 11s\n",
            "40:\tlearn: 0.3704369\ttotal: 3.02s\tremaining: 1m 10s\n",
            "41:\tlearn: 0.3663734\ttotal: 3.07s\tremaining: 1m 10s\n",
            "42:\tlearn: 0.3624142\ttotal: 3.12s\tremaining: 1m 9s\n",
            "43:\tlearn: 0.3572405\ttotal: 3.17s\tremaining: 1m 8s\n",
            "44:\tlearn: 0.3523054\ttotal: 3.21s\tremaining: 1m 8s\n",
            "45:\tlearn: 0.3484798\ttotal: 3.27s\tremaining: 1m 7s\n",
            "46:\tlearn: 0.3450678\ttotal: 3.32s\tremaining: 1m 7s\n",
            "47:\tlearn: 0.3416664\ttotal: 3.37s\tremaining: 1m 6s\n",
            "48:\tlearn: 0.3381269\ttotal: 3.39s\tremaining: 1m 5s\n",
            "49:\tlearn: 0.3337103\ttotal: 3.43s\tremaining: 1m 5s\n",
            "50:\tlearn: 0.3300990\ttotal: 3.49s\tremaining: 1m 4s\n",
            "51:\tlearn: 0.3251562\ttotal: 3.53s\tremaining: 1m 4s\n",
            "52:\tlearn: 0.3210438\ttotal: 3.59s\tremaining: 1m 4s\n",
            "53:\tlearn: 0.3177520\ttotal: 3.64s\tremaining: 1m 3s\n",
            "54:\tlearn: 0.3150415\ttotal: 3.7s\tremaining: 1m 3s\n",
            "55:\tlearn: 0.3117218\ttotal: 3.72s\tremaining: 1m 2s\n",
            "56:\tlearn: 0.3076716\ttotal: 3.75s\tremaining: 1m 2s\n",
            "57:\tlearn: 0.3033684\ttotal: 3.78s\tremaining: 1m 1s\n",
            "58:\tlearn: 0.3001569\ttotal: 3.8s\tremaining: 1m\n",
            "59:\tlearn: 0.2962988\ttotal: 3.84s\tremaining: 1m\n",
            "60:\tlearn: 0.2938340\ttotal: 3.93s\tremaining: 1m\n",
            "61:\tlearn: 0.2896705\ttotal: 4.01s\tremaining: 1m\n",
            "62:\tlearn: 0.2876744\ttotal: 4.06s\tremaining: 1m\n",
            "63:\tlearn: 0.2850324\ttotal: 4.11s\tremaining: 1m\n",
            "64:\tlearn: 0.2827937\ttotal: 4.15s\tremaining: 59.7s\n",
            "65:\tlearn: 0.2802532\ttotal: 4.22s\tremaining: 59.7s\n",
            "66:\tlearn: 0.2771693\ttotal: 4.28s\tremaining: 59.7s\n",
            "67:\tlearn: 0.2747960\ttotal: 4.32s\tremaining: 59.3s\n",
            "68:\tlearn: 0.2722805\ttotal: 4.36s\tremaining: 58.9s\n",
            "69:\tlearn: 0.2705450\ttotal: 4.39s\tremaining: 58.3s\n",
            "70:\tlearn: 0.2683979\ttotal: 4.42s\tremaining: 57.9s\n",
            "71:\tlearn: 0.2663373\ttotal: 4.48s\tremaining: 57.8s\n",
            "72:\tlearn: 0.2641963\ttotal: 4.54s\tremaining: 57.7s\n",
            "73:\tlearn: 0.2622357\ttotal: 4.59s\tremaining: 57.4s\n",
            "74:\tlearn: 0.2597294\ttotal: 4.63s\tremaining: 57.1s\n",
            "75:\tlearn: 0.2578898\ttotal: 4.68s\tremaining: 56.9s\n",
            "76:\tlearn: 0.2557316\ttotal: 4.76s\tremaining: 57s\n",
            "77:\tlearn: 0.2535732\ttotal: 4.82s\tremaining: 56.9s\n",
            "78:\tlearn: 0.2511649\ttotal: 4.88s\tremaining: 56.9s\n",
            "79:\tlearn: 0.2490372\ttotal: 4.91s\tremaining: 56.5s\n",
            "80:\tlearn: 0.2475874\ttotal: 4.94s\tremaining: 56s\n",
            "81:\tlearn: 0.2453250\ttotal: 4.98s\tremaining: 55.7s\n",
            "82:\tlearn: 0.2431713\ttotal: 5.02s\tremaining: 55.5s\n",
            "83:\tlearn: 0.2414642\ttotal: 5.07s\tremaining: 55.2s\n",
            "84:\tlearn: 0.2397018\ttotal: 5.11s\tremaining: 55s\n",
            "85:\tlearn: 0.2380128\ttotal: 5.15s\tremaining: 54.8s\n",
            "86:\tlearn: 0.2355461\ttotal: 5.21s\tremaining: 54.6s\n",
            "87:\tlearn: 0.2339445\ttotal: 5.25s\tremaining: 54.4s\n",
            "88:\tlearn: 0.2320667\ttotal: 5.31s\tremaining: 54.4s\n",
            "89:\tlearn: 0.2306960\ttotal: 5.36s\tremaining: 54.2s\n",
            "90:\tlearn: 0.2287348\ttotal: 5.4s\tremaining: 54s\n",
            "91:\tlearn: 0.2271670\ttotal: 5.44s\tremaining: 53.7s\n",
            "92:\tlearn: 0.2255833\ttotal: 5.49s\tremaining: 53.5s\n",
            "93:\tlearn: 0.2228967\ttotal: 5.54s\tremaining: 53.4s\n",
            "94:\tlearn: 0.2204817\ttotal: 5.59s\tremaining: 53.3s\n",
            "95:\tlearn: 0.2188565\ttotal: 5.63s\tremaining: 53.1s\n",
            "96:\tlearn: 0.2168701\ttotal: 5.67s\tremaining: 52.8s\n",
            "97:\tlearn: 0.2149205\ttotal: 5.74s\tremaining: 52.8s\n",
            "98:\tlearn: 0.2128968\ttotal: 5.8s\tremaining: 52.8s\n",
            "99:\tlearn: 0.2115958\ttotal: 5.86s\tremaining: 52.7s\n",
            "100:\tlearn: 0.2096899\ttotal: 5.91s\tremaining: 52.6s\n",
            "101:\tlearn: 0.2081648\ttotal: 5.97s\tremaining: 52.6s\n",
            "102:\tlearn: 0.2057496\ttotal: 6.05s\tremaining: 52.7s\n",
            "103:\tlearn: 0.2046510\ttotal: 6.13s\tremaining: 52.8s\n",
            "104:\tlearn: 0.2032974\ttotal: 6.19s\tremaining: 52.8s\n",
            "105:\tlearn: 0.2018709\ttotal: 6.25s\tremaining: 52.7s\n",
            "106:\tlearn: 0.2006802\ttotal: 6.28s\tremaining: 52.4s\n",
            "107:\tlearn: 0.1996458\ttotal: 6.32s\tremaining: 52.2s\n",
            "108:\tlearn: 0.1984366\ttotal: 6.35s\tremaining: 51.9s\n",
            "109:\tlearn: 0.1972428\ttotal: 6.43s\tremaining: 52s\n",
            "110:\tlearn: 0.1956846\ttotal: 6.48s\tremaining: 51.9s\n",
            "111:\tlearn: 0.1944334\ttotal: 6.51s\tremaining: 51.6s\n",
            "112:\tlearn: 0.1931047\ttotal: 6.54s\tremaining: 51.3s\n",
            "113:\tlearn: 0.1920598\ttotal: 6.62s\tremaining: 51.4s\n",
            "114:\tlearn: 0.1909816\ttotal: 6.68s\tremaining: 51.4s\n",
            "115:\tlearn: 0.1899069\ttotal: 6.76s\tremaining: 51.5s\n",
            "116:\tlearn: 0.1887903\ttotal: 6.83s\tremaining: 51.6s\n",
            "117:\tlearn: 0.1868891\ttotal: 6.87s\tremaining: 51.4s\n",
            "118:\tlearn: 0.1860333\ttotal: 6.95s\tremaining: 51.4s\n",
            "119:\tlearn: 0.1847621\ttotal: 7s\tremaining: 51.3s\n",
            "120:\tlearn: 0.1836539\ttotal: 7.03s\tremaining: 51s\n",
            "121:\tlearn: 0.1819683\ttotal: 7.07s\tremaining: 50.9s\n",
            "122:\tlearn: 0.1806544\ttotal: 7.12s\tremaining: 50.8s\n",
            "123:\tlearn: 0.1799492\ttotal: 7.18s\tremaining: 50.7s\n",
            "124:\tlearn: 0.1788621\ttotal: 7.24s\tremaining: 50.7s\n",
            "125:\tlearn: 0.1780138\ttotal: 7.3s\tremaining: 50.7s\n",
            "126:\tlearn: 0.1769034\ttotal: 7.34s\tremaining: 50.5s\n",
            "127:\tlearn: 0.1755409\ttotal: 7.39s\tremaining: 50.4s\n",
            "128:\tlearn: 0.1747135\ttotal: 7.44s\tremaining: 50.3s\n",
            "129:\tlearn: 0.1735129\ttotal: 7.49s\tremaining: 50.1s\n",
            "130:\tlearn: 0.1717475\ttotal: 7.54s\tremaining: 50.1s\n",
            "131:\tlearn: 0.1708554\ttotal: 7.6s\tremaining: 50s\n",
            "132:\tlearn: 0.1699565\ttotal: 7.64s\tremaining: 49.8s\n",
            "133:\tlearn: 0.1690206\ttotal: 7.68s\tremaining: 49.6s\n",
            "134:\tlearn: 0.1685235\ttotal: 7.72s\tremaining: 49.5s\n",
            "135:\tlearn: 0.1678544\ttotal: 7.77s\tremaining: 49.4s\n",
            "136:\tlearn: 0.1671513\ttotal: 7.79s\tremaining: 49.1s\n",
            "137:\tlearn: 0.1659896\ttotal: 7.82s\tremaining: 48.9s\n",
            "138:\tlearn: 0.1651701\ttotal: 7.87s\tremaining: 48.8s\n",
            "139:\tlearn: 0.1644083\ttotal: 7.91s\tremaining: 48.6s\n",
            "140:\tlearn: 0.1633626\ttotal: 7.93s\tremaining: 48.3s\n",
            "141:\tlearn: 0.1628158\ttotal: 7.97s\tremaining: 48.1s\n",
            "142:\tlearn: 0.1618338\ttotal: 8.02s\tremaining: 48.1s\n",
            "143:\tlearn: 0.1611457\ttotal: 8.06s\tremaining: 47.9s\n",
            "144:\tlearn: 0.1605723\ttotal: 8.14s\tremaining: 48s\n",
            "145:\tlearn: 0.1591413\ttotal: 8.2s\tremaining: 47.9s\n",
            "146:\tlearn: 0.1580314\ttotal: 8.22s\tremaining: 47.7s\n",
            "147:\tlearn: 0.1571600\ttotal: 8.25s\tremaining: 47.5s\n",
            "148:\tlearn: 0.1562363\ttotal: 8.3s\tremaining: 47.4s\n",
            "149:\tlearn: 0.1556541\ttotal: 8.33s\tremaining: 47.2s\n",
            "150:\tlearn: 0.1549037\ttotal: 8.38s\tremaining: 47.1s\n",
            "151:\tlearn: 0.1542719\ttotal: 8.42s\tremaining: 47s\n",
            "152:\tlearn: 0.1536540\ttotal: 8.47s\tremaining: 46.9s\n",
            "153:\tlearn: 0.1527407\ttotal: 8.51s\tremaining: 46.8s\n",
            "154:\tlearn: 0.1519826\ttotal: 8.56s\tremaining: 46.6s\n",
            "155:\tlearn: 0.1513093\ttotal: 8.62s\tremaining: 46.6s\n",
            "156:\tlearn: 0.1505349\ttotal: 8.66s\tremaining: 46.5s\n",
            "157:\tlearn: 0.1498628\ttotal: 8.7s\tremaining: 46.4s\n",
            "158:\tlearn: 0.1489728\ttotal: 8.74s\tremaining: 46.2s\n",
            "159:\tlearn: 0.1481000\ttotal: 8.78s\tremaining: 46.1s\n",
            "160:\tlearn: 0.1473430\ttotal: 8.87s\tremaining: 46.2s\n",
            "161:\tlearn: 0.1466378\ttotal: 8.92s\tremaining: 46.1s\n",
            "162:\tlearn: 0.1460479\ttotal: 8.96s\tremaining: 46s\n",
            "163:\tlearn: 0.1455275\ttotal: 9.01s\tremaining: 45.9s\n",
            "164:\tlearn: 0.1449365\ttotal: 9.05s\tremaining: 45.8s\n",
            "165:\tlearn: 0.1439712\ttotal: 9.09s\tremaining: 45.7s\n",
            "166:\tlearn: 0.1432015\ttotal: 9.13s\tremaining: 45.6s\n",
            "167:\tlearn: 0.1425996\ttotal: 9.18s\tremaining: 45.5s\n",
            "168:\tlearn: 0.1419977\ttotal: 9.22s\tremaining: 45.4s\n",
            "169:\tlearn: 0.1412961\ttotal: 9.27s\tremaining: 45.2s\n",
            "170:\tlearn: 0.1406599\ttotal: 9.33s\tremaining: 45.2s\n",
            "171:\tlearn: 0.1401003\ttotal: 9.37s\tremaining: 45.1s\n",
            "172:\tlearn: 0.1395329\ttotal: 9.41s\tremaining: 45s\n",
            "173:\tlearn: 0.1387863\ttotal: 9.46s\tremaining: 44.9s\n",
            "174:\tlearn: 0.1380932\ttotal: 9.5s\tremaining: 44.8s\n",
            "175:\tlearn: 0.1371749\ttotal: 9.54s\tremaining: 44.7s\n",
            "176:\tlearn: 0.1364871\ttotal: 9.6s\tremaining: 44.7s\n",
            "177:\tlearn: 0.1360343\ttotal: 9.67s\tremaining: 44.7s\n",
            "178:\tlearn: 0.1352974\ttotal: 9.72s\tremaining: 44.6s\n",
            "179:\tlearn: 0.1345932\ttotal: 9.76s\tremaining: 44.5s\n",
            "180:\tlearn: 0.1340329\ttotal: 9.81s\tremaining: 44.4s\n",
            "181:\tlearn: 0.1335569\ttotal: 9.87s\tremaining: 44.4s\n",
            "182:\tlearn: 0.1324631\ttotal: 9.94s\tremaining: 44.4s\n",
            "183:\tlearn: 0.1317575\ttotal: 10s\tremaining: 44.3s\n",
            "184:\tlearn: 0.1311888\ttotal: 10.1s\tremaining: 44.4s\n",
            "185:\tlearn: 0.1308135\ttotal: 10.1s\tremaining: 44.2s\n",
            "186:\tlearn: 0.1302432\ttotal: 10.1s\tremaining: 44s\n",
            "187:\tlearn: 0.1297638\ttotal: 10.2s\tremaining: 43.9s\n",
            "188:\tlearn: 0.1292138\ttotal: 10.2s\tremaining: 43.7s\n",
            "189:\tlearn: 0.1287481\ttotal: 10.2s\tremaining: 43.5s\n",
            "190:\tlearn: 0.1283651\ttotal: 10.2s\tremaining: 43.3s\n",
            "191:\tlearn: 0.1276737\ttotal: 10.2s\tremaining: 43.1s\n",
            "192:\tlearn: 0.1268485\ttotal: 10.3s\tremaining: 42.9s\n",
            "193:\tlearn: 0.1262810\ttotal: 10.3s\tremaining: 42.7s\n",
            "194:\tlearn: 0.1251794\ttotal: 10.3s\tremaining: 42.6s\n",
            "195:\tlearn: 0.1247976\ttotal: 10.3s\tremaining: 42.4s\n",
            "196:\tlearn: 0.1242280\ttotal: 10.4s\tremaining: 42.2s\n",
            "197:\tlearn: 0.1238642\ttotal: 10.4s\tremaining: 42s\n",
            "198:\tlearn: 0.1233500\ttotal: 10.4s\tremaining: 41.8s\n",
            "199:\tlearn: 0.1228191\ttotal: 10.4s\tremaining: 41.7s\n",
            "200:\tlearn: 0.1222307\ttotal: 10.4s\tremaining: 41.5s\n",
            "201:\tlearn: 0.1216517\ttotal: 10.5s\tremaining: 41.3s\n",
            "202:\tlearn: 0.1210001\ttotal: 10.5s\tremaining: 41.1s\n",
            "203:\tlearn: 0.1206626\ttotal: 10.5s\tremaining: 40.9s\n",
            "204:\tlearn: 0.1203225\ttotal: 10.5s\tremaining: 40.8s\n",
            "205:\tlearn: 0.1198608\ttotal: 10.5s\tremaining: 40.6s\n",
            "206:\tlearn: 0.1191292\ttotal: 10.6s\tremaining: 40.4s\n",
            "207:\tlearn: 0.1186016\ttotal: 10.6s\tremaining: 40.3s\n",
            "208:\tlearn: 0.1182060\ttotal: 10.6s\tremaining: 40.1s\n",
            "209:\tlearn: 0.1179915\ttotal: 10.6s\tremaining: 39.9s\n",
            "210:\tlearn: 0.1174849\ttotal: 10.7s\tremaining: 39.8s\n",
            "211:\tlearn: 0.1170825\ttotal: 10.7s\tremaining: 39.7s\n",
            "212:\tlearn: 0.1167616\ttotal: 10.7s\tremaining: 39.5s\n",
            "213:\tlearn: 0.1162446\ttotal: 10.7s\tremaining: 39.3s\n",
            "214:\tlearn: 0.1157821\ttotal: 10.7s\tremaining: 39.2s\n",
            "215:\tlearn: 0.1151754\ttotal: 10.8s\tremaining: 39s\n",
            "216:\tlearn: 0.1146644\ttotal: 10.8s\tremaining: 38.9s\n",
            "217:\tlearn: 0.1142588\ttotal: 10.8s\tremaining: 38.7s\n",
            "218:\tlearn: 0.1135680\ttotal: 10.8s\tremaining: 38.6s\n",
            "219:\tlearn: 0.1131555\ttotal: 10.8s\tremaining: 38.4s\n",
            "220:\tlearn: 0.1126546\ttotal: 10.9s\tremaining: 38.3s\n",
            "221:\tlearn: 0.1120365\ttotal: 10.9s\tremaining: 38.1s\n",
            "222:\tlearn: 0.1114132\ttotal: 10.9s\tremaining: 38s\n",
            "223:\tlearn: 0.1108453\ttotal: 10.9s\tremaining: 37.8s\n",
            "224:\tlearn: 0.1104149\ttotal: 10.9s\tremaining: 37.7s\n",
            "225:\tlearn: 0.1099535\ttotal: 11s\tremaining: 37.5s\n",
            "226:\tlearn: 0.1096361\ttotal: 11s\tremaining: 37.4s\n",
            "227:\tlearn: 0.1091704\ttotal: 11s\tremaining: 37.3s\n",
            "228:\tlearn: 0.1086169\ttotal: 11s\tremaining: 37.2s\n",
            "229:\tlearn: 0.1081346\ttotal: 11.1s\tremaining: 37s\n",
            "230:\tlearn: 0.1077653\ttotal: 11.1s\tremaining: 36.9s\n",
            "231:\tlearn: 0.1073155\ttotal: 11.1s\tremaining: 36.8s\n",
            "232:\tlearn: 0.1067054\ttotal: 11.1s\tremaining: 36.7s\n",
            "233:\tlearn: 0.1063659\ttotal: 11.2s\tremaining: 36.5s\n",
            "234:\tlearn: 0.1058857\ttotal: 11.2s\tremaining: 36.4s\n",
            "235:\tlearn: 0.1055838\ttotal: 11.2s\tremaining: 36.3s\n",
            "236:\tlearn: 0.1053180\ttotal: 11.2s\tremaining: 36.1s\n",
            "237:\tlearn: 0.1048589\ttotal: 11.2s\tremaining: 36s\n",
            "238:\tlearn: 0.1045272\ttotal: 11.3s\tremaining: 35.9s\n",
            "239:\tlearn: 0.1040704\ttotal: 11.3s\tremaining: 35.8s\n",
            "240:\tlearn: 0.1037995\ttotal: 11.3s\tremaining: 35.6s\n",
            "241:\tlearn: 0.1033539\ttotal: 11.3s\tremaining: 35.5s\n",
            "242:\tlearn: 0.1028797\ttotal: 11.4s\tremaining: 35.4s\n",
            "243:\tlearn: 0.1026042\ttotal: 11.4s\tremaining: 35.3s\n",
            "244:\tlearn: 0.1021716\ttotal: 11.4s\tremaining: 35.1s\n",
            "245:\tlearn: 0.1017706\ttotal: 11.4s\tremaining: 35s\n",
            "246:\tlearn: 0.1013759\ttotal: 11.4s\tremaining: 34.9s\n",
            "247:\tlearn: 0.1011114\ttotal: 11.5s\tremaining: 34.8s\n",
            "248:\tlearn: 0.1008008\ttotal: 11.5s\tremaining: 34.6s\n",
            "249:\tlearn: 0.1004180\ttotal: 11.5s\tremaining: 34.5s\n",
            "250:\tlearn: 0.1000110\ttotal: 11.5s\tremaining: 34.4s\n",
            "251:\tlearn: 0.0994798\ttotal: 11.5s\tremaining: 34.3s\n",
            "252:\tlearn: 0.0991876\ttotal: 11.6s\tremaining: 34.2s\n",
            "253:\tlearn: 0.0988481\ttotal: 11.6s\tremaining: 34s\n",
            "254:\tlearn: 0.0985397\ttotal: 11.6s\tremaining: 33.9s\n",
            "255:\tlearn: 0.0982679\ttotal: 11.6s\tremaining: 33.8s\n",
            "256:\tlearn: 0.0979872\ttotal: 11.6s\tremaining: 33.7s\n",
            "257:\tlearn: 0.0973932\ttotal: 11.7s\tremaining: 33.6s\n",
            "258:\tlearn: 0.0970994\ttotal: 11.7s\tremaining: 33.4s\n",
            "259:\tlearn: 0.0965984\ttotal: 11.7s\tremaining: 33.3s\n",
            "260:\tlearn: 0.0962781\ttotal: 11.7s\tremaining: 33.2s\n",
            "261:\tlearn: 0.0960764\ttotal: 11.7s\tremaining: 33.1s\n",
            "262:\tlearn: 0.0958651\ttotal: 11.8s\tremaining: 33s\n",
            "263:\tlearn: 0.0954406\ttotal: 11.8s\tremaining: 32.9s\n",
            "264:\tlearn: 0.0950108\ttotal: 11.8s\tremaining: 32.7s\n",
            "265:\tlearn: 0.0946630\ttotal: 11.8s\tremaining: 32.6s\n",
            "266:\tlearn: 0.0941982\ttotal: 11.8s\tremaining: 32.5s\n",
            "267:\tlearn: 0.0936982\ttotal: 11.9s\tremaining: 32.4s\n",
            "268:\tlearn: 0.0934173\ttotal: 11.9s\tremaining: 32.3s\n",
            "269:\tlearn: 0.0932191\ttotal: 11.9s\tremaining: 32.2s\n",
            "270:\tlearn: 0.0928822\ttotal: 11.9s\tremaining: 32.1s\n",
            "271:\tlearn: 0.0925370\ttotal: 12s\tremaining: 32s\n",
            "272:\tlearn: 0.0918414\ttotal: 12s\tremaining: 31.9s\n",
            "273:\tlearn: 0.0915646\ttotal: 12s\tremaining: 31.8s\n",
            "274:\tlearn: 0.0911812\ttotal: 12s\tremaining: 31.7s\n",
            "275:\tlearn: 0.0909205\ttotal: 12.1s\tremaining: 31.6s\n",
            "276:\tlearn: 0.0905200\ttotal: 12.1s\tremaining: 31.5s\n",
            "277:\tlearn: 0.0901549\ttotal: 12.1s\tremaining: 31.4s\n",
            "278:\tlearn: 0.0898747\ttotal: 12.1s\tremaining: 31.4s\n",
            "279:\tlearn: 0.0894327\ttotal: 12.2s\tremaining: 31.3s\n",
            "280:\tlearn: 0.0892184\ttotal: 12.2s\tremaining: 31.1s\n",
            "281:\tlearn: 0.0889086\ttotal: 12.2s\tremaining: 31.1s\n",
            "282:\tlearn: 0.0885739\ttotal: 12.2s\tremaining: 31s\n",
            "283:\tlearn: 0.0879689\ttotal: 12.2s\tremaining: 30.9s\n",
            "284:\tlearn: 0.0877502\ttotal: 12.3s\tremaining: 30.8s\n",
            "285:\tlearn: 0.0873342\ttotal: 12.3s\tremaining: 30.7s\n",
            "286:\tlearn: 0.0870125\ttotal: 12.3s\tremaining: 30.6s\n",
            "287:\tlearn: 0.0866301\ttotal: 12.3s\tremaining: 30.5s\n",
            "288:\tlearn: 0.0859020\ttotal: 12.3s\tremaining: 30.4s\n",
            "289:\tlearn: 0.0856397\ttotal: 12.4s\tremaining: 30.3s\n",
            "290:\tlearn: 0.0850570\ttotal: 12.4s\tremaining: 30.2s\n",
            "291:\tlearn: 0.0847555\ttotal: 12.4s\tremaining: 30.1s\n",
            "292:\tlearn: 0.0844902\ttotal: 12.4s\tremaining: 30s\n",
            "293:\tlearn: 0.0843482\ttotal: 12.5s\tremaining: 29.9s\n",
            "294:\tlearn: 0.0842471\ttotal: 12.5s\tremaining: 29.9s\n",
            "295:\tlearn: 0.0840965\ttotal: 12.5s\tremaining: 29.8s\n",
            "296:\tlearn: 0.0838353\ttotal: 12.6s\tremaining: 29.8s\n",
            "297:\tlearn: 0.0836711\ttotal: 12.6s\tremaining: 29.8s\n",
            "298:\tlearn: 0.0835282\ttotal: 12.7s\tremaining: 29.7s\n",
            "299:\tlearn: 0.0832892\ttotal: 12.7s\tremaining: 29.6s\n",
            "300:\tlearn: 0.0829893\ttotal: 12.7s\tremaining: 29.6s\n",
            "301:\tlearn: 0.0826781\ttotal: 12.8s\tremaining: 29.5s\n",
            "302:\tlearn: 0.0824332\ttotal: 12.8s\tremaining: 29.5s\n",
            "303:\tlearn: 0.0821298\ttotal: 12.9s\tremaining: 29.4s\n",
            "304:\tlearn: 0.0817964\ttotal: 12.9s\tremaining: 29.4s\n",
            "305:\tlearn: 0.0815205\ttotal: 12.9s\tremaining: 29.3s\n",
            "306:\tlearn: 0.0814082\ttotal: 13s\tremaining: 29.3s\n",
            "307:\tlearn: 0.0810802\ttotal: 13s\tremaining: 29.3s\n",
            "308:\tlearn: 0.0808374\ttotal: 13.1s\tremaining: 29.2s\n",
            "309:\tlearn: 0.0806685\ttotal: 13.1s\tremaining: 29.2s\n",
            "310:\tlearn: 0.0806032\ttotal: 13.2s\tremaining: 29.1s\n",
            "311:\tlearn: 0.0805005\ttotal: 13.2s\tremaining: 29.1s\n",
            "312:\tlearn: 0.0801213\ttotal: 13.2s\tremaining: 29.1s\n",
            "313:\tlearn: 0.0797696\ttotal: 13.3s\tremaining: 29s\n",
            "314:\tlearn: 0.0795991\ttotal: 13.3s\tremaining: 29s\n",
            "315:\tlearn: 0.0792366\ttotal: 13.4s\tremaining: 28.9s\n",
            "316:\tlearn: 0.0789259\ttotal: 13.4s\tremaining: 28.9s\n",
            "317:\tlearn: 0.0786566\ttotal: 13.5s\tremaining: 28.9s\n",
            "318:\tlearn: 0.0783571\ttotal: 13.5s\tremaining: 28.8s\n",
            "319:\tlearn: 0.0781988\ttotal: 13.5s\tremaining: 28.8s\n",
            "320:\tlearn: 0.0780016\ttotal: 13.6s\tremaining: 28.7s\n",
            "321:\tlearn: 0.0778645\ttotal: 13.6s\tremaining: 28.7s\n",
            "322:\tlearn: 0.0773153\ttotal: 13.7s\tremaining: 28.7s\n",
            "323:\tlearn: 0.0772324\ttotal: 13.7s\tremaining: 28.6s\n",
            "324:\tlearn: 0.0771522\ttotal: 13.8s\tremaining: 28.6s\n",
            "325:\tlearn: 0.0769093\ttotal: 13.8s\tremaining: 28.5s\n",
            "326:\tlearn: 0.0765624\ttotal: 13.8s\tremaining: 28.4s\n",
            "327:\tlearn: 0.0764775\ttotal: 13.9s\tremaining: 28.4s\n",
            "328:\tlearn: 0.0762988\ttotal: 13.9s\tremaining: 28.4s\n",
            "329:\tlearn: 0.0758448\ttotal: 13.9s\tremaining: 28.3s\n",
            "330:\tlearn: 0.0755213\ttotal: 14s\tremaining: 28.3s\n",
            "331:\tlearn: 0.0752144\ttotal: 14s\tremaining: 28.2s\n",
            "332:\tlearn: 0.0750917\ttotal: 14.1s\tremaining: 28.2s\n",
            "333:\tlearn: 0.0748373\ttotal: 14.1s\tremaining: 28.2s\n",
            "334:\tlearn: 0.0747834\ttotal: 14.2s\tremaining: 28.1s\n",
            "335:\tlearn: 0.0746179\ttotal: 14.2s\tremaining: 28.1s\n",
            "336:\tlearn: 0.0745540\ttotal: 14.3s\tremaining: 28s\n",
            "337:\tlearn: 0.0745088\ttotal: 14.3s\tremaining: 28s\n",
            "338:\tlearn: 0.0742493\ttotal: 14.3s\tremaining: 27.9s\n",
            "339:\tlearn: 0.0740167\ttotal: 14.4s\tremaining: 27.9s\n",
            "340:\tlearn: 0.0738826\ttotal: 14.4s\tremaining: 27.9s\n",
            "341:\tlearn: 0.0736402\ttotal: 14.4s\tremaining: 27.8s\n",
            "342:\tlearn: 0.0733863\ttotal: 14.5s\tremaining: 27.7s\n",
            "343:\tlearn: 0.0732982\ttotal: 14.5s\tremaining: 27.7s\n",
            "344:\tlearn: 0.0731592\ttotal: 14.6s\tremaining: 27.6s\n",
            "345:\tlearn: 0.0729377\ttotal: 14.6s\tremaining: 27.6s\n",
            "346:\tlearn: 0.0729000\ttotal: 14.6s\tremaining: 27.5s\n",
            "347:\tlearn: 0.0725604\ttotal: 14.7s\tremaining: 27.5s\n",
            "348:\tlearn: 0.0722969\ttotal: 14.7s\tremaining: 27.5s\n",
            "349:\tlearn: 0.0719395\ttotal: 14.8s\tremaining: 27.4s\n",
            "350:\tlearn: 0.0716748\ttotal: 14.8s\tremaining: 27.4s\n",
            "351:\tlearn: 0.0716270\ttotal: 14.9s\tremaining: 27.3s\n",
            "352:\tlearn: 0.0715730\ttotal: 14.9s\tremaining: 27.3s\n",
            "353:\tlearn: 0.0713408\ttotal: 14.9s\tremaining: 27.3s\n",
            "354:\tlearn: 0.0710840\ttotal: 15s\tremaining: 27.2s\n",
            "355:\tlearn: 0.0710251\ttotal: 15s\tremaining: 27.2s\n",
            "356:\tlearn: 0.0707964\ttotal: 15s\tremaining: 27.1s\n",
            "357:\tlearn: 0.0706609\ttotal: 15.1s\tremaining: 27s\n",
            "358:\tlearn: 0.0704559\ttotal: 15.1s\tremaining: 27s\n",
            "359:\tlearn: 0.0702014\ttotal: 15.2s\tremaining: 26.9s\n",
            "360:\tlearn: 0.0700810\ttotal: 15.2s\tremaining: 26.9s\n",
            "361:\tlearn: 0.0697853\ttotal: 15.3s\tremaining: 26.9s\n",
            "362:\tlearn: 0.0696338\ttotal: 15.3s\tremaining: 26.8s\n",
            "363:\tlearn: 0.0695837\ttotal: 15.3s\tremaining: 26.8s\n",
            "364:\tlearn: 0.0694563\ttotal: 15.3s\tremaining: 26.7s\n",
            "365:\tlearn: 0.0693176\ttotal: 15.4s\tremaining: 26.6s\n",
            "366:\tlearn: 0.0691982\ttotal: 15.4s\tremaining: 26.5s\n",
            "367:\tlearn: 0.0689901\ttotal: 15.4s\tremaining: 26.5s\n",
            "368:\tlearn: 0.0689404\ttotal: 15.5s\tremaining: 26.4s\n",
            "369:\tlearn: 0.0686718\ttotal: 15.5s\tremaining: 26.4s\n",
            "370:\tlearn: 0.0686398\ttotal: 15.6s\tremaining: 26.4s\n",
            "371:\tlearn: 0.0685352\ttotal: 15.6s\tremaining: 26.3s\n",
            "372:\tlearn: 0.0682609\ttotal: 15.6s\tremaining: 26.3s\n",
            "373:\tlearn: 0.0681360\ttotal: 15.7s\tremaining: 26.3s\n",
            "374:\tlearn: 0.0680856\ttotal: 15.7s\tremaining: 26.2s\n",
            "375:\tlearn: 0.0677930\ttotal: 15.8s\tremaining: 26.2s\n",
            "376:\tlearn: 0.0673247\ttotal: 15.8s\tremaining: 26.1s\n",
            "377:\tlearn: 0.0670497\ttotal: 15.9s\tremaining: 26.1s\n",
            "378:\tlearn: 0.0668979\ttotal: 15.9s\tremaining: 26s\n",
            "379:\tlearn: 0.0666961\ttotal: 15.9s\tremaining: 26s\n",
            "380:\tlearn: 0.0664830\ttotal: 16s\tremaining: 25.9s\n",
            "381:\tlearn: 0.0663183\ttotal: 16s\tremaining: 25.9s\n",
            "382:\tlearn: 0.0660033\ttotal: 16.1s\tremaining: 25.9s\n",
            "383:\tlearn: 0.0658402\ttotal: 16.1s\tremaining: 25.8s\n",
            "384:\tlearn: 0.0656218\ttotal: 16.1s\tremaining: 25.8s\n",
            "385:\tlearn: 0.0655033\ttotal: 16.2s\tremaining: 25.7s\n",
            "386:\tlearn: 0.0652460\ttotal: 16.2s\tremaining: 25.7s\n",
            "387:\tlearn: 0.0650238\ttotal: 16.3s\tremaining: 25.7s\n",
            "388:\tlearn: 0.0649802\ttotal: 16.3s\tremaining: 25.6s\n",
            "389:\tlearn: 0.0647781\ttotal: 16.4s\tremaining: 25.6s\n",
            "390:\tlearn: 0.0645957\ttotal: 16.4s\tremaining: 25.5s\n",
            "391:\tlearn: 0.0644528\ttotal: 16.4s\tremaining: 25.5s\n",
            "392:\tlearn: 0.0643687\ttotal: 16.5s\tremaining: 25.5s\n",
            "393:\tlearn: 0.0641889\ttotal: 16.5s\tremaining: 25.4s\n",
            "394:\tlearn: 0.0639800\ttotal: 16.6s\tremaining: 25.4s\n",
            "395:\tlearn: 0.0636870\ttotal: 16.6s\tremaining: 25.3s\n",
            "396:\tlearn: 0.0635881\ttotal: 16.7s\tremaining: 25.3s\n",
            "397:\tlearn: 0.0634859\ttotal: 16.7s\tremaining: 25.3s\n",
            "398:\tlearn: 0.0634432\ttotal: 16.8s\tremaining: 25.2s\n",
            "399:\tlearn: 0.0633020\ttotal: 16.8s\tremaining: 25.2s\n",
            "400:\tlearn: 0.0632535\ttotal: 16.8s\tremaining: 25.2s\n",
            "401:\tlearn: 0.0631136\ttotal: 16.9s\tremaining: 25.1s\n",
            "402:\tlearn: 0.0629101\ttotal: 16.9s\tremaining: 25s\n",
            "403:\tlearn: 0.0627823\ttotal: 16.9s\tremaining: 25s\n",
            "404:\tlearn: 0.0624723\ttotal: 16.9s\tremaining: 24.9s\n",
            "405:\tlearn: 0.0622398\ttotal: 17s\tremaining: 24.8s\n",
            "406:\tlearn: 0.0621810\ttotal: 17s\tremaining: 24.7s\n",
            "407:\tlearn: 0.0621457\ttotal: 17s\tremaining: 24.7s\n",
            "408:\tlearn: 0.0618201\ttotal: 17s\tremaining: 24.6s\n",
            "409:\tlearn: 0.0616207\ttotal: 17s\tremaining: 24.5s\n",
            "410:\tlearn: 0.0614404\ttotal: 17.1s\tremaining: 24.5s\n",
            "411:\tlearn: 0.0613336\ttotal: 17.1s\tremaining: 24.4s\n",
            "412:\tlearn: 0.0611772\ttotal: 17.1s\tremaining: 24.3s\n",
            "413:\tlearn: 0.0609310\ttotal: 17.1s\tremaining: 24.2s\n",
            "414:\tlearn: 0.0606623\ttotal: 17.1s\tremaining: 24.2s\n",
            "415:\tlearn: 0.0606263\ttotal: 17.2s\tremaining: 24.1s\n",
            "416:\tlearn: 0.0605699\ttotal: 17.2s\tremaining: 24s\n",
            "417:\tlearn: 0.0602689\ttotal: 17.2s\tremaining: 24s\n",
            "418:\tlearn: 0.0602210\ttotal: 17.2s\tremaining: 23.9s\n",
            "419:\tlearn: 0.0598994\ttotal: 17.3s\tremaining: 23.8s\n",
            "420:\tlearn: 0.0598475\ttotal: 17.3s\tremaining: 23.8s\n",
            "421:\tlearn: 0.0597408\ttotal: 17.3s\tremaining: 23.7s\n",
            "422:\tlearn: 0.0596095\ttotal: 17.3s\tremaining: 23.6s\n",
            "423:\tlearn: 0.0593908\ttotal: 17.3s\tremaining: 23.6s\n",
            "424:\tlearn: 0.0592344\ttotal: 17.4s\tremaining: 23.5s\n",
            "425:\tlearn: 0.0590494\ttotal: 17.4s\tremaining: 23.4s\n",
            "426:\tlearn: 0.0588447\ttotal: 17.4s\tremaining: 23.4s\n",
            "427:\tlearn: 0.0587191\ttotal: 17.4s\tremaining: 23.3s\n",
            "428:\tlearn: 0.0585765\ttotal: 17.5s\tremaining: 23.2s\n",
            "429:\tlearn: 0.0583136\ttotal: 17.5s\tremaining: 23.2s\n",
            "430:\tlearn: 0.0581177\ttotal: 17.5s\tremaining: 23.1s\n",
            "431:\tlearn: 0.0580753\ttotal: 17.5s\tremaining: 23s\n",
            "432:\tlearn: 0.0578447\ttotal: 17.5s\tremaining: 23s\n",
            "433:\tlearn: 0.0577897\ttotal: 17.6s\tremaining: 22.9s\n",
            "434:\tlearn: 0.0575517\ttotal: 17.6s\tremaining: 22.8s\n",
            "435:\tlearn: 0.0573465\ttotal: 17.6s\tremaining: 22.8s\n",
            "436:\tlearn: 0.0571637\ttotal: 17.6s\tremaining: 22.7s\n",
            "437:\tlearn: 0.0570478\ttotal: 17.6s\tremaining: 22.6s\n",
            "438:\tlearn: 0.0569042\ttotal: 17.7s\tremaining: 22.6s\n",
            "439:\tlearn: 0.0567605\ttotal: 17.7s\tremaining: 22.5s\n",
            "440:\tlearn: 0.0564753\ttotal: 17.7s\tremaining: 22.4s\n",
            "441:\tlearn: 0.0562574\ttotal: 17.7s\tremaining: 22.4s\n",
            "442:\tlearn: 0.0562251\ttotal: 17.7s\tremaining: 22.3s\n",
            "443:\tlearn: 0.0562021\ttotal: 17.8s\tremaining: 22.2s\n",
            "444:\tlearn: 0.0561052\ttotal: 17.8s\tremaining: 22.2s\n",
            "445:\tlearn: 0.0559168\ttotal: 17.8s\tremaining: 22.1s\n",
            "446:\tlearn: 0.0556570\ttotal: 17.8s\tremaining: 22.1s\n",
            "447:\tlearn: 0.0555133\ttotal: 17.8s\tremaining: 22s\n",
            "448:\tlearn: 0.0554629\ttotal: 17.9s\tremaining: 21.9s\n",
            "449:\tlearn: 0.0553093\ttotal: 17.9s\tremaining: 21.9s\n",
            "450:\tlearn: 0.0552113\ttotal: 17.9s\tremaining: 21.8s\n",
            "451:\tlearn: 0.0551904\ttotal: 17.9s\tremaining: 21.7s\n",
            "452:\tlearn: 0.0550678\ttotal: 18s\tremaining: 21.7s\n",
            "453:\tlearn: 0.0550415\ttotal: 18s\tremaining: 21.6s\n",
            "454:\tlearn: 0.0550014\ttotal: 18s\tremaining: 21.5s\n",
            "455:\tlearn: 0.0549702\ttotal: 18s\tremaining: 21.5s\n",
            "456:\tlearn: 0.0549370\ttotal: 18s\tremaining: 21.4s\n",
            "457:\tlearn: 0.0549156\ttotal: 18s\tremaining: 21.4s\n",
            "458:\tlearn: 0.0547706\ttotal: 18.1s\tremaining: 21.3s\n",
            "459:\tlearn: 0.0546001\ttotal: 18.1s\tremaining: 21.2s\n",
            "460:\tlearn: 0.0544666\ttotal: 18.1s\tremaining: 21.2s\n",
            "461:\tlearn: 0.0544356\ttotal: 18.1s\tremaining: 21.1s\n",
            "462:\tlearn: 0.0544148\ttotal: 18.1s\tremaining: 21s\n",
            "463:\tlearn: 0.0542364\ttotal: 18.2s\tremaining: 21s\n",
            "464:\tlearn: 0.0541264\ttotal: 18.2s\tremaining: 20.9s\n",
            "465:\tlearn: 0.0539919\ttotal: 18.2s\tremaining: 20.9s\n",
            "466:\tlearn: 0.0537867\ttotal: 18.2s\tremaining: 20.8s\n",
            "467:\tlearn: 0.0536824\ttotal: 18.3s\tremaining: 20.7s\n",
            "468:\tlearn: 0.0535464\ttotal: 18.3s\tremaining: 20.7s\n",
            "469:\tlearn: 0.0535277\ttotal: 18.3s\tremaining: 20.6s\n",
            "470:\tlearn: 0.0535087\ttotal: 18.3s\tremaining: 20.6s\n",
            "471:\tlearn: 0.0533210\ttotal: 18.3s\tremaining: 20.5s\n",
            "472:\tlearn: 0.0531095\ttotal: 18.4s\tremaining: 20.4s\n",
            "473:\tlearn: 0.0529323\ttotal: 18.4s\tremaining: 20.4s\n",
            "474:\tlearn: 0.0528878\ttotal: 18.4s\tremaining: 20.4s\n",
            "475:\tlearn: 0.0528443\ttotal: 18.4s\tremaining: 20.3s\n",
            "476:\tlearn: 0.0528086\ttotal: 18.5s\tremaining: 20.2s\n",
            "477:\tlearn: 0.0526074\ttotal: 18.5s\tremaining: 20.2s\n",
            "478:\tlearn: 0.0525815\ttotal: 18.5s\tremaining: 20.1s\n",
            "479:\tlearn: 0.0523802\ttotal: 18.5s\tremaining: 20.1s\n",
            "480:\tlearn: 0.0521694\ttotal: 18.5s\tremaining: 20s\n",
            "481:\tlearn: 0.0520419\ttotal: 18.6s\tremaining: 19.9s\n",
            "482:\tlearn: 0.0520130\ttotal: 18.6s\tremaining: 19.9s\n",
            "483:\tlearn: 0.0518537\ttotal: 18.6s\tremaining: 19.8s\n",
            "484:\tlearn: 0.0518241\ttotal: 18.6s\tremaining: 19.8s\n",
            "485:\tlearn: 0.0517944\ttotal: 18.6s\tremaining: 19.7s\n",
            "486:\tlearn: 0.0517617\ttotal: 18.7s\tremaining: 19.6s\n",
            "487:\tlearn: 0.0516833\ttotal: 18.7s\tremaining: 19.6s\n",
            "488:\tlearn: 0.0515537\ttotal: 18.7s\tremaining: 19.5s\n",
            "489:\tlearn: 0.0515350\ttotal: 18.7s\tremaining: 19.5s\n",
            "490:\tlearn: 0.0514256\ttotal: 18.7s\tremaining: 19.4s\n",
            "491:\tlearn: 0.0512256\ttotal: 18.8s\tremaining: 19.4s\n",
            "492:\tlearn: 0.0511906\ttotal: 18.8s\tremaining: 19.3s\n",
            "493:\tlearn: 0.0509816\ttotal: 18.8s\tremaining: 19.3s\n",
            "494:\tlearn: 0.0508388\ttotal: 18.8s\tremaining: 19.2s\n",
            "495:\tlearn: 0.0506428\ttotal: 18.8s\tremaining: 19.1s\n",
            "496:\tlearn: 0.0506197\ttotal: 18.9s\tremaining: 19.1s\n",
            "497:\tlearn: 0.0504064\ttotal: 18.9s\tremaining: 19s\n",
            "498:\tlearn: 0.0502447\ttotal: 18.9s\tremaining: 19s\n",
            "499:\tlearn: 0.0502200\ttotal: 18.9s\tremaining: 18.9s\n",
            "500:\tlearn: 0.0500923\ttotal: 18.9s\tremaining: 18.9s\n",
            "501:\tlearn: 0.0500579\ttotal: 19s\tremaining: 18.8s\n",
            "502:\tlearn: 0.0499186\ttotal: 19s\tremaining: 18.8s\n",
            "503:\tlearn: 0.0497769\ttotal: 19s\tremaining: 18.7s\n",
            "504:\tlearn: 0.0497346\ttotal: 19s\tremaining: 18.6s\n",
            "505:\tlearn: 0.0497051\ttotal: 19s\tremaining: 18.6s\n",
            "506:\tlearn: 0.0495150\ttotal: 19.1s\tremaining: 18.5s\n",
            "507:\tlearn: 0.0494899\ttotal: 19.1s\tremaining: 18.5s\n",
            "508:\tlearn: 0.0492851\ttotal: 19.1s\tremaining: 18.4s\n",
            "509:\tlearn: 0.0492327\ttotal: 19.1s\tremaining: 18.4s\n",
            "510:\tlearn: 0.0491616\ttotal: 19.1s\tremaining: 18.3s\n",
            "511:\tlearn: 0.0490078\ttotal: 19.2s\tremaining: 18.3s\n",
            "512:\tlearn: 0.0489555\ttotal: 19.2s\tremaining: 18.2s\n",
            "513:\tlearn: 0.0487587\ttotal: 19.2s\tremaining: 18.2s\n",
            "514:\tlearn: 0.0485656\ttotal: 19.2s\tremaining: 18.1s\n",
            "515:\tlearn: 0.0484503\ttotal: 19.2s\tremaining: 18s\n",
            "516:\tlearn: 0.0483650\ttotal: 19.3s\tremaining: 18s\n",
            "517:\tlearn: 0.0483433\ttotal: 19.3s\tremaining: 17.9s\n",
            "518:\tlearn: 0.0481624\ttotal: 19.3s\tremaining: 17.9s\n",
            "519:\tlearn: 0.0481313\ttotal: 19.3s\tremaining: 17.8s\n",
            "520:\tlearn: 0.0481006\ttotal: 19.3s\tremaining: 17.8s\n",
            "521:\tlearn: 0.0478907\ttotal: 19.4s\tremaining: 17.7s\n",
            "522:\tlearn: 0.0477701\ttotal: 19.4s\tremaining: 17.7s\n",
            "523:\tlearn: 0.0477515\ttotal: 19.4s\tremaining: 17.6s\n",
            "524:\tlearn: 0.0475670\ttotal: 19.4s\tremaining: 17.6s\n",
            "525:\tlearn: 0.0475331\ttotal: 19.5s\tremaining: 17.5s\n",
            "526:\tlearn: 0.0474577\ttotal: 19.5s\tremaining: 17.5s\n",
            "527:\tlearn: 0.0473552\ttotal: 19.5s\tremaining: 17.4s\n",
            "528:\tlearn: 0.0473338\ttotal: 19.5s\tremaining: 17.4s\n",
            "529:\tlearn: 0.0471567\ttotal: 19.5s\tremaining: 17.3s\n",
            "530:\tlearn: 0.0469989\ttotal: 19.6s\tremaining: 17.3s\n",
            "531:\tlearn: 0.0469834\ttotal: 19.6s\tremaining: 17.2s\n",
            "532:\tlearn: 0.0468618\ttotal: 19.6s\tremaining: 17.2s\n",
            "533:\tlearn: 0.0468440\ttotal: 19.6s\tremaining: 17.1s\n",
            "534:\tlearn: 0.0466798\ttotal: 19.6s\tremaining: 17.1s\n",
            "535:\tlearn: 0.0466541\ttotal: 19.7s\tremaining: 17s\n",
            "536:\tlearn: 0.0465174\ttotal: 19.7s\tremaining: 17s\n",
            "537:\tlearn: 0.0463450\ttotal: 19.7s\tremaining: 16.9s\n",
            "538:\tlearn: 0.0461735\ttotal: 19.7s\tremaining: 16.9s\n",
            "539:\tlearn: 0.0461569\ttotal: 19.7s\tremaining: 16.8s\n",
            "540:\tlearn: 0.0460068\ttotal: 19.8s\tremaining: 16.8s\n",
            "541:\tlearn: 0.0459623\ttotal: 19.8s\tremaining: 16.7s\n",
            "542:\tlearn: 0.0459384\ttotal: 19.8s\tremaining: 16.7s\n",
            "543:\tlearn: 0.0457166\ttotal: 19.8s\tremaining: 16.6s\n",
            "544:\tlearn: 0.0455906\ttotal: 19.8s\tremaining: 16.6s\n",
            "545:\tlearn: 0.0455477\ttotal: 19.9s\tremaining: 16.5s\n",
            "546:\tlearn: 0.0455229\ttotal: 19.9s\tremaining: 16.5s\n",
            "547:\tlearn: 0.0455020\ttotal: 19.9s\tremaining: 16.4s\n",
            "548:\tlearn: 0.0453651\ttotal: 19.9s\tremaining: 16.4s\n",
            "549:\tlearn: 0.0453373\ttotal: 19.9s\tremaining: 16.3s\n",
            "550:\tlearn: 0.0451862\ttotal: 20s\tremaining: 16.3s\n",
            "551:\tlearn: 0.0451555\ttotal: 20s\tremaining: 16.2s\n",
            "552:\tlearn: 0.0451306\ttotal: 20s\tremaining: 16.2s\n",
            "553:\tlearn: 0.0450431\ttotal: 20s\tremaining: 16.1s\n",
            "554:\tlearn: 0.0450259\ttotal: 20.1s\tremaining: 16.1s\n",
            "555:\tlearn: 0.0448718\ttotal: 20.1s\tremaining: 16s\n",
            "556:\tlearn: 0.0446626\ttotal: 20.1s\tremaining: 16s\n",
            "557:\tlearn: 0.0446136\ttotal: 20.1s\tremaining: 15.9s\n",
            "558:\tlearn: 0.0445736\ttotal: 20.1s\tremaining: 15.9s\n",
            "559:\tlearn: 0.0445387\ttotal: 20.2s\tremaining: 15.8s\n",
            "560:\tlearn: 0.0443290\ttotal: 20.2s\tremaining: 15.8s\n",
            "561:\tlearn: 0.0442566\ttotal: 20.2s\tremaining: 15.7s\n",
            "562:\tlearn: 0.0441419\ttotal: 20.2s\tremaining: 15.7s\n",
            "563:\tlearn: 0.0440059\ttotal: 20.2s\tremaining: 15.6s\n",
            "564:\tlearn: 0.0438731\ttotal: 20.3s\tremaining: 15.6s\n",
            "565:\tlearn: 0.0438481\ttotal: 20.3s\tremaining: 15.6s\n",
            "566:\tlearn: 0.0437148\ttotal: 20.3s\tremaining: 15.5s\n",
            "567:\tlearn: 0.0435516\ttotal: 20.3s\tremaining: 15.5s\n",
            "568:\tlearn: 0.0435291\ttotal: 20.3s\tremaining: 15.4s\n",
            "569:\tlearn: 0.0434070\ttotal: 20.4s\tremaining: 15.4s\n",
            "570:\tlearn: 0.0433872\ttotal: 20.4s\tremaining: 15.3s\n",
            "571:\tlearn: 0.0433680\ttotal: 20.4s\tremaining: 15.3s\n",
            "572:\tlearn: 0.0432375\ttotal: 20.4s\tremaining: 15.2s\n",
            "573:\tlearn: 0.0432064\ttotal: 20.5s\tremaining: 15.2s\n",
            "574:\tlearn: 0.0431711\ttotal: 20.5s\tremaining: 15.1s\n",
            "575:\tlearn: 0.0429462\ttotal: 20.5s\tremaining: 15.1s\n",
            "576:\tlearn: 0.0427448\ttotal: 20.5s\tremaining: 15s\n",
            "577:\tlearn: 0.0426045\ttotal: 20.5s\tremaining: 15s\n",
            "578:\tlearn: 0.0424483\ttotal: 20.6s\tremaining: 15s\n",
            "579:\tlearn: 0.0424288\ttotal: 20.6s\tremaining: 14.9s\n",
            "580:\tlearn: 0.0424099\ttotal: 20.6s\tremaining: 14.9s\n",
            "581:\tlearn: 0.0423826\ttotal: 20.6s\tremaining: 14.8s\n",
            "582:\tlearn: 0.0422955\ttotal: 20.6s\tremaining: 14.8s\n",
            "583:\tlearn: 0.0421996\ttotal: 20.7s\tremaining: 14.7s\n",
            "584:\tlearn: 0.0420567\ttotal: 20.7s\tremaining: 14.7s\n",
            "585:\tlearn: 0.0419095\ttotal: 20.7s\tremaining: 14.6s\n",
            "586:\tlearn: 0.0418795\ttotal: 20.7s\tremaining: 14.6s\n",
            "587:\tlearn: 0.0416881\ttotal: 20.7s\tremaining: 14.5s\n",
            "588:\tlearn: 0.0415075\ttotal: 20.8s\tremaining: 14.5s\n",
            "589:\tlearn: 0.0413773\ttotal: 20.8s\tremaining: 14.4s\n",
            "590:\tlearn: 0.0412441\ttotal: 20.8s\tremaining: 14.4s\n",
            "591:\tlearn: 0.0412183\ttotal: 20.8s\tremaining: 14.4s\n",
            "592:\tlearn: 0.0410803\ttotal: 20.8s\tremaining: 14.3s\n",
            "593:\tlearn: 0.0409343\ttotal: 20.9s\tremaining: 14.3s\n",
            "594:\tlearn: 0.0409163\ttotal: 20.9s\tremaining: 14.2s\n",
            "595:\tlearn: 0.0408913\ttotal: 20.9s\tremaining: 14.2s\n",
            "596:\tlearn: 0.0406634\ttotal: 20.9s\tremaining: 14.1s\n",
            "597:\tlearn: 0.0405676\ttotal: 21s\tremaining: 14.1s\n",
            "598:\tlearn: 0.0403578\ttotal: 21s\tremaining: 14s\n",
            "599:\tlearn: 0.0402300\ttotal: 21s\tremaining: 14s\n",
            "600:\tlearn: 0.0401402\ttotal: 21s\tremaining: 13.9s\n",
            "601:\tlearn: 0.0399292\ttotal: 21s\tremaining: 13.9s\n",
            "602:\tlearn: 0.0397250\ttotal: 21s\tremaining: 13.9s\n",
            "603:\tlearn: 0.0395447\ttotal: 21.1s\tremaining: 13.8s\n",
            "604:\tlearn: 0.0395263\ttotal: 21.1s\tremaining: 13.8s\n",
            "605:\tlearn: 0.0395020\ttotal: 21.1s\tremaining: 13.7s\n",
            "606:\tlearn: 0.0394125\ttotal: 21.1s\tremaining: 13.7s\n",
            "607:\tlearn: 0.0393905\ttotal: 21.2s\tremaining: 13.6s\n",
            "608:\tlearn: 0.0392822\ttotal: 21.2s\tremaining: 13.6s\n",
            "609:\tlearn: 0.0392436\ttotal: 21.2s\tremaining: 13.6s\n",
            "610:\tlearn: 0.0392226\ttotal: 21.2s\tremaining: 13.5s\n",
            "611:\tlearn: 0.0390979\ttotal: 21.2s\tremaining: 13.5s\n",
            "612:\tlearn: 0.0390213\ttotal: 21.3s\tremaining: 13.4s\n",
            "613:\tlearn: 0.0388780\ttotal: 21.3s\tremaining: 13.4s\n",
            "614:\tlearn: 0.0388642\ttotal: 21.3s\tremaining: 13.3s\n",
            "615:\tlearn: 0.0386942\ttotal: 21.3s\tremaining: 13.3s\n",
            "616:\tlearn: 0.0386717\ttotal: 21.3s\tremaining: 13.2s\n",
            "617:\tlearn: 0.0386528\ttotal: 21.4s\tremaining: 13.2s\n",
            "618:\tlearn: 0.0385422\ttotal: 21.4s\tremaining: 13.2s\n",
            "619:\tlearn: 0.0383088\ttotal: 21.4s\tremaining: 13.1s\n",
            "620:\tlearn: 0.0382429\ttotal: 21.4s\tremaining: 13.1s\n",
            "621:\tlearn: 0.0379604\ttotal: 21.4s\tremaining: 13s\n",
            "622:\tlearn: 0.0377960\ttotal: 21.5s\tremaining: 13s\n",
            "623:\tlearn: 0.0375101\ttotal: 21.5s\tremaining: 13s\n",
            "624:\tlearn: 0.0374602\ttotal: 21.5s\tremaining: 12.9s\n",
            "625:\tlearn: 0.0373183\ttotal: 21.5s\tremaining: 12.9s\n",
            "626:\tlearn: 0.0372349\ttotal: 21.6s\tremaining: 12.8s\n",
            "627:\tlearn: 0.0372138\ttotal: 21.6s\tremaining: 12.8s\n",
            "628:\tlearn: 0.0372004\ttotal: 21.6s\tremaining: 12.7s\n",
            "629:\tlearn: 0.0371716\ttotal: 21.6s\tremaining: 12.7s\n",
            "630:\tlearn: 0.0370206\ttotal: 21.6s\tremaining: 12.7s\n",
            "631:\tlearn: 0.0368612\ttotal: 21.7s\tremaining: 12.6s\n",
            "632:\tlearn: 0.0368441\ttotal: 21.7s\tremaining: 12.6s\n",
            "633:\tlearn: 0.0368314\ttotal: 21.7s\tremaining: 12.5s\n",
            "634:\tlearn: 0.0368104\ttotal: 21.7s\tremaining: 12.5s\n",
            "635:\tlearn: 0.0367638\ttotal: 21.7s\tremaining: 12.4s\n",
            "636:\tlearn: 0.0366786\ttotal: 21.8s\tremaining: 12.4s\n",
            "637:\tlearn: 0.0366624\ttotal: 21.8s\tremaining: 12.4s\n",
            "638:\tlearn: 0.0365275\ttotal: 21.8s\tremaining: 12.3s\n",
            "639:\tlearn: 0.0364369\ttotal: 21.8s\tremaining: 12.3s\n",
            "640:\tlearn: 0.0363189\ttotal: 21.8s\tremaining: 12.2s\n",
            "641:\tlearn: 0.0361984\ttotal: 21.9s\tremaining: 12.2s\n",
            "642:\tlearn: 0.0361830\ttotal: 21.9s\tremaining: 12.1s\n",
            "643:\tlearn: 0.0361594\ttotal: 21.9s\tremaining: 12.1s\n",
            "644:\tlearn: 0.0361130\ttotal: 21.9s\tremaining: 12.1s\n",
            "645:\tlearn: 0.0359510\ttotal: 21.9s\tremaining: 12s\n",
            "646:\tlearn: 0.0359333\ttotal: 22s\tremaining: 12s\n",
            "647:\tlearn: 0.0359139\ttotal: 22s\tremaining: 11.9s\n",
            "648:\tlearn: 0.0359019\ttotal: 22s\tremaining: 11.9s\n",
            "649:\tlearn: 0.0358249\ttotal: 22s\tremaining: 11.9s\n",
            "650:\tlearn: 0.0357245\ttotal: 22.1s\tremaining: 11.8s\n",
            "651:\tlearn: 0.0356284\ttotal: 22.1s\tremaining: 11.8s\n",
            "652:\tlearn: 0.0353943\ttotal: 22.1s\tremaining: 11.7s\n",
            "653:\tlearn: 0.0353158\ttotal: 22.1s\tremaining: 11.7s\n",
            "654:\tlearn: 0.0351888\ttotal: 22.1s\tremaining: 11.7s\n",
            "655:\tlearn: 0.0350406\ttotal: 22.2s\tremaining: 11.6s\n",
            "656:\tlearn: 0.0349635\ttotal: 22.2s\tremaining: 11.6s\n",
            "657:\tlearn: 0.0349451\ttotal: 22.2s\tremaining: 11.5s\n",
            "658:\tlearn: 0.0349327\ttotal: 22.2s\tremaining: 11.5s\n",
            "659:\tlearn: 0.0349189\ttotal: 22.2s\tremaining: 11.5s\n",
            "660:\tlearn: 0.0348171\ttotal: 22.3s\tremaining: 11.4s\n",
            "661:\tlearn: 0.0347989\ttotal: 22.3s\tremaining: 11.4s\n",
            "662:\tlearn: 0.0347858\ttotal: 22.3s\tremaining: 11.3s\n",
            "663:\tlearn: 0.0346423\ttotal: 22.3s\tremaining: 11.3s\n",
            "664:\tlearn: 0.0346268\ttotal: 22.3s\tremaining: 11.3s\n",
            "665:\tlearn: 0.0345058\ttotal: 22.4s\tremaining: 11.2s\n",
            "666:\tlearn: 0.0344490\ttotal: 22.4s\tremaining: 11.2s\n",
            "667:\tlearn: 0.0344353\ttotal: 22.4s\tremaining: 11.1s\n",
            "668:\tlearn: 0.0344188\ttotal: 22.4s\tremaining: 11.1s\n",
            "669:\tlearn: 0.0342666\ttotal: 22.4s\tremaining: 11.1s\n",
            "670:\tlearn: 0.0341225\ttotal: 22.5s\tremaining: 11s\n",
            "671:\tlearn: 0.0341029\ttotal: 22.5s\tremaining: 11s\n",
            "672:\tlearn: 0.0340890\ttotal: 22.5s\tremaining: 10.9s\n",
            "673:\tlearn: 0.0338915\ttotal: 22.5s\tremaining: 10.9s\n",
            "674:\tlearn: 0.0338756\ttotal: 22.6s\tremaining: 10.9s\n",
            "675:\tlearn: 0.0338581\ttotal: 22.6s\tremaining: 10.8s\n",
            "676:\tlearn: 0.0337067\ttotal: 22.6s\tremaining: 10.8s\n",
            "677:\tlearn: 0.0335942\ttotal: 22.6s\tremaining: 10.7s\n",
            "678:\tlearn: 0.0335818\ttotal: 22.6s\tremaining: 10.7s\n",
            "679:\tlearn: 0.0335668\ttotal: 22.7s\tremaining: 10.7s\n",
            "680:\tlearn: 0.0334563\ttotal: 22.7s\tremaining: 10.6s\n",
            "681:\tlearn: 0.0334432\ttotal: 22.7s\tremaining: 10.6s\n",
            "682:\tlearn: 0.0334324\ttotal: 22.7s\tremaining: 10.5s\n",
            "683:\tlearn: 0.0332334\ttotal: 22.7s\tremaining: 10.5s\n",
            "684:\tlearn: 0.0330551\ttotal: 22.8s\tremaining: 10.5s\n",
            "685:\tlearn: 0.0329551\ttotal: 22.8s\tremaining: 10.4s\n",
            "686:\tlearn: 0.0329446\ttotal: 22.8s\tremaining: 10.4s\n",
            "687:\tlearn: 0.0328064\ttotal: 22.8s\tremaining: 10.4s\n",
            "688:\tlearn: 0.0327169\ttotal: 22.8s\tremaining: 10.3s\n",
            "689:\tlearn: 0.0326421\ttotal: 22.9s\tremaining: 10.3s\n",
            "690:\tlearn: 0.0326245\ttotal: 22.9s\tremaining: 10.2s\n",
            "691:\tlearn: 0.0324521\ttotal: 22.9s\tremaining: 10.2s\n",
            "692:\tlearn: 0.0324403\ttotal: 22.9s\tremaining: 10.2s\n",
            "693:\tlearn: 0.0324279\ttotal: 23s\tremaining: 10.1s\n",
            "694:\tlearn: 0.0324177\ttotal: 23s\tremaining: 10.1s\n",
            "695:\tlearn: 0.0323755\ttotal: 23s\tremaining: 10s\n",
            "696:\tlearn: 0.0323382\ttotal: 23s\tremaining: 10s\n",
            "697:\tlearn: 0.0322219\ttotal: 23s\tremaining: 9.97s\n",
            "698:\tlearn: 0.0322072\ttotal: 23.1s\tremaining: 9.93s\n",
            "699:\tlearn: 0.0320410\ttotal: 23.1s\tremaining: 9.89s\n",
            "700:\tlearn: 0.0319309\ttotal: 23.1s\tremaining: 9.85s\n",
            "701:\tlearn: 0.0319191\ttotal: 23.1s\tremaining: 9.81s\n",
            "702:\tlearn: 0.0318515\ttotal: 23.1s\tremaining: 9.78s\n",
            "703:\tlearn: 0.0318403\ttotal: 23.2s\tremaining: 9.74s\n",
            "704:\tlearn: 0.0316931\ttotal: 23.2s\tremaining: 9.7s\n",
            "705:\tlearn: 0.0315481\ttotal: 23.2s\tremaining: 9.67s\n",
            "706:\tlearn: 0.0315385\ttotal: 23.2s\tremaining: 9.63s\n",
            "707:\tlearn: 0.0314884\ttotal: 23.3s\tremaining: 9.59s\n",
            "708:\tlearn: 0.0314719\ttotal: 23.3s\tremaining: 9.55s\n",
            "709:\tlearn: 0.0313668\ttotal: 23.3s\tremaining: 9.52s\n",
            "710:\tlearn: 0.0312868\ttotal: 23.3s\tremaining: 9.48s\n",
            "711:\tlearn: 0.0312745\ttotal: 23.3s\tremaining: 9.44s\n",
            "712:\tlearn: 0.0312421\ttotal: 23.4s\tremaining: 9.4s\n",
            "713:\tlearn: 0.0311813\ttotal: 23.4s\tremaining: 9.36s\n",
            "714:\tlearn: 0.0311544\ttotal: 23.4s\tremaining: 9.32s\n",
            "715:\tlearn: 0.0310408\ttotal: 23.4s\tremaining: 9.29s\n",
            "716:\tlearn: 0.0309571\ttotal: 23.4s\tremaining: 9.25s\n",
            "717:\tlearn: 0.0308187\ttotal: 23.5s\tremaining: 9.22s\n",
            "718:\tlearn: 0.0307890\ttotal: 23.5s\tremaining: 9.18s\n",
            "719:\tlearn: 0.0306824\ttotal: 23.5s\tremaining: 9.14s\n",
            "720:\tlearn: 0.0305334\ttotal: 23.5s\tremaining: 9.1s\n",
            "721:\tlearn: 0.0305197\ttotal: 23.6s\tremaining: 9.07s\n",
            "722:\tlearn: 0.0303834\ttotal: 23.6s\tremaining: 9.03s\n",
            "723:\tlearn: 0.0302887\ttotal: 23.6s\tremaining: 9s\n",
            "724:\tlearn: 0.0301161\ttotal: 23.6s\tremaining: 8.96s\n",
            "725:\tlearn: 0.0300774\ttotal: 23.6s\tremaining: 8.92s\n",
            "726:\tlearn: 0.0300618\ttotal: 23.7s\tremaining: 8.89s\n",
            "727:\tlearn: 0.0299684\ttotal: 23.7s\tremaining: 8.85s\n",
            "728:\tlearn: 0.0298638\ttotal: 23.7s\tremaining: 8.81s\n",
            "729:\tlearn: 0.0297825\ttotal: 23.7s\tremaining: 8.77s\n",
            "730:\tlearn: 0.0296898\ttotal: 23.7s\tremaining: 8.74s\n",
            "731:\tlearn: 0.0296810\ttotal: 23.8s\tremaining: 8.7s\n",
            "732:\tlearn: 0.0295036\ttotal: 23.8s\tremaining: 8.66s\n",
            "733:\tlearn: 0.0292899\ttotal: 23.8s\tremaining: 8.63s\n",
            "734:\tlearn: 0.0292781\ttotal: 23.8s\tremaining: 8.59s\n",
            "735:\tlearn: 0.0292680\ttotal: 23.8s\tremaining: 8.55s\n",
            "736:\tlearn: 0.0292591\ttotal: 23.9s\tremaining: 8.52s\n",
            "737:\tlearn: 0.0292512\ttotal: 23.9s\tremaining: 8.48s\n",
            "738:\tlearn: 0.0290921\ttotal: 23.9s\tremaining: 8.44s\n",
            "739:\tlearn: 0.0290838\ttotal: 23.9s\tremaining: 8.41s\n",
            "740:\tlearn: 0.0289767\ttotal: 23.9s\tremaining: 8.37s\n",
            "741:\tlearn: 0.0289642\ttotal: 24s\tremaining: 8.33s\n",
            "742:\tlearn: 0.0289498\ttotal: 24s\tremaining: 8.3s\n",
            "743:\tlearn: 0.0289279\ttotal: 24s\tremaining: 8.26s\n",
            "744:\tlearn: 0.0288247\ttotal: 24s\tremaining: 8.22s\n",
            "745:\tlearn: 0.0287092\ttotal: 24s\tremaining: 8.19s\n",
            "746:\tlearn: 0.0286429\ttotal: 24.1s\tremaining: 8.15s\n",
            "747:\tlearn: 0.0286348\ttotal: 24.1s\tremaining: 8.12s\n",
            "748:\tlearn: 0.0285315\ttotal: 24.1s\tremaining: 8.08s\n",
            "749:\tlearn: 0.0283987\ttotal: 24.1s\tremaining: 8.04s\n",
            "750:\tlearn: 0.0283775\ttotal: 24.2s\tremaining: 8.01s\n",
            "751:\tlearn: 0.0283696\ttotal: 24.2s\tremaining: 7.97s\n",
            "752:\tlearn: 0.0282356\ttotal: 24.2s\tremaining: 7.94s\n",
            "753:\tlearn: 0.0282272\ttotal: 24.2s\tremaining: 7.9s\n",
            "754:\tlearn: 0.0282200\ttotal: 24.2s\tremaining: 7.87s\n",
            "755:\tlearn: 0.0282100\ttotal: 24.3s\tremaining: 7.83s\n",
            "756:\tlearn: 0.0281971\ttotal: 24.3s\tremaining: 7.79s\n",
            "757:\tlearn: 0.0280934\ttotal: 24.3s\tremaining: 7.76s\n",
            "758:\tlearn: 0.0280775\ttotal: 24.3s\tremaining: 7.72s\n",
            "759:\tlearn: 0.0280604\ttotal: 24.3s\tremaining: 7.69s\n",
            "760:\tlearn: 0.0278910\ttotal: 24.4s\tremaining: 7.65s\n",
            "761:\tlearn: 0.0276646\ttotal: 24.4s\tremaining: 7.61s\n",
            "762:\tlearn: 0.0275134\ttotal: 24.4s\tremaining: 7.58s\n",
            "763:\tlearn: 0.0274994\ttotal: 24.4s\tremaining: 7.54s\n",
            "764:\tlearn: 0.0274032\ttotal: 24.4s\tremaining: 7.51s\n",
            "765:\tlearn: 0.0272454\ttotal: 24.5s\tremaining: 7.47s\n",
            "766:\tlearn: 0.0272350\ttotal: 24.5s\tremaining: 7.44s\n",
            "767:\tlearn: 0.0271380\ttotal: 24.5s\tremaining: 7.4s\n",
            "768:\tlearn: 0.0271245\ttotal: 24.5s\tremaining: 7.37s\n",
            "769:\tlearn: 0.0270163\ttotal: 24.5s\tremaining: 7.33s\n",
            "770:\tlearn: 0.0269978\ttotal: 24.6s\tremaining: 7.3s\n",
            "771:\tlearn: 0.0269909\ttotal: 24.6s\tremaining: 7.26s\n",
            "772:\tlearn: 0.0269820\ttotal: 24.6s\tremaining: 7.23s\n",
            "773:\tlearn: 0.0268698\ttotal: 24.6s\tremaining: 7.2s\n",
            "774:\tlearn: 0.0267677\ttotal: 24.7s\tremaining: 7.16s\n",
            "775:\tlearn: 0.0267597\ttotal: 24.7s\tremaining: 7.13s\n",
            "776:\tlearn: 0.0267417\ttotal: 24.7s\tremaining: 7.09s\n",
            "777:\tlearn: 0.0267347\ttotal: 24.7s\tremaining: 7.06s\n",
            "778:\tlearn: 0.0266863\ttotal: 24.8s\tremaining: 7.03s\n",
            "779:\tlearn: 0.0266785\ttotal: 24.8s\tremaining: 6.99s\n",
            "780:\tlearn: 0.0265877\ttotal: 24.8s\tremaining: 6.96s\n",
            "781:\tlearn: 0.0265690\ttotal: 24.8s\tremaining: 6.92s\n",
            "782:\tlearn: 0.0265625\ttotal: 24.8s\tremaining: 6.88s\n",
            "783:\tlearn: 0.0264952\ttotal: 24.9s\tremaining: 6.85s\n",
            "784:\tlearn: 0.0264875\ttotal: 24.9s\tremaining: 6.81s\n",
            "785:\tlearn: 0.0264049\ttotal: 24.9s\tremaining: 6.78s\n",
            "786:\tlearn: 0.0263976\ttotal: 24.9s\tremaining: 6.75s\n",
            "787:\tlearn: 0.0263415\ttotal: 24.9s\tremaining: 6.71s\n",
            "788:\tlearn: 0.0263304\ttotal: 25s\tremaining: 6.67s\n",
            "789:\tlearn: 0.0263239\ttotal: 25s\tremaining: 6.64s\n",
            "790:\tlearn: 0.0263175\ttotal: 25s\tremaining: 6.61s\n",
            "791:\tlearn: 0.0263097\ttotal: 25s\tremaining: 6.57s\n",
            "792:\tlearn: 0.0263034\ttotal: 25s\tremaining: 6.54s\n",
            "793:\tlearn: 0.0261924\ttotal: 25.1s\tremaining: 6.5s\n",
            "794:\tlearn: 0.0261320\ttotal: 25.1s\tremaining: 6.47s\n",
            "795:\tlearn: 0.0261146\ttotal: 25.1s\tremaining: 6.43s\n",
            "796:\tlearn: 0.0260321\ttotal: 25.1s\tremaining: 6.4s\n",
            "797:\tlearn: 0.0260200\ttotal: 25.2s\tremaining: 6.37s\n",
            "798:\tlearn: 0.0260124\ttotal: 25.2s\tremaining: 6.33s\n",
            "799:\tlearn: 0.0259495\ttotal: 25.2s\tremaining: 6.3s\n",
            "800:\tlearn: 0.0259432\ttotal: 25.2s\tremaining: 6.26s\n",
            "801:\tlearn: 0.0258783\ttotal: 25.2s\tremaining: 6.23s\n",
            "802:\tlearn: 0.0257452\ttotal: 25.3s\tremaining: 6.2s\n",
            "803:\tlearn: 0.0257327\ttotal: 25.3s\tremaining: 6.16s\n",
            "804:\tlearn: 0.0256357\ttotal: 25.3s\tremaining: 6.13s\n",
            "805:\tlearn: 0.0255514\ttotal: 25.3s\tremaining: 6.09s\n",
            "806:\tlearn: 0.0254936\ttotal: 25.3s\tremaining: 6.06s\n",
            "807:\tlearn: 0.0254845\ttotal: 25.4s\tremaining: 6.02s\n",
            "808:\tlearn: 0.0254726\ttotal: 25.4s\tremaining: 5.99s\n",
            "809:\tlearn: 0.0254529\ttotal: 25.4s\tremaining: 5.96s\n",
            "810:\tlearn: 0.0253417\ttotal: 25.4s\tremaining: 5.92s\n",
            "811:\tlearn: 0.0252291\ttotal: 25.4s\tremaining: 5.89s\n",
            "812:\tlearn: 0.0252124\ttotal: 25.5s\tremaining: 5.85s\n",
            "813:\tlearn: 0.0252069\ttotal: 25.5s\tremaining: 5.82s\n",
            "814:\tlearn: 0.0251995\ttotal: 25.5s\tremaining: 5.79s\n",
            "815:\tlearn: 0.0251441\ttotal: 25.5s\tremaining: 5.75s\n",
            "816:\tlearn: 0.0251224\ttotal: 25.5s\tremaining: 5.72s\n",
            "817:\tlearn: 0.0251163\ttotal: 25.6s\tremaining: 5.68s\n",
            "818:\tlearn: 0.0250000\ttotal: 25.6s\tremaining: 5.65s\n",
            "819:\tlearn: 0.0249009\ttotal: 25.6s\tremaining: 5.62s\n",
            "820:\tlearn: 0.0248940\ttotal: 25.6s\tremaining: 5.59s\n",
            "821:\tlearn: 0.0248809\ttotal: 25.7s\tremaining: 5.55s\n",
            "822:\tlearn: 0.0248356\ttotal: 25.7s\tremaining: 5.52s\n",
            "823:\tlearn: 0.0248262\ttotal: 25.7s\tremaining: 5.49s\n",
            "824:\tlearn: 0.0248201\ttotal: 25.7s\tremaining: 5.45s\n",
            "825:\tlearn: 0.0247234\ttotal: 25.7s\tremaining: 5.42s\n",
            "826:\tlearn: 0.0246659\ttotal: 25.8s\tremaining: 5.39s\n",
            "827:\tlearn: 0.0246589\ttotal: 25.8s\tremaining: 5.35s\n",
            "828:\tlearn: 0.0246525\ttotal: 25.8s\tremaining: 5.32s\n",
            "829:\tlearn: 0.0246467\ttotal: 25.8s\tremaining: 5.29s\n",
            "830:\tlearn: 0.0246339\ttotal: 25.8s\tremaining: 5.25s\n",
            "831:\tlearn: 0.0245033\ttotal: 25.9s\tremaining: 5.22s\n",
            "832:\tlearn: 0.0244977\ttotal: 25.9s\tremaining: 5.19s\n",
            "833:\tlearn: 0.0244912\ttotal: 25.9s\tremaining: 5.15s\n",
            "834:\tlearn: 0.0243788\ttotal: 25.9s\tremaining: 5.12s\n",
            "835:\tlearn: 0.0243724\ttotal: 25.9s\tremaining: 5.09s\n",
            "836:\tlearn: 0.0243560\ttotal: 26s\tremaining: 5.05s\n",
            "837:\tlearn: 0.0242354\ttotal: 26s\tremaining: 5.02s\n",
            "838:\tlearn: 0.0241857\ttotal: 26s\tremaining: 4.99s\n",
            "839:\tlearn: 0.0241212\ttotal: 26s\tremaining: 4.96s\n",
            "840:\tlearn: 0.0241059\ttotal: 26s\tremaining: 4.92s\n",
            "841:\tlearn: 0.0240510\ttotal: 26.1s\tremaining: 4.89s\n",
            "842:\tlearn: 0.0240365\ttotal: 26.1s\tremaining: 4.86s\n",
            "843:\tlearn: 0.0240307\ttotal: 26.1s\tremaining: 4.82s\n",
            "844:\tlearn: 0.0239232\ttotal: 26.1s\tremaining: 4.79s\n",
            "845:\tlearn: 0.0239179\ttotal: 26.1s\tremaining: 4.76s\n",
            "846:\tlearn: 0.0239125\ttotal: 26.2s\tremaining: 4.73s\n",
            "847:\tlearn: 0.0238163\ttotal: 26.2s\tremaining: 4.69s\n",
            "848:\tlearn: 0.0237715\ttotal: 26.2s\tremaining: 4.66s\n",
            "849:\tlearn: 0.0237615\ttotal: 26.2s\tremaining: 4.63s\n",
            "850:\tlearn: 0.0237497\ttotal: 26.2s\tremaining: 4.59s\n",
            "851:\tlearn: 0.0237446\ttotal: 26.3s\tremaining: 4.56s\n",
            "852:\tlearn: 0.0237343\ttotal: 26.3s\tremaining: 4.53s\n",
            "853:\tlearn: 0.0237290\ttotal: 26.3s\tremaining: 4.5s\n",
            "854:\tlearn: 0.0237180\ttotal: 26.3s\tremaining: 4.46s\n",
            "855:\tlearn: 0.0237127\ttotal: 26.3s\tremaining: 4.43s\n",
            "856:\tlearn: 0.0236196\ttotal: 26.4s\tremaining: 4.4s\n",
            "857:\tlearn: 0.0235020\ttotal: 26.4s\tremaining: 4.37s\n",
            "858:\tlearn: 0.0233959\ttotal: 26.4s\tremaining: 4.33s\n",
            "859:\tlearn: 0.0233579\ttotal: 26.4s\tremaining: 4.3s\n",
            "860:\tlearn: 0.0232635\ttotal: 26.4s\tremaining: 4.27s\n",
            "861:\tlearn: 0.0232368\ttotal: 26.5s\tremaining: 4.24s\n",
            "862:\tlearn: 0.0231161\ttotal: 26.5s\tremaining: 4.21s\n",
            "863:\tlearn: 0.0230342\ttotal: 26.5s\tremaining: 4.17s\n",
            "864:\tlearn: 0.0230240\ttotal: 26.5s\tremaining: 4.14s\n",
            "865:\tlearn: 0.0230161\ttotal: 26.6s\tremaining: 4.11s\n",
            "866:\tlearn: 0.0229498\ttotal: 26.6s\tremaining: 4.08s\n",
            "867:\tlearn: 0.0229447\ttotal: 26.6s\tremaining: 4.04s\n",
            "868:\tlearn: 0.0228355\ttotal: 26.6s\tremaining: 4.01s\n",
            "869:\tlearn: 0.0227916\ttotal: 26.6s\tremaining: 3.98s\n",
            "870:\tlearn: 0.0227139\ttotal: 26.7s\tremaining: 3.95s\n",
            "871:\tlearn: 0.0227035\ttotal: 26.7s\tremaining: 3.92s\n",
            "872:\tlearn: 0.0226954\ttotal: 26.7s\tremaining: 3.89s\n",
            "873:\tlearn: 0.0225985\ttotal: 26.7s\tremaining: 3.85s\n",
            "874:\tlearn: 0.0225668\ttotal: 26.8s\tremaining: 3.82s\n",
            "875:\tlearn: 0.0224527\ttotal: 26.8s\tremaining: 3.79s\n",
            "876:\tlearn: 0.0224429\ttotal: 26.8s\tremaining: 3.76s\n",
            "877:\tlearn: 0.0223755\ttotal: 26.9s\tremaining: 3.73s\n",
            "878:\tlearn: 0.0222308\ttotal: 26.9s\tremaining: 3.7s\n",
            "879:\tlearn: 0.0221305\ttotal: 26.9s\tremaining: 3.67s\n",
            "880:\tlearn: 0.0221223\ttotal: 27s\tremaining: 3.64s\n",
            "881:\tlearn: 0.0220929\ttotal: 27s\tremaining: 3.61s\n",
            "882:\tlearn: 0.0220877\ttotal: 27s\tremaining: 3.58s\n",
            "883:\tlearn: 0.0220776\ttotal: 27.1s\tremaining: 3.55s\n",
            "884:\tlearn: 0.0220720\ttotal: 27.1s\tremaining: 3.52s\n",
            "885:\tlearn: 0.0220666\ttotal: 27.2s\tremaining: 3.49s\n",
            "886:\tlearn: 0.0219802\ttotal: 27.2s\tremaining: 3.46s\n",
            "887:\tlearn: 0.0218919\ttotal: 27.2s\tremaining: 3.44s\n",
            "888:\tlearn: 0.0218871\ttotal: 27.3s\tremaining: 3.41s\n",
            "889:\tlearn: 0.0218096\ttotal: 27.3s\tremaining: 3.38s\n",
            "890:\tlearn: 0.0217994\ttotal: 27.4s\tremaining: 3.35s\n",
            "891:\tlearn: 0.0217771\ttotal: 27.4s\tremaining: 3.32s\n",
            "892:\tlearn: 0.0217725\ttotal: 27.5s\tremaining: 3.29s\n",
            "893:\tlearn: 0.0217321\ttotal: 27.5s\tremaining: 3.26s\n",
            "894:\tlearn: 0.0217237\ttotal: 27.5s\tremaining: 3.23s\n",
            "895:\tlearn: 0.0217148\ttotal: 27.6s\tremaining: 3.2s\n",
            "896:\tlearn: 0.0217105\ttotal: 27.6s\tremaining: 3.17s\n",
            "897:\tlearn: 0.0217065\ttotal: 27.7s\tremaining: 3.14s\n",
            "898:\tlearn: 0.0216255\ttotal: 27.7s\tremaining: 3.11s\n",
            "899:\tlearn: 0.0216160\ttotal: 27.8s\tremaining: 3.08s\n",
            "900:\tlearn: 0.0215317\ttotal: 27.8s\tremaining: 3.05s\n",
            "901:\tlearn: 0.0214415\ttotal: 27.8s\tremaining: 3.02s\n",
            "902:\tlearn: 0.0213960\ttotal: 27.9s\tremaining: 2.99s\n",
            "903:\tlearn: 0.0213407\ttotal: 27.9s\tremaining: 2.96s\n",
            "904:\tlearn: 0.0213321\ttotal: 28s\tremaining: 2.94s\n",
            "905:\tlearn: 0.0213230\ttotal: 28s\tremaining: 2.9s\n",
            "906:\tlearn: 0.0213185\ttotal: 28s\tremaining: 2.87s\n",
            "907:\tlearn: 0.0212486\ttotal: 28.1s\tremaining: 2.84s\n",
            "908:\tlearn: 0.0212396\ttotal: 28.1s\tremaining: 2.81s\n",
            "909:\tlearn: 0.0212310\ttotal: 28.2s\tremaining: 2.78s\n",
            "910:\tlearn: 0.0211183\ttotal: 28.2s\tremaining: 2.75s\n",
            "911:\tlearn: 0.0210341\ttotal: 28.2s\tremaining: 2.72s\n",
            "912:\tlearn: 0.0209750\ttotal: 28.3s\tremaining: 2.69s\n",
            "913:\tlearn: 0.0209049\ttotal: 28.3s\tremaining: 2.66s\n",
            "914:\tlearn: 0.0208570\ttotal: 28.3s\tremaining: 2.63s\n",
            "915:\tlearn: 0.0208475\ttotal: 28.4s\tremaining: 2.6s\n",
            "916:\tlearn: 0.0208403\ttotal: 28.4s\tremaining: 2.57s\n",
            "917:\tlearn: 0.0207789\ttotal: 28.5s\tremaining: 2.54s\n",
            "918:\tlearn: 0.0206912\ttotal: 28.5s\tremaining: 2.51s\n",
            "919:\tlearn: 0.0206384\ttotal: 28.6s\tremaining: 2.48s\n",
            "920:\tlearn: 0.0205593\ttotal: 28.6s\tremaining: 2.45s\n",
            "921:\tlearn: 0.0205011\ttotal: 28.6s\tremaining: 2.42s\n",
            "922:\tlearn: 0.0204425\ttotal: 28.7s\tremaining: 2.39s\n",
            "923:\tlearn: 0.0203945\ttotal: 28.7s\tremaining: 2.36s\n",
            "924:\tlearn: 0.0203320\ttotal: 28.7s\tremaining: 2.33s\n",
            "925:\tlearn: 0.0203202\ttotal: 28.8s\tremaining: 2.3s\n",
            "926:\tlearn: 0.0203111\ttotal: 28.8s\tremaining: 2.27s\n",
            "927:\tlearn: 0.0202568\ttotal: 28.9s\tremaining: 2.24s\n",
            "928:\tlearn: 0.0202502\ttotal: 28.9s\tremaining: 2.21s\n",
            "929:\tlearn: 0.0201877\ttotal: 29s\tremaining: 2.18s\n",
            "930:\tlearn: 0.0201839\ttotal: 29s\tremaining: 2.15s\n",
            "931:\tlearn: 0.0201007\ttotal: 29s\tremaining: 2.12s\n",
            "932:\tlearn: 0.0200230\ttotal: 29.1s\tremaining: 2.09s\n",
            "933:\tlearn: 0.0200117\ttotal: 29.1s\tremaining: 2.06s\n",
            "934:\tlearn: 0.0200029\ttotal: 29.2s\tremaining: 2.03s\n",
            "935:\tlearn: 0.0199989\ttotal: 29.2s\tremaining: 2s\n",
            "936:\tlearn: 0.0199910\ttotal: 29.2s\tremaining: 1.97s\n",
            "937:\tlearn: 0.0199869\ttotal: 29.3s\tremaining: 1.94s\n",
            "938:\tlearn: 0.0198989\ttotal: 29.3s\tremaining: 1.91s\n",
            "939:\tlearn: 0.0198898\ttotal: 29.4s\tremaining: 1.87s\n",
            "940:\tlearn: 0.0198867\ttotal: 29.4s\tremaining: 1.84s\n",
            "941:\tlearn: 0.0198152\ttotal: 29.4s\tremaining: 1.81s\n",
            "942:\tlearn: 0.0197754\ttotal: 29.5s\tremaining: 1.78s\n",
            "943:\tlearn: 0.0197203\ttotal: 29.5s\tremaining: 1.75s\n",
            "944:\tlearn: 0.0196681\ttotal: 29.6s\tremaining: 1.72s\n",
            "945:\tlearn: 0.0195774\ttotal: 29.6s\tremaining: 1.69s\n",
            "946:\tlearn: 0.0195511\ttotal: 29.7s\tremaining: 1.66s\n",
            "947:\tlearn: 0.0194790\ttotal: 29.7s\tremaining: 1.63s\n",
            "948:\tlearn: 0.0194751\ttotal: 29.8s\tremaining: 1.6s\n",
            "949:\tlearn: 0.0194447\ttotal: 29.8s\tremaining: 1.57s\n",
            "950:\tlearn: 0.0194375\ttotal: 29.8s\tremaining: 1.54s\n",
            "951:\tlearn: 0.0193713\ttotal: 29.9s\tremaining: 1.51s\n",
            "952:\tlearn: 0.0192892\ttotal: 29.9s\tremaining: 1.48s\n",
            "953:\tlearn: 0.0192855\ttotal: 30s\tremaining: 1.44s\n",
            "954:\tlearn: 0.0192747\ttotal: 30s\tremaining: 1.41s\n",
            "955:\tlearn: 0.0192712\ttotal: 30s\tremaining: 1.38s\n",
            "956:\tlearn: 0.0192672\ttotal: 30.1s\tremaining: 1.35s\n",
            "957:\tlearn: 0.0191939\ttotal: 30.1s\tremaining: 1.32s\n",
            "958:\tlearn: 0.0191602\ttotal: 30.1s\tremaining: 1.29s\n",
            "959:\tlearn: 0.0190983\ttotal: 30.2s\tremaining: 1.26s\n",
            "960:\tlearn: 0.0190635\ttotal: 30.2s\tremaining: 1.23s\n",
            "961:\tlearn: 0.0189828\ttotal: 30.3s\tremaining: 1.2s\n",
            "962:\tlearn: 0.0189757\ttotal: 30.3s\tremaining: 1.16s\n",
            "963:\tlearn: 0.0189720\ttotal: 30.3s\tremaining: 1.13s\n",
            "964:\tlearn: 0.0189654\ttotal: 30.4s\tremaining: 1.1s\n",
            "965:\tlearn: 0.0189348\ttotal: 30.4s\tremaining: 1.07s\n",
            "966:\tlearn: 0.0189274\ttotal: 30.5s\tremaining: 1.04s\n",
            "967:\tlearn: 0.0188827\ttotal: 30.5s\tremaining: 1.01s\n",
            "968:\tlearn: 0.0188199\ttotal: 30.5s\tremaining: 977ms\n",
            "969:\tlearn: 0.0187938\ttotal: 30.6s\tremaining: 946ms\n",
            "970:\tlearn: 0.0187875\ttotal: 30.6s\tremaining: 915ms\n",
            "971:\tlearn: 0.0187791\ttotal: 30.7s\tremaining: 884ms\n",
            "972:\tlearn: 0.0187758\ttotal: 30.7s\tremaining: 852ms\n",
            "973:\tlearn: 0.0187653\ttotal: 30.8s\tremaining: 821ms\n",
            "974:\tlearn: 0.0187614\ttotal: 30.8s\tremaining: 790ms\n",
            "975:\tlearn: 0.0186718\ttotal: 30.8s\tremaining: 758ms\n",
            "976:\tlearn: 0.0186209\ttotal: 30.9s\tremaining: 727ms\n",
            "977:\tlearn: 0.0186175\ttotal: 30.9s\tremaining: 695ms\n",
            "978:\tlearn: 0.0185028\ttotal: 31s\tremaining: 664ms\n",
            "979:\tlearn: 0.0184774\ttotal: 31s\tremaining: 632ms\n",
            "980:\tlearn: 0.0184690\ttotal: 31s\tremaining: 600ms\n",
            "981:\tlearn: 0.0183861\ttotal: 31s\tremaining: 569ms\n",
            "982:\tlearn: 0.0183761\ttotal: 31s\tremaining: 537ms\n",
            "983:\tlearn: 0.0183664\ttotal: 31.1s\tremaining: 505ms\n",
            "984:\tlearn: 0.0183626\ttotal: 31.1s\tremaining: 473ms\n",
            "985:\tlearn: 0.0183596\ttotal: 31.1s\tremaining: 442ms\n",
            "986:\tlearn: 0.0182800\ttotal: 31.1s\tremaining: 410ms\n",
            "987:\tlearn: 0.0182356\ttotal: 31.1s\tremaining: 378ms\n",
            "988:\tlearn: 0.0182113\ttotal: 31.2s\tremaining: 347ms\n",
            "989:\tlearn: 0.0182078\ttotal: 31.2s\tremaining: 315ms\n",
            "990:\tlearn: 0.0182043\ttotal: 31.2s\tremaining: 283ms\n",
            "991:\tlearn: 0.0182009\ttotal: 31.2s\tremaining: 252ms\n",
            "992:\tlearn: 0.0181976\ttotal: 31.3s\tremaining: 220ms\n",
            "993:\tlearn: 0.0181884\ttotal: 31.3s\tremaining: 189ms\n",
            "994:\tlearn: 0.0181444\ttotal: 31.3s\tremaining: 157ms\n",
            "995:\tlearn: 0.0180937\ttotal: 31.3s\tremaining: 126ms\n",
            "996:\tlearn: 0.0180533\ttotal: 31.3s\tremaining: 94.3ms\n",
            "997:\tlearn: 0.0180457\ttotal: 31.4s\tremaining: 62.8ms\n",
            "998:\tlearn: 0.0179745\ttotal: 31.4s\tremaining: 31.4ms\n",
            "999:\tlearn: 0.0179711\ttotal: 31.4s\tremaining: 0us\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 31.833112955093384\n",
            "CPU times: user 37.1 s, sys: 4.3 s, total: 41.4 s\n",
            "Wall time: 31.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Stochastic Gradient Descent (SGD)**"
      ],
      "metadata": {
        "id": "MfzCGwacnmM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Stochastic Gradient Descent (SGD)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Stochastic Gradient Descent (SGD)'][0])\n",
        "print(\"Precision:\", results['Stochastic Gradient Descent (SGD)'][1])\n",
        "print(\"Recall:\", results['Stochastic Gradient Descent (SGD)'][2])\n",
        "print(\"F1-score:\", results['Stochastic Gradient Descent (SGD)'][3])\n",
        "print(\"Training Time:\", results['Stochastic Gradient Descent (SGD)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGYIMrV1noie",
        "outputId": "d6cd8728-bcd9-49e0-aacf-0aa693316de0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 0.004798412322998047\n",
            "CPU times: user 14.9 ms, sys: 0 ns, total: 14.9 ms\n",
            "Wall time: 15.2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Linear Discriminant Analysis (LDA)**"
      ],
      "metadata": {
        "id": "hFd3OieZKDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Initialize Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lda.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lda.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaoOVVwFKERs",
        "outputId": "e0e329db-6b46-49d3-885e-9ba79a64d8c4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9906666666666667\n",
            "Precision: 0.9907830650972412\n",
            "Recall: 0.9906666666666667\n",
            "F1-score: 0.9906792563465785\n",
            "Training Time: 3.8185791969299316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Quadratic Discriminant Analysis (QDA)**"
      ],
      "metadata": {
        "id": "r-Kr6q8VKIyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Initialize Quadratic Discriminant Analysis (QDA)\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "qda.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = qda.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPrQyz2rKMbZ",
        "outputId": "1a87c530-d27c-4a2e-aa7b-af0960eabb06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 2.300788640975952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks 🧠"
      ],
      "metadata": {
        "id": "oTHFBxWJKRym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating NN layers and compiling with loss, metrics, optimizer configs"
      ],
      "metadata": {
        "id": "eeuS5khpopxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training NN"
      ],
      "metadata": {
        "id": "_Q-qs1TXoqfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Convert SparseTensor to dense numpy arrays\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_dense,\n",
        "                     y_train,\n",
        "                     epochs=500,\n",
        "                     verbose=1,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(X_test_dense, y_test))\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3YIzhuKXLz",
        "outputId": "8b414b14-db19-4278-b063-246604c60e4b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - binary_accuracy: 0.6372 - loss: 0.6307 - val_binary_accuracy: 0.9513 - val_loss: 0.2492\n",
            "Epoch 2/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 0.9710 - loss: 0.1592 - val_binary_accuracy: 0.9980 - val_loss: 0.0225\n",
            "Epoch 3/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 0.9970 - loss: 0.0190 - val_binary_accuracy: 1.0000 - val_loss: 0.0063\n",
            "Epoch 4/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 0.0065 - val_binary_accuracy: 1.0000 - val_loss: 0.0028\n",
            "Epoch 5/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 0.0024 - val_binary_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 6/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 0.0014 - val_binary_accuracy: 1.0000 - val_loss: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 0.0011 - val_binary_accuracy: 1.0000 - val_loss: 7.2275e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.1960e-04 - val_binary_accuracy: 1.0000 - val_loss: 5.4125e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.1923e-04 - val_binary_accuracy: 1.0000 - val_loss: 4.0873e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 3.4067e-04 - val_binary_accuracy: 1.0000 - val_loss: 3.1996e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.2748e-04 - val_binary_accuracy: 1.0000 - val_loss: 2.5405e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3672e-04 - val_binary_accuracy: 1.0000 - val_loss: 2.0655e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9447e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.6973e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6180e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.4100e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.4094e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.1887e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.1102e-04 - val_binary_accuracy: 1.0000 - val_loss: 1.0146e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0774e-04 - val_binary_accuracy: 1.0000 - val_loss: 8.7018e-05\n",
            "Epoch 18/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.0487e-05 - val_binary_accuracy: 1.0000 - val_loss: 7.5829e-05\n",
            "Epoch 19/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.1749e-05 - val_binary_accuracy: 1.0000 - val_loss: 6.6407e-05\n",
            "Epoch 20/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 6.9244e-05 - val_binary_accuracy: 1.0000 - val_loss: 5.8551e-05\n",
            "Epoch 21/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 5.6388e-05 - val_binary_accuracy: 1.0000 - val_loss: 5.2274e-05\n",
            "Epoch 22/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 4.5029e-05 - val_binary_accuracy: 1.0000 - val_loss: 4.6819e-05\n",
            "Epoch 23/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.1968e-05 - val_binary_accuracy: 1.0000 - val_loss: 4.1901e-05\n",
            "Epoch 24/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.8806e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.7822e-05\n",
            "Epoch 25/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.8301e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.4381e-05\n",
            "Epoch 26/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 3.8730e-05 - val_binary_accuracy: 1.0000 - val_loss: 3.1274e-05\n",
            "Epoch 27/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.0399e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.8666e-05\n",
            "Epoch 28/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.3988e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.6290e-05\n",
            "Epoch 29/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.7746e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.4077e-05\n",
            "Epoch 30/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1748e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.2326e-05\n",
            "Epoch 31/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9606e-05 - val_binary_accuracy: 1.0000 - val_loss: 2.0651e-05\n",
            "Epoch 32/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9648e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.9155e-05\n",
            "Epoch 33/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8317e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.7814e-05\n",
            "Epoch 34/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.8839e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.6571e-05\n",
            "Epoch 35/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5840e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.5476e-05\n",
            "Epoch 36/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7939e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.4488e-05\n",
            "Epoch 37/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3189e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.3620e-05\n",
            "Epoch 38/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.2582e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.2751e-05\n",
            "Epoch 39/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1812e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.2006e-05\n",
            "Epoch 40/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1073e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.1313e-05\n",
            "Epoch 41/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.1512e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.0644e-05\n",
            "Epoch 42/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 1.0149e-05 - val_binary_accuracy: 1.0000 - val_loss: 1.0057e-05\n",
            "Epoch 43/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 9.4219e-06 - val_binary_accuracy: 1.0000 - val_loss: 9.5055e-06\n",
            "Epoch 44/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 9.2301e-06 - val_binary_accuracy: 1.0000 - val_loss: 8.9953e-06\n",
            "Epoch 45/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 8.5718e-06 - val_binary_accuracy: 1.0000 - val_loss: 8.5342e-06\n",
            "Epoch 46/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 8.2571e-06 - val_binary_accuracy: 1.0000 - val_loss: 8.0797e-06\n",
            "Epoch 47/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.7485e-06 - val_binary_accuracy: 1.0000 - val_loss: 7.6704e-06\n",
            "Epoch 48/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.0605e-06 - val_binary_accuracy: 1.0000 - val_loss: 7.2773e-06\n",
            "Epoch 49/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.0325e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.9282e-06\n",
            "Epoch 50/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.5668e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.5897e-06\n",
            "Epoch 51/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.6476e-06 - val_binary_accuracy: 1.0000 - val_loss: 6.2896e-06\n",
            "Epoch 52/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.8406e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.9977e-06\n",
            "Epoch 53/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 5.1072e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.7251e-06\n",
            "Epoch 54/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 5.6199e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.4613e-06\n",
            "Epoch 55/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2943e-06 - val_binary_accuracy: 1.0000 - val_loss: 5.2277e-06\n",
            "Epoch 56/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.3534e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.9859e-06\n",
            "Epoch 57/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7208e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.7701e-06\n",
            "Epoch 58/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.4379e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.5675e-06\n",
            "Epoch 59/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.4870e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.3750e-06\n",
            "Epoch 60/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.4799e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.1942e-06\n",
            "Epoch 61/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.9994e-06 - val_binary_accuracy: 1.0000 - val_loss: 4.0179e-06\n",
            "Epoch 62/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.4091e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.8510e-06\n",
            "Epoch 63/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.5404e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.6929e-06\n",
            "Epoch 64/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - binary_accuracy: 1.0000 - loss: 3.8357e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.5511e-06\n",
            "Epoch 65/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 3.5225e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.4151e-06\n",
            "Epoch 66/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 3.0735e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.2770e-06\n",
            "Epoch 67/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 3.7066e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.1453e-06\n",
            "Epoch 68/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.3590e-06 - val_binary_accuracy: 1.0000 - val_loss: 3.0258e-06\n",
            "Epoch 69/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.1783e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.9098e-06\n",
            "Epoch 70/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.0297e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.8027e-06\n",
            "Epoch 71/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.0509e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.6979e-06\n",
            "Epoch 72/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.4389e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.6013e-06\n",
            "Epoch 73/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3014e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.5055e-06\n",
            "Epoch 74/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5976e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.4142e-06\n",
            "Epoch 75/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1722e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.3300e-06\n",
            "Epoch 76/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0655e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.2443e-06\n",
            "Epoch 77/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.1426e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.1634e-06\n",
            "Epoch 78/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0882e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.0878e-06\n",
            "Epoch 79/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.1054e-06 - val_binary_accuracy: 1.0000 - val_loss: 2.0127e-06\n",
            "Epoch 80/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9751e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.9447e-06\n",
            "Epoch 81/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 1.6967e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.8774e-06\n",
            "Epoch 82/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9798e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.8113e-06\n",
            "Epoch 83/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9620e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.7488e-06\n",
            "Epoch 84/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5685e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.6935e-06\n",
            "Epoch 85/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8482e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.6328e-06\n",
            "Epoch 86/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.7302e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.5786e-06\n",
            "Epoch 87/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.4056e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.5281e-06\n",
            "Epoch 88/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.4915e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.4766e-06\n",
            "Epoch 89/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - binary_accuracy: 1.0000 - loss: 1.3590e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.4264e-06\n",
            "Epoch 90/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3963e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.3804e-06\n",
            "Epoch 91/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.4259e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.3366e-06\n",
            "Epoch 92/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3972e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2902e-06\n",
            "Epoch 93/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2838e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2510e-06\n",
            "Epoch 94/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3378e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.2098e-06\n",
            "Epoch 95/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1899e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.1711e-06\n",
            "Epoch 96/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1737e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.1334e-06\n",
            "Epoch 97/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1480e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.0982e-06\n",
            "Epoch 98/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2191e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.0629e-06\n",
            "Epoch 99/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 1.1582e-06 - val_binary_accuracy: 1.0000 - val_loss: 1.0301e-06\n",
            "Epoch 100/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0270e-06 - val_binary_accuracy: 1.0000 - val_loss: 9.9836e-07\n",
            "Epoch 101/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.5992e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.6844e-07\n",
            "Epoch 102/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.9468e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.3847e-07\n",
            "Epoch 103/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 8.8008e-07 - val_binary_accuracy: 1.0000 - val_loss: 9.0920e-07\n",
            "Epoch 104/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.4983e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.8201e-07\n",
            "Epoch 105/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 9.3494e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.5418e-07\n",
            "Epoch 106/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.3577e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.2782e-07\n",
            "Epoch 107/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.5877e-07 - val_binary_accuracy: 1.0000 - val_loss: 8.0386e-07\n",
            "Epoch 108/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 8.0883e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.7893e-07\n",
            "Epoch 109/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 7.3152e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.5551e-07\n",
            "Epoch 110/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 8.2959e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.3227e-07\n",
            "Epoch 111/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 6.7977e-07 - val_binary_accuracy: 1.0000 - val_loss: 7.1129e-07\n",
            "Epoch 112/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.5087e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.8982e-07\n",
            "Epoch 113/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.5184e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.6894e-07\n",
            "Epoch 114/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.1948e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.5037e-07\n",
            "Epoch 115/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.5878e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.3024e-07\n",
            "Epoch 116/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.5929e-07 - val_binary_accuracy: 1.0000 - val_loss: 6.1193e-07\n",
            "Epoch 117/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.7432e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.9443e-07\n",
            "Epoch 118/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.0781e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.7724e-07\n",
            "Epoch 119/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.5249e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.5998e-07\n",
            "Epoch 120/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.8622e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.4371e-07\n",
            "Epoch 121/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.6713e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.2876e-07\n",
            "Epoch 122/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.2635e-07 - val_binary_accuracy: 1.0000 - val_loss: 5.1335e-07\n",
            "Epoch 123/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.0490e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.9825e-07\n",
            "Epoch 124/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.1771e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.8464e-07\n",
            "Epoch 125/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.8697e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.7050e-07\n",
            "Epoch 126/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2166e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.5677e-07\n",
            "Epoch 127/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.4844e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.4430e-07\n",
            "Epoch 128/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.1230e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.3202e-07\n",
            "Epoch 129/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.7540e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.1941e-07\n",
            "Epoch 130/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.4477e-07 - val_binary_accuracy: 1.0000 - val_loss: 4.0755e-07\n",
            "Epoch 131/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 3.6848e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.9670e-07\n",
            "Epoch 132/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.1260e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.8542e-07\n",
            "Epoch 133/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.1909e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.7438e-07\n",
            "Epoch 134/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.7784e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.6407e-07\n",
            "Epoch 135/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.3777e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.5420e-07\n",
            "Epoch 136/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.4552e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.4439e-07\n",
            "Epoch 137/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.1813e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.3505e-07\n",
            "Epoch 138/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.1262e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.2583e-07\n",
            "Epoch 139/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.4114e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.1669e-07\n",
            "Epoch 140/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.2920e-07 - val_binary_accuracy: 1.0000 - val_loss: 3.0829e-07\n",
            "Epoch 141/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.9019e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.9993e-07\n",
            "Epoch 142/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - binary_accuracy: 1.0000 - loss: 2.8273e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.9171e-07\n",
            "Epoch 143/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.3282e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.8319e-07\n",
            "Epoch 144/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.7167e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.7574e-07\n",
            "Epoch 145/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5436e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.6836e-07\n",
            "Epoch 146/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5449e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.6111e-07\n",
            "Epoch 147/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.7636e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.5392e-07\n",
            "Epoch 148/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1938e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.4752e-07\n",
            "Epoch 149/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3448e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.4062e-07\n",
            "Epoch 150/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1846e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.3416e-07\n",
            "Epoch 151/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1856e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.2792e-07\n",
            "Epoch 152/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.4407e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.2172e-07\n",
            "Epoch 153/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1205e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.1601e-07\n",
            "Epoch 154/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.5264e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.0995e-07\n",
            "Epoch 155/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 2.1589e-07 - val_binary_accuracy: 1.0000 - val_loss: 2.0448e-07\n",
            "Epoch 156/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 1.8176e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.9930e-07\n",
            "Epoch 157/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.0163e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.9388e-07\n",
            "Epoch 158/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.9830e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.8884e-07\n",
            "Epoch 159/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6712e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.8407e-07\n",
            "Epoch 160/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7886e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.7894e-07\n",
            "Epoch 161/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7947e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.7422e-07\n",
            "Epoch 162/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5973e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.6989e-07\n",
            "Epoch 163/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7154e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.6521e-07\n",
            "Epoch 164/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5304e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.6113e-07\n",
            "Epoch 165/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6635e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.5673e-07\n",
            "Epoch 166/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6628e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.5273e-07\n",
            "Epoch 167/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.4344e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.4869e-07\n",
            "Epoch 168/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3882e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.4488e-07\n",
            "Epoch 169/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3781e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.4115e-07\n",
            "Epoch 170/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.4012e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.3741e-07\n",
            "Epoch 171/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3874e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.3380e-07\n",
            "Epoch 172/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1770e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.3059e-07\n",
            "Epoch 173/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2346e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.2722e-07\n",
            "Epoch 174/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2383e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.2389e-07\n",
            "Epoch 175/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2187e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.2073e-07\n",
            "Epoch 176/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0987e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.1763e-07\n",
            "Epoch 177/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.1695e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.1458e-07\n",
            "Epoch 178/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.1125e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.1167e-07\n",
            "Epoch 179/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.2117e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.0883e-07\n",
            "Epoch 180/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 1.1681e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.0613e-07\n",
            "Epoch 181/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1002e-07 - val_binary_accuracy: 1.0000 - val_loss: 1.0340e-07\n",
            "Epoch 182/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.7934e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0090e-07\n",
            "Epoch 183/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.5301e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.8312e-08\n",
            "Epoch 184/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.5851e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.5723e-08\n",
            "Epoch 185/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.0724e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.3313e-08\n",
            "Epoch 186/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.4360e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.0997e-08\n",
            "Epoch 187/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.8228e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.8740e-08\n",
            "Epoch 188/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.7434e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.6466e-08\n",
            "Epoch 189/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.6611e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.4389e-08\n",
            "Epoch 190/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.3038e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.2168e-08\n",
            "Epoch 191/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.8394e-08 - val_binary_accuracy: 1.0000 - val_loss: 8.0210e-08\n",
            "Epoch 192/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.4531e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.8186e-08\n",
            "Epoch 193/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.9251e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.6228e-08\n",
            "Epoch 194/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 8.1831e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.4343e-08\n",
            "Epoch 195/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.4307e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.2557e-08\n",
            "Epoch 196/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.5051e-08 - val_binary_accuracy: 1.0000 - val_loss: 7.0805e-08\n",
            "Epoch 197/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.6119e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.8971e-08\n",
            "Epoch 198/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.4910e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.7293e-08\n",
            "Epoch 199/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 6.2291e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.5728e-08\n",
            "Epoch 200/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 5.9903e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.4106e-08\n",
            "Epoch 201/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 6.5294e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.2499e-08\n",
            "Epoch 202/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 6.2924e-08 - val_binary_accuracy: 1.0000 - val_loss: 6.0970e-08\n",
            "Epoch 203/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 6.9768e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.9442e-08\n",
            "Epoch 204/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.7847e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.8057e-08\n",
            "Epoch 205/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.8533e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.6703e-08\n",
            "Epoch 206/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.6187e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.5231e-08\n",
            "Epoch 207/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.4865e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.3934e-08\n",
            "Epoch 208/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2436e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.2631e-08\n",
            "Epoch 209/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 5.1246e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.1345e-08\n",
            "Epoch 210/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2303e-08 - val_binary_accuracy: 1.0000 - val_loss: 5.0137e-08\n",
            "Epoch 211/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.8030e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.8959e-08\n",
            "Epoch 212/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.8797e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.7767e-08\n",
            "Epoch 213/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.3322e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.6670e-08\n",
            "Epoch 214/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.6661e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.5554e-08\n",
            "Epoch 215/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.7327e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.4497e-08\n",
            "Epoch 216/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.2187e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.3462e-08\n",
            "Epoch 217/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.0491e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.2450e-08\n",
            "Epoch 218/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.3820e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.1427e-08\n",
            "Epoch 219/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.6744e-08 - val_binary_accuracy: 1.0000 - val_loss: 4.0439e-08\n",
            "Epoch 220/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.8274e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.9535e-08\n",
            "Epoch 221/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.7701e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.8601e-08\n",
            "Epoch 222/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.6722e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.7711e-08\n",
            "Epoch 223/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 3.9250e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.6812e-08\n",
            "Epoch 224/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 3.6596e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.5976e-08\n",
            "Epoch 225/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 3.6808e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.5147e-08\n",
            "Epoch 226/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 3.3993e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.4329e-08\n",
            "Epoch 227/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0728e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.3549e-08\n",
            "Epoch 228/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0459e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.2796e-08\n",
            "Epoch 229/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.1918e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.2004e-08\n",
            "Epoch 230/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5619e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.1307e-08\n",
            "Epoch 231/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3291e-08 - val_binary_accuracy: 1.0000 - val_loss: 3.0575e-08\n",
            "Epoch 232/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.1705e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.9889e-08\n",
            "Epoch 233/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.9791e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.9229e-08\n",
            "Epoch 234/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.8314e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.8586e-08\n",
            "Epoch 235/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6682e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.7949e-08\n",
            "Epoch 236/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.8902e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.7328e-08\n",
            "Epoch 237/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7938e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.6716e-08\n",
            "Epoch 238/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3792e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.6140e-08\n",
            "Epoch 239/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6701e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.5544e-08\n",
            "Epoch 240/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5302e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.4957e-08\n",
            "Epoch 241/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6896e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.4403e-08\n",
            "Epoch 242/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 1.0000 - loss: 2.5883e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.3872e-08\n",
            "Epoch 243/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - binary_accuracy: 1.0000 - loss: 2.4959e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.3337e-08\n",
            "Epoch 244/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 2.2460e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.2836e-08\n",
            "Epoch 245/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.5625e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.2318e-08\n",
            "Epoch 246/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0839e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.1861e-08\n",
            "Epoch 247/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1722e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.1357e-08\n",
            "Epoch 248/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1398e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.0895e-08\n",
            "Epoch 249/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1282e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.0452e-08\n",
            "Epoch 250/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8924e-08 - val_binary_accuracy: 1.0000 - val_loss: 2.0016e-08\n",
            "Epoch 251/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3639e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.9555e-08\n",
            "Epoch 252/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0903e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.9149e-08\n",
            "Epoch 253/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7148e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.8755e-08\n",
            "Epoch 254/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8664e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.8338e-08\n",
            "Epoch 255/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8518e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.7958e-08\n",
            "Epoch 256/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7110e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.7567e-08\n",
            "Epoch 257/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7411e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.7194e-08\n",
            "Epoch 258/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6747e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.6831e-08\n",
            "Epoch 259/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.6376e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.6452e-08\n",
            "Epoch 260/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7494e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.6115e-08\n",
            "Epoch 261/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5103e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.5771e-08\n",
            "Epoch 262/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7667e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.5425e-08\n",
            "Epoch 263/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 1.6780e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.5096e-08\n",
            "Epoch 264/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.5081e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.4786e-08\n",
            "Epoch 265/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 1.5462e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.4480e-08\n",
            "Epoch 266/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 1.4252e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.4187e-08\n",
            "Epoch 267/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.4144e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3887e-08\n",
            "Epoch 268/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.3561e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3608e-08\n",
            "Epoch 269/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4404e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3333e-08\n",
            "Epoch 270/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3365e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.3069e-08\n",
            "Epoch 271/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2713e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2812e-08\n",
            "Epoch 272/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3794e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2543e-08\n",
            "Epoch 273/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.2215e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2306e-08\n",
            "Epoch 274/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.2995e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.2053e-08\n",
            "Epoch 275/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1890e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1811e-08\n",
            "Epoch 276/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0919e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1580e-08\n",
            "Epoch 277/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1800e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1351e-08\n",
            "Epoch 278/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.1180e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.1125e-08\n",
            "Epoch 279/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.0341e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0912e-08\n",
            "Epoch 280/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.9044e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.0690e-08\n",
            "Epoch 281/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.1646e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0479e-08\n",
            "Epoch 282/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.8190e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.0273e-08\n",
            "Epoch 283/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.0615e-08 - val_binary_accuracy: 1.0000 - val_loss: 1.0070e-08\n",
            "Epoch 284/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.0095e-08 - val_binary_accuracy: 1.0000 - val_loss: 9.8834e-09\n",
            "Epoch 285/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 9.3355e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.6993e-09\n",
            "Epoch 286/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 9.6035e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.5204e-09\n",
            "Epoch 287/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 9.3146e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.3477e-09\n",
            "Epoch 288/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 9.7511e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.1702e-09\n",
            "Epoch 289/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.0837e-09 - val_binary_accuracy: 1.0000 - val_loss: 9.0028e-09\n",
            "Epoch 290/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.4631e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.8484e-09\n",
            "Epoch 291/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 9.3256e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.6887e-09\n",
            "Epoch 292/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.6181e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.5425e-09\n",
            "Epoch 293/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.8422e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.3863e-09\n",
            "Epoch 294/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.6073e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.2428e-09\n",
            "Epoch 295/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.9108e-09 - val_binary_accuracy: 1.0000 - val_loss: 8.0929e-09\n",
            "Epoch 296/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 7.5792e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.9499e-09\n",
            "Epoch 297/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.7214e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.8146e-09\n",
            "Epoch 298/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.8244e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.6718e-09\n",
            "Epoch 299/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 8.3225e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.5426e-09\n",
            "Epoch 300/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.7788e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.4147e-09\n",
            "Epoch 301/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.8713e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.2791e-09\n",
            "Epoch 302/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.7939e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.1453e-09\n",
            "Epoch 303/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 7.0261e-09 - val_binary_accuracy: 1.0000 - val_loss: 7.0325e-09\n",
            "Epoch 304/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.3465e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.9103e-09\n",
            "Epoch 305/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.9589e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.7911e-09\n",
            "Epoch 306/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.4401e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.6757e-09\n",
            "Epoch 307/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 7.2777e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.5639e-09\n",
            "Epoch 308/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 5.4194e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.4701e-09\n",
            "Epoch 309/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 6.7875e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.3493e-09\n",
            "Epoch 310/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.5422e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.2469e-09\n",
            "Epoch 311/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.0924e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.1514e-09\n",
            "Epoch 312/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.3032e-09 - val_binary_accuracy: 1.0000 - val_loss: 6.0531e-09\n",
            "Epoch 313/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.4688e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.9513e-09\n",
            "Epoch 314/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.4940e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.8559e-09\n",
            "Epoch 315/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.9029e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.7605e-09\n",
            "Epoch 316/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.6890e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.6666e-09\n",
            "Epoch 317/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 6.0376e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.5828e-09\n",
            "Epoch 318/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 6.2064e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.4959e-09\n",
            "Epoch 319/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.4201e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.4155e-09\n",
            "Epoch 320/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.8452e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.3291e-09\n",
            "Epoch 321/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.2319e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.2477e-09\n",
            "Epoch 322/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 5.4197e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.1677e-09\n",
            "Epoch 323/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.9635e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.0857e-09\n",
            "Epoch 324/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.7814e-09 - val_binary_accuracy: 1.0000 - val_loss: 5.0081e-09\n",
            "Epoch 325/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.7948e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.9378e-09\n",
            "Epoch 326/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 5.4570e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.8613e-09\n",
            "Epoch 327/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 4.7556e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.7947e-09\n",
            "Epoch 328/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 4.6024e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.7286e-09\n",
            "Epoch 329/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 4.9222e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.6637e-09\n",
            "Epoch 330/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 5.0590e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.6012e-09\n",
            "Epoch 331/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.9685e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.5462e-09\n",
            "Epoch 332/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.0535e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.4885e-09\n",
            "Epoch 333/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.3940e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.4246e-09\n",
            "Epoch 334/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.0916e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.3649e-09\n",
            "Epoch 335/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.2375e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.3025e-09\n",
            "Epoch 336/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 4.2861e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.2413e-09\n",
            "Epoch 337/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.5270e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.1831e-09\n",
            "Epoch 338/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - binary_accuracy: 1.0000 - loss: 4.5705e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.1318e-09\n",
            "Epoch 339/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - binary_accuracy: 1.0000 - loss: 3.9371e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.0769e-09\n",
            "Epoch 340/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - binary_accuracy: 1.0000 - loss: 3.9098e-09 - val_binary_accuracy: 1.0000 - val_loss: 4.0219e-09\n",
            "Epoch 341/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - binary_accuracy: 1.0000 - loss: 4.1658e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.9651e-09\n",
            "Epoch 342/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - binary_accuracy: 1.0000 - loss: 3.9341e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.9173e-09\n",
            "Epoch 343/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - binary_accuracy: 1.0000 - loss: 3.6544e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.8689e-09\n",
            "Epoch 344/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.5445e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.8235e-09\n",
            "Epoch 345/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3289e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.7769e-09\n",
            "Epoch 346/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 4.2584e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.7206e-09\n",
            "Epoch 347/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.8153e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.6724e-09\n",
            "Epoch 348/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.7067e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.6300e-09\n",
            "Epoch 349/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 4.0258e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.5826e-09\n",
            "Epoch 350/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.6720e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.5408e-09\n",
            "Epoch 351/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3626e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.4986e-09\n",
            "Epoch 352/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.5779e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.4557e-09\n",
            "Epoch 353/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.4747e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.4213e-09\n",
            "Epoch 354/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7135e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.3865e-09\n",
            "Epoch 355/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.9155e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.3504e-09\n",
            "Epoch 356/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.9884e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.3059e-09\n",
            "Epoch 357/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.2068e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.2760e-09\n",
            "Epoch 358/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3448e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.2296e-09\n",
            "Epoch 359/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3993e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.1942e-09\n",
            "Epoch 360/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.9727e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.1541e-09\n",
            "Epoch 361/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.0293e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.1198e-09\n",
            "Epoch 362/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 3.5470e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.0752e-09\n",
            "Epoch 363/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 3.0338e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.0432e-09\n",
            "Epoch 364/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.8693e-09 - val_binary_accuracy: 1.0000 - val_loss: 3.0078e-09\n",
            "Epoch 365/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - binary_accuracy: 1.0000 - loss: 2.6221e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9741e-09\n",
            "Epoch 366/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 3.1189e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9390e-09\n",
            "Epoch 367/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 3.3237e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.9059e-09\n",
            "Epoch 368/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.6868e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8770e-09\n",
            "Epoch 369/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7821e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8475e-09\n",
            "Epoch 370/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 3.0172e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8217e-09\n",
            "Epoch 371/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6717e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.8015e-09\n",
            "Epoch 372/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7889e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.7656e-09\n",
            "Epoch 373/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.8159e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.7396e-09\n",
            "Epoch 374/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.2808e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.7105e-09\n",
            "Epoch 375/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - binary_accuracy: 1.0000 - loss: 2.8444e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6837e-09\n",
            "Epoch 376/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6758e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6618e-09\n",
            "Epoch 377/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6740e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6383e-09\n",
            "Epoch 378/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.7816e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.6115e-09\n",
            "Epoch 379/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6718e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5802e-09\n",
            "Epoch 380/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.8813e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5616e-09\n",
            "Epoch 381/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.6632e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5404e-09\n",
            "Epoch 382/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.5501e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.5230e-09\n",
            "Epoch 383/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 2.3599e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4976e-09\n",
            "Epoch 384/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.3538e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4807e-09\n",
            "Epoch 385/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 2.4382e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4549e-09\n",
            "Epoch 386/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 2.2959e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4330e-09\n",
            "Epoch 387/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.2638e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.4162e-09\n",
            "Epoch 388/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4346e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3933e-09\n",
            "Epoch 389/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.4918e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3763e-09\n",
            "Epoch 390/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2948e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3620e-09\n",
            "Epoch 391/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.4380e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3399e-09\n",
            "Epoch 392/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2910e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3251e-09\n",
            "Epoch 393/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2075e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.3116e-09\n",
            "Epoch 394/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.7061e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2846e-09\n",
            "Epoch 395/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3580e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2702e-09\n",
            "Epoch 396/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.3746e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2561e-09\n",
            "Epoch 397/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2987e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2365e-09\n",
            "Epoch 398/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2089e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2295e-09\n",
            "Epoch 399/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.1714e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.2115e-09\n",
            "Epoch 400/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.1608e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1997e-09\n",
            "Epoch 401/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2383e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1846e-09\n",
            "Epoch 402/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1930e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1748e-09\n",
            "Epoch 403/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.3720e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1671e-09\n",
            "Epoch 404/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.2535e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1513e-09\n",
            "Epoch 405/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.3572e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1489e-09\n",
            "Epoch 406/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 2.3662e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1313e-09\n",
            "Epoch 407/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 2.0880e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1254e-09\n",
            "Epoch 408/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.1045e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1168e-09\n",
            "Epoch 409/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.1220e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.1116e-09\n",
            "Epoch 410/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0530e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0950e-09\n",
            "Epoch 411/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9836e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0900e-09\n",
            "Epoch 412/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1404e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0839e-09\n",
            "Epoch 413/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1242e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0701e-09\n",
            "Epoch 414/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9809e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0698e-09\n",
            "Epoch 415/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0210e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0620e-09\n",
            "Epoch 416/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.9236e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0480e-09\n",
            "Epoch 417/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0610e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0382e-09\n",
            "Epoch 418/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 2.1379e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0339e-09\n",
            "Epoch 419/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0283e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0261e-09\n",
            "Epoch 420/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0003e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0156e-09\n",
            "Epoch 421/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.1184e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0071e-09\n",
            "Epoch 422/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8174e-09 - val_binary_accuracy: 1.0000 - val_loss: 2.0017e-09\n",
            "Epoch 423/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 1.9413e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9902e-09\n",
            "Epoch 424/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.7963e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9827e-09\n",
            "Epoch 425/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0295e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9740e-09\n",
            "Epoch 426/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.8067e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9620e-09\n",
            "Epoch 427/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.8112e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9526e-09\n",
            "Epoch 428/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 1.0000 - loss: 1.9445e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9491e-09\n",
            "Epoch 429/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9455e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9419e-09\n",
            "Epoch 430/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9657e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9216e-09\n",
            "Epoch 431/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 2.0727e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9290e-09\n",
            "Epoch 432/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.9613e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9129e-09\n",
            "Epoch 433/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8137e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9117e-09\n",
            "Epoch 434/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 1.0000 - loss: 1.9087e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9066e-09\n",
            "Epoch 435/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9564e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.9002e-09\n",
            "Epoch 436/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.7720e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8930e-09\n",
            "Epoch 437/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7525e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8735e-09\n",
            "Epoch 438/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8380e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8883e-09\n",
            "Epoch 439/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9216e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8580e-09\n",
            "Epoch 440/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8317e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8618e-09\n",
            "Epoch 441/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.8409e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8477e-09\n",
            "Epoch 442/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 2.0839e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8553e-09\n",
            "Epoch 443/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.8865e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8262e-09\n",
            "Epoch 444/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7339e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8396e-09\n",
            "Epoch 445/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9358e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8131e-09\n",
            "Epoch 446/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.8221e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8188e-09\n",
            "Epoch 447/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - binary_accuracy: 1.0000 - loss: 1.8258e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8098e-09\n",
            "Epoch 448/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - binary_accuracy: 1.0000 - loss: 1.7417e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.8024e-09\n",
            "Epoch 449/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.7784e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7932e-09\n",
            "Epoch 450/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7889e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7916e-09\n",
            "Epoch 451/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.9462e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7890e-09\n",
            "Epoch 452/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7523e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7713e-09\n",
            "Epoch 453/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.7883e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7728e-09\n",
            "Epoch 454/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.8363e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7608e-09\n",
            "Epoch 455/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7278e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7576e-09\n",
            "Epoch 456/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6964e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7358e-09\n",
            "Epoch 457/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6784e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7480e-09\n",
            "Epoch 458/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.9785e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7291e-09\n",
            "Epoch 459/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7351e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7259e-09\n",
            "Epoch 460/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5855e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7206e-09\n",
            "Epoch 461/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7569e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.7135e-09\n",
            "Epoch 462/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7318e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6987e-09\n",
            "Epoch 463/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6757e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6819e-09\n",
            "Epoch 464/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7437e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6951e-09\n",
            "Epoch 465/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.7413e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6907e-09\n",
            "Epoch 466/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5377e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6774e-09\n",
            "Epoch 467/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7664e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6780e-09\n",
            "Epoch 468/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 1.0000 - loss: 1.7547e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6755e-09\n",
            "Epoch 469/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.5661e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6557e-09\n",
            "Epoch 470/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 1.7702e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6677e-09\n",
            "Epoch 471/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 1.0000 - loss: 1.4797e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6323e-09\n",
            "Epoch 472/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6752e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6451e-09\n",
            "Epoch 473/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.7211e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6521e-09\n",
            "Epoch 474/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6059e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6353e-09\n",
            "Epoch 475/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6392e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6219e-09\n",
            "Epoch 476/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.4510e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6157e-09\n",
            "Epoch 477/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4685e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6223e-09\n",
            "Epoch 478/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.6904e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6261e-09\n",
            "Epoch 479/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.6047e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6021e-09\n",
            "Epoch 480/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.4071e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5927e-09\n",
            "Epoch 481/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5460e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.6010e-09\n",
            "Epoch 482/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5338e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5773e-09\n",
            "Epoch 483/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.7918e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5813e-09\n",
            "Epoch 484/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - binary_accuracy: 1.0000 - loss: 1.6542e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5641e-09\n",
            "Epoch 485/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4939e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5754e-09\n",
            "Epoch 486/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5862e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5727e-09\n",
            "Epoch 487/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4951e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5685e-09\n",
            "Epoch 488/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5591e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5570e-09\n",
            "Epoch 489/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.6226e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5601e-09\n",
            "Epoch 490/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 1.0000 - loss: 1.4382e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5498e-09\n",
            "Epoch 491/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.5247e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5416e-09\n",
            "Epoch 492/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 1.0000 - loss: 1.5123e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5356e-09\n",
            "Epoch 493/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.6200e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5320e-09\n",
            "Epoch 494/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.4623e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5262e-09\n",
            "Epoch 495/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5510e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5203e-09\n",
            "Epoch 496/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5068e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5303e-09\n",
            "Epoch 497/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5447e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5048e-09\n",
            "Epoch 498/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 1.0000 - loss: 1.5495e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5232e-09\n",
            "Epoch 499/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.5570e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.5204e-09\n",
            "Epoch 500/500\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 1.0000 - loss: 1.3356e-09 - val_binary_accuracy: 1.0000 - val_loss: 1.4998e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.plot(history.history['binary_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "y6dgf8EcpEE4",
        "outputId": "c3b232e7-2652-404e-c75d-48912b353d55"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x782f03ed2590>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.round(model.predict(X_test)).flatten()\n",
        "\n",
        "results['Neural Network'] = [accuracy_score(y_test, y_pred),\n",
        "                             precision_score(y_test, y_pred, average='weighted'),\n",
        "                             recall_score(y_test, y_pred, average='weighted'),\n",
        "                             f1_score(y_test, y_pred, average='weighted'),\n",
        "                             training_time]\n",
        "print(\"Accuracy:\", results['Neural Network'][0])\n",
        "print(\"Precision:\", results['Neural Network'][1])\n",
        "print(\"Recall:\", results['Neural Network'][2])\n",
        "print(\"F1-score:\", results['Neural Network'][3])\n",
        "print(\"Training Time:\", results['Neural Network'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-kWVBeaKbxE",
        "outputId": "3a50c222-8dd2-4d19-f725-b9d4f16b642c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 323.9352648258209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Result Comparison and Analysis 📈"
      ],
      "metadata": {
        "id": "5Svry9nRpSCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time'])\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "BxPpTKIaZO8k",
        "outputId": "8d930a2d-22e0-4db6-ce49-ceb5e2e7e535"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Accuracy  Precision    Recall  \\\n",
              "Logistic Regression                       0.992667   0.992722  0.992667   \n",
              "K-Nearest Neighbors (KNN)                 0.961333   0.963767  0.961333   \n",
              "Decision Trees                            1.000000   1.000000  1.000000   \n",
              "Random Forest                             1.000000   1.000000  1.000000   \n",
              "Extra Trees                               1.000000   1.000000  1.000000   \n",
              "Support Vector Machines                   1.000000   1.000000  1.000000   \n",
              "Neural Networks (Multi-layer Perceptron)  1.000000   1.000000  1.000000   \n",
              "AdaBoost                                  1.000000   1.000000  1.000000   \n",
              "XGBoost                                   1.000000   1.000000  1.000000   \n",
              "CatBoost                                  1.000000   1.000000  1.000000   \n",
              "Stochastic Gradient Descent (SGD)         1.000000   1.000000  1.000000   \n",
              "Neural Network                            1.000000   1.000000  1.000000   \n",
              "\n",
              "                                          F1-Score  Training Time  \n",
              "Logistic Regression                       0.992657       0.040001  \n",
              "K-Nearest Neighbors (KNN)                 0.961549       0.386080  \n",
              "Decision Trees                            1.000000       0.121746  \n",
              "Random Forest                             1.000000       0.852047  \n",
              "Extra Trees                               1.000000       0.783073  \n",
              "Support Vector Machines                   1.000000       0.547423  \n",
              "Neural Networks (Multi-layer Perceptron)  1.000000      11.617570  \n",
              "AdaBoost                                  1.000000       0.931497  \n",
              "XGBoost                                   1.000000       8.296207  \n",
              "CatBoost                                  1.000000      31.833113  \n",
              "Stochastic Gradient Descent (SGD)         1.000000       0.004798  \n",
              "Neural Network                            1.000000     323.935265  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c91574a0-b34c-441d-9ebc-1af486a9629d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.992667</td>\n",
              "      <td>0.992722</td>\n",
              "      <td>0.992667</td>\n",
              "      <td>0.992657</td>\n",
              "      <td>0.040001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbors (KNN)</th>\n",
              "      <td>0.961333</td>\n",
              "      <td>0.963767</td>\n",
              "      <td>0.961333</td>\n",
              "      <td>0.961549</td>\n",
              "      <td>0.386080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Trees</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.121746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.852047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra Trees</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.783073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machines</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.547423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Networks (Multi-layer Perceptron)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.617570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.931497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.296207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.833113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stochastic Gradient Descent (SGD)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>323.935265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c91574a0-b34c-441d-9ebc-1af486a9629d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c91574a0-b34c-441d-9ebc-1af486a9629d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c91574a0-b34c-441d-9ebc-1af486a9629d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c0fb5384-0966-4d07-9b65-6deee0987dfc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0fb5384-0966-4d07-9b65-6deee0987dfc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c0fb5384-0966-4d07-9b65-6deee0987dfc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c042ca3c-3387-45a7-9be8-683e9a908c2f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c042ca3c-3387-45a7-9be8-683e9a908c2f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011170397386744012,\n        \"min\": 0.9613333333333334,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9926666666666667,\n          0.9613333333333334,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010479518297760882,\n        \"min\": 0.9637670892742709,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9927224312410754,\n          0.9637670892742709,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011170397386744012,\n        \"min\": 0.9613333333333334,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9926666666666667,\n          0.9613333333333334,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011109528176126307,\n        \"min\": 0.9615490402431071,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.992657134228,\n          0.9615490402431071,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 92.52112419069361,\n        \"min\": 0.004798412322998047,\n        \"max\": 323.9352648258209,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.004798412322998047,\n          31.833112955093384,\n          0.04000067710876465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Best Performing Model - Linear Discriminant Analysis (LDA)"
      ],
      "metadata": {
        "id": "5CwALZoTpgOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Convert SparseTensor to dense numpy arrays\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Initialize Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lda.fit(X_train_dense, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lda.predict(X_test_dense)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHigg7lQpqu4",
        "outputId": "46603bfd-bcf6-4a57-bfa2-dd2395fb459a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9906666666666667\n",
            "Precision: 0.9907830650972412\n",
            "Recall: 0.9906666666666667\n",
            "F1-score: 0.9906792563465785\n",
            "Training Time: 3.8430850505828857\n",
            "CPU times: user 6.74 s, sys: 648 ms, total: 7.39 s\n",
            "Wall time: 3.92 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bc_aBu5pxyU",
        "outputId": "ad38429b-661b-43c1-8e9e-dc192bf4fb33"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       599\n",
            "           1       1.00      0.99      0.99       901\n",
            "\n",
            "    accuracy                           0.99      1500\n",
            "   macro avg       0.99      0.99      0.99      1500\n",
            "weighted avg       0.99      0.99      0.99      1500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix-"
      ],
      "metadata": {
        "id": "_qxMzBIYp6-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "classes = ['0', '1']\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "\n",
        "# Fill the cells of the confusion matrix with values\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "D97HTxxOp5tk",
        "outputId": "2b19a95c-0f6b-453b-e339-cc83b3a53c4d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Iterate over each classifier\n",
        "classifiers = {\n",
        "    'Logistic Regression': logistic,\n",
        "    'K-Nearest Neighbors (KNN)': knn,\n",
        "    'Gaussian Naive Bayes': gnb,\n",
        "    'Decision Trees': dt,\n",
        "    'Random Forest': rf,\n",
        "    'Extra Trees': et,\n",
        "    'Support Vector Machines': svm,\n",
        "    'Neural Networks (Multi-layer Perceptron)': mlp,\n",
        "    'AdaBoost': ada,\n",
        "    'XGBoost': xgboost,\n",
        "    'LightGBM': lgbm,\n",
        "    'CatBoost': cat,\n",
        "    'Stochastic Gradient Descent (SGD)': sgd,\n",
        "    'Linear Discriminant Analysis': lda,\n",
        "    'Quadratic Discriminant Analysis': qda,\n",
        "    'Neural Network': model\n",
        "}\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "    try:\n",
        "        # Predict using the classifier\n",
        "        if name == 'Neural Network':  # For neural network model\n",
        "            # Convert SparseTensor to dense numpy arrays\n",
        "            X_test_dense = X_test.toarray()\n",
        "            y_pred = np.round(classifier.predict(X_test_dense)).flatten()\n",
        "        elif name == 'LightGBM':\n",
        "            # Predict using LightGBM model directly\n",
        "            y_pred = classifier.predict(X_test)\n",
        "        else:\n",
        "            # Convert TF-IDF transformed sparse matrices to dense numpy arrays\n",
        "            X_test_dense = X_test.toarray()\n",
        "            y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "        # Get indices of rows predicted as hate speech\n",
        "        hate_speech_indices = np.where(y_pred == 1)[0]\n",
        "\n",
        "        # Get the rows of speeches predicted as hate speech\n",
        "        hate_speech_rows = df1.iloc[hate_speech_indices]\n",
        "\n",
        "        # Display the hate speech rows\n",
        "        print(f\"Hate speech detected by {name} classifier:\")\n",
        "        print(hate_speech_rows)\n",
        "\n",
        "        # Save the hate speech rows to a CSV file\n",
        "        hate_speech_rows.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/{name}_hate_speech.csv\", index=False)\n",
        "    except AttributeError:\n",
        "        print(f\"AttributeError: Cannot predict using {name}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXZ-ElHbqkc7",
        "outputId": "b3ffd368-1bd7-429a-a993-c2f0c8299774"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate speech detected by Logistic Regression classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[910 rows x 2 columns]\n",
            "Hate speech detected by K-Nearest Neighbors (KNN) classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "12    Saying 'Arabs' is a generalization and does no...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[853 rows x 2 columns]\n",
            "Hate speech detected by Gaussian Naive Bayes classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[898 rows x 2 columns]\n",
            "Hate speech detected by Decision Trees classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Random Forest classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Extra Trees classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Support Vector Machines classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Neural Networks (Multi-layer Perceptron) classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by AdaBoost classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by XGBoost classifier:\n",
            "                                                 speech  class\n",
            "2     It's a shame that there is no longer the cruci...      0\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "5     These Islamic will bring us back to the Middle...      0\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "...                                                 ...    ...\n",
            "1494                      I wish all of them would die.      0\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1498           A real Islamic invasion is taking place.      0\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[1274 rows x 2 columns]\n",
            "AttributeError: Cannot predict using LightGBM.\n",
            "Hate speech detected by CatBoost classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Stochastic Gradient Descent (SGD) classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "Hate speech detected by Linear Discriminant Analysis classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[891 rows x 2 columns]\n",
            "Hate speech detected by Quadratic Discriminant Analysis classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Hate speech detected by Neural Network classifier:\n",
            "                                                 speech  class\n",
            "3     Then we must castrate even Italians who rape, ...      1\n",
            "4     The Arabs do not want to impose their religion...      1\n",
            "6     Freedom of thought, conscience and religion me...      1\n",
            "8                                           The idea of      1\n",
            "11    The number of Muslims who have committed certa...      1\n",
            "...                                                 ...    ...\n",
            "1492  I personally have never met a Muslim who tried...      1\n",
            "1493  There is no better way to spread the terrorism...      1\n",
            "1495  What is your problem with Muslims? They are pe...      1\n",
            "1496  Did you know that the only terrorist attacks i...      1\n",
            "1499  Hi, I also condemn these acts that are so atro...      1\n",
            "\n",
            "[901 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}